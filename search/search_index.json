{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 As a software engineer, I created this handbook to serve as my own personal \"second brain\" - a living repository of knowledge, experiences, and learning that will go with me throughout my career. While others may find value in this documentation, its primary purpose is to help me grow and excel in my software engineering journey. Why I Created This Handbook \u00b6 The inspiration for this handbook came from a common challenge I faced, that I also feel others continuously face as well: the need to constantly revisit, relearn, and recall various aspects of software engineering. I found myself: Repeatedly searching for solutions I had previously implemented Needing a reliable way to document my learning experiences Wanting to track my growth and evolution as a developer Desiring a structured way to build upon my knowledge This handbook serves as my personal knowledge management system, helping me maintain and expand my expertise while reducing cognitive load. Structure of My Knowledge Base \u00b6 I've organized this handbook to reflect the key areas of my software engineering practice: \ud83d\udd2e Fundamentals Core concepts I need to maintain and regularly revisit, including programming principles, data structures, and algorithms. \ud83d\udcbb Programming Languages Documentation of my experience with Python, JavaScript/TypeScript, Java, Go, Rust, and C/C++: Language-specific patterns that I frequently use Solutions to common challenges Language-specific syntax overviews of each for review Personal coding preferences and style notes Tips and tricks to remember \ud83d\udee0 Tools and Technologies My setup and configurations for: Version control workflows IDE customizations Debugging approaches Container configurations \ud83d\udcd0 Architecture and Design Time tested insights, personal experiences, and learnings with: Design patterns Microservices architecture Tradoffs between different architectural approaches \ud83d\udcbe Database Systems My learnings, readings, and knowledge of: SQL and NoSQL as well as their various implementations ORM configurations Database design decisions and their outcomes \ud83d\ude80 DevOps and Deployment Here will be documentation of my preferred: CI/CD pipeline setups Monitoring solutions Cloud service configurations \ud83d\udccb Project Management Here you'll find my notes and learnings on process improvements and team collaboration. \ud83d\udc68\u200d\ud83d\udcbb Professional Development Here is where you'll find tracking my career growth through: My own growth in personal coding standards and skill Code review insights that I receive as I gain in seniority Learning resources that I find valuable as time goes on How I Use This Handbook \u00b6 Daily Work \u00b6 Quick references for common tasks Documentation of solutions to recurring problems Storage for useful code snippets and patterns I find myself continually searching for Learning and Growth \u00b6 Recording new concepts as I learn them Documenting lessons learned from projects that I take on and contribute to Tracking my evolution in different technical areas Career Development \u00b6 Maintaining a record of my growing expertise Tracking projects and their outcomes Noting areas for future learning and improvement Benefits of Maintaining This Knowledge Base \u00b6 1. Personal Reference \u00b6 It provides quick access to my preferred solutions Documents my learning journey as my career progresses Records my decisions and their outcomes for better feedback loops 2. Knowledge Retention \u00b6 Structured documentation of knowledge reduces cognitive overhead Reduces the need to continually search for answers to common problems I encounter Provides a base level floor of knowledge that I can always build off of as my field changes i.e. \"first-principles\". 3. Career Growth \u00b6 Portfolio of my technical knowledge Record of problem-solving appraoches Documentation of my professional evolution Living Documentation \u00b6 This handbook grows with my career, reflecting: New technologies I learn Projects I complete Challenges I overcome Insights I gain Skills I develop While others may find value in this documentation, its primary purpose is to serve as my personal knowledge repository, helping me become a better software engineer. It represents my journey, my learnings, and my growth in the field. As I continue to learn and evolve in my career, this handbook will remain my trusted companion, growing and adapting with each new experience and challenge.","title":"Introduction"},{"location":"#introduction","text":"As a software engineer, I created this handbook to serve as my own personal \"second brain\" - a living repository of knowledge, experiences, and learning that will go with me throughout my career. While others may find value in this documentation, its primary purpose is to help me grow and excel in my software engineering journey.","title":"Introduction"},{"location":"#why-i-created-this-handbook","text":"The inspiration for this handbook came from a common challenge I faced, that I also feel others continuously face as well: the need to constantly revisit, relearn, and recall various aspects of software engineering. I found myself: Repeatedly searching for solutions I had previously implemented Needing a reliable way to document my learning experiences Wanting to track my growth and evolution as a developer Desiring a structured way to build upon my knowledge This handbook serves as my personal knowledge management system, helping me maintain and expand my expertise while reducing cognitive load.","title":"Why I Created This Handbook"},{"location":"#structure-of-my-knowledge-base","text":"I've organized this handbook to reflect the key areas of my software engineering practice: \ud83d\udd2e Fundamentals Core concepts I need to maintain and regularly revisit, including programming principles, data structures, and algorithms. \ud83d\udcbb Programming Languages Documentation of my experience with Python, JavaScript/TypeScript, Java, Go, Rust, and C/C++: Language-specific patterns that I frequently use Solutions to common challenges Language-specific syntax overviews of each for review Personal coding preferences and style notes Tips and tricks to remember \ud83d\udee0 Tools and Technologies My setup and configurations for: Version control workflows IDE customizations Debugging approaches Container configurations \ud83d\udcd0 Architecture and Design Time tested insights, personal experiences, and learnings with: Design patterns Microservices architecture Tradoffs between different architectural approaches \ud83d\udcbe Database Systems My learnings, readings, and knowledge of: SQL and NoSQL as well as their various implementations ORM configurations Database design decisions and their outcomes \ud83d\ude80 DevOps and Deployment Here will be documentation of my preferred: CI/CD pipeline setups Monitoring solutions Cloud service configurations \ud83d\udccb Project Management Here you'll find my notes and learnings on process improvements and team collaboration. \ud83d\udc68\u200d\ud83d\udcbb Professional Development Here is where you'll find tracking my career growth through: My own growth in personal coding standards and skill Code review insights that I receive as I gain in seniority Learning resources that I find valuable as time goes on","title":"Structure of My Knowledge Base"},{"location":"#how-i-use-this-handbook","text":"","title":"How I Use This Handbook"},{"location":"#daily-work","text":"Quick references for common tasks Documentation of solutions to recurring problems Storage for useful code snippets and patterns I find myself continually searching for","title":"Daily Work"},{"location":"#learning-and-growth","text":"Recording new concepts as I learn them Documenting lessons learned from projects that I take on and contribute to Tracking my evolution in different technical areas","title":"Learning and Growth"},{"location":"#career-development","text":"Maintaining a record of my growing expertise Tracking projects and their outcomes Noting areas for future learning and improvement","title":"Career Development"},{"location":"#benefits-of-maintaining-this-knowledge-base","text":"","title":"Benefits of Maintaining This Knowledge Base"},{"location":"#1-personal-reference","text":"It provides quick access to my preferred solutions Documents my learning journey as my career progresses Records my decisions and their outcomes for better feedback loops","title":"1. Personal Reference"},{"location":"#2-knowledge-retention","text":"Structured documentation of knowledge reduces cognitive overhead Reduces the need to continually search for answers to common problems I encounter Provides a base level floor of knowledge that I can always build off of as my field changes i.e. \"first-principles\".","title":"2. Knowledge Retention"},{"location":"#3-career-growth","text":"Portfolio of my technical knowledge Record of problem-solving appraoches Documentation of my professional evolution","title":"3. Career Growth"},{"location":"#living-documentation","text":"This handbook grows with my career, reflecting: New technologies I learn Projects I complete Challenges I overcome Insights I gain Skills I develop While others may find value in this documentation, its primary purpose is to serve as my personal knowledge repository, helping me become a better software engineer. It represents my journey, my learnings, and my growth in the field. As I continue to learn and evolve in my career, this handbook will remain my trusted companion, growing and adapting with each new experience and challenge.","title":"Living Documentation"},{"location":"1.Fundamentals/a.%20programming_principles/","text":"\ud83d\udd2e Programming Fundamentals \u00b6 Introduction \u00b6 As a software engineer, mastering programming fundamentals is fundamental to writing maintainable, scalable, and efficient code. This guide focuses on Object-Oriented Programming (OOP), one of the most important paradigms in modern software development. Why Object-Oriented Programming? \u00b6 I've personally found OOP to be crucial so far in my journey as a software engineer. OOP is important because: It helps manage complex systems by breaking them into manageable pieces Promotes code reuse and reduces redundancy Makes code more maintainable and easier to debug Facilitates team collaboration through clear interfaces \u2705 When to Use OOP \u00b6 When building medium to large-scale applications Working on long-term maintainable projects Developing systems with clear entity relationships Creating frameworks or libraries Working with domain-driven design \u274c When Not to Use OOP \u00b6 Simple script-like programs One-off automation tasks Performance-critical systems where procedural code might be more efficient Functional programming scenarios \ud83d\udcd8 Core Concepts \u00b6 \ud83d\udce6 Classes and Objects \u00b6 What Are They? \u00b6 Class: A blueprint for creating objects, defining their properties and behaviors Object: An instance of a class with actual values When to Create a Class \u00b6 When modeling real-world entities (e.g., User, Product) When grouping related functionality When you need multiple instances with similar properties When implementing a design pattern public class User { // Properties (state) private String username ; private String email ; // Constructor public User ( String username , String email ) { this . username = username ; this . email = email ; } // Methods (behavior) public void updateEmail ( String newEmail ) { this . email = newEmail ; } } \ud83d\udd12 Encapsulation \u00b6 What Is It? \u00b6 Encapsulation bundles data and the methods that it operates on within a single unit, restricting direct access to some of an object's components. \u2705 When to Use \u00b6 Protecting internal state of objects Controlling access to data Hiding implementation details Enforcing validation logic public class BankAccount { private double balance ; // Encapsulated data public void deposit ( double amount ) { if ( amount > 0 ) { balance += amount ; } else { throw new IllegalArgumentException ( \"Deposit amount must be positive\" ); } } public double getBalance () { return balance ; } } \ud83e\uddec Inheritance \u00b6 What Is It? \u00b6 Inheritance allows a class to inherit attributes and methods from another class, establishing an \"is-a\" relationship. \u2705 When to Use \u00b6 Creating specialized versions of classes Sharing common functionality among related classes Implementing polymorphic behavior Building class hierarchies \u274c When Not to Use \u00b6 When there's no clear \"is-a\" relationship When you need flexibility in changing behavior When inheritance would create deep hierarchies When composition would be more appropriate public abstract class Vehicle { protected String brand ; public abstract void start (); } public class Car extends Vehicle { @Override public void start () { System . out . println ( \"Car starting...\" ); } } \ud83d\udd04 Polymorphism \u00b6 What Is It? \u00b6 Polymorphism allows objects to take multiple forms, enabling you to perform the same action in different ways. Types of Polymorphism \u00b6 1. Compile-time (Method Overloading) \u00b6 Same method name, different parameters Resolve at compile time 2. Runtime (Method Overriding) \u00b6 Same method signature in parent and child classes Resolved at runtime \u2705 When to Use \u00b6 Creating flexible and extensible APIs Implementing plugins or extensions Working with collections of related objects Building framework-level code // Method Overloading public class Calculator { public int add ( int a , int b ) { return a + b ; } public double add ( double a , double b ) { return a + b ; } } // Method Overriding public interface PaymentProcessor { void processPayment ( double amount ); } public class CreditCardProcessor implements PaymentProcessor { @Override public void processPayment ( double amount ) { // Credit card specific logic } } \ud83d\udd17 Association, Aggregation, and Composition \u00b6 \ud83e\udd1d Association \u00b6 Represents relationships between objects Can be one-to-one, one-to-many, or many-to-many Objects have independent lifecycles \u2705 When to Use Association \u00b6 When objects need to communicate When representing relationships between independent entities When objects can exist independently One-to-One Association \u00b6 public class Person { private Passport passport ; // One person has exactly one passport public Person () {} public void setPassport ( Passport passport ) { this . passport = passport ; } public Passport getPassport () { return passport ; } } public class Passport { private Person owner ; // One passport belongs to exactly one person private String passportNumber ; public Passport ( String passportNumber ) { this . passportNumber = passportNumber ; } public void setOwner ( Person person ) { this . owner = person ; } } One-to-Many Association \u00b6 public class Department { private String name ; private List < Employee > employees ; // One department has many employees public Department ( String name ) { this . name = name ; this . employees = new ArrayList <> (); } public void addEmployee ( Employee employee ) { employees . add ( employee ); } public List < Employee > getEmployees () { return new ArrayList <> ( employees ); // Return copy for encapsulation } } public class Employee { private String name ; private Department department ; // One employee belongs to one department public Employee ( String name ) { this . name = name ; } public void setDepartment ( Department department ) { this . department = department ; } } Many-to-Many Association \u00b6 public class Student { private String name ; private List < Course > courses ; // One student can enroll in many courses public Student ( String name ) { this . name = name ; this . courses = new ArrayList <> (); } public void enrollInCourse ( Course course ) { if ( ! courses . contains ( course )) { courses . add ( course ); course . addStudent ( this ); } } public List < Course > getCourses () { return new ArrayList <> ( courses ); } } public class Course { private String courseName ; private List < Student > students ; // One course can have many students public Course ( String courseName ) { this . courseName = courseName ; this . students = new ArrayList <> (); } public void addStudent ( Student student ) { if ( ! students . contains ( student )) { students . add ( student ); } } public List < Student > getStudents () { return new ArrayList <> ( students ); } } // Usage Example public class Main { public static void main ( String [] args ) { // Creating courses Course java = new Course ( \"Java Programming\" ); Course python = new Course ( \"Python Programming\" ); // Creating students Student alice = new Student ( \"Alice\" ); Student bob = new Student ( \"Bob\" ); // Enrolling students in multiple courses alice . enrollInCourse ( java ); alice . enrollInCourse ( python ); bob . enrollInCourse ( java ); // Now: // - Alice is enrolled in both Java and Python courses // - Bob is enrolled in Java course // - Java course has two students (Alice and Bob) // - Python course has one student (Alice) } } Key Points About Associations \u00b6 1. One-to-One \ud83d\udd17 \u00b6 Each object is related to exactly one instance of another object Example: Person-Passport relationship Use when: representing unique pairings 2. One-to-Many \ud83d\udce6 \u00b6 One object can be related to multiple instances of another object Example: Department-Employee relationship Use when: representing hierarchical relationships 3. Many-to-Many \ud83d\udd04 \u00b6 Multiple objects can be related to multiple instances of another object Example: Student-Course relationship Use when: representing complex relationships where both sides can have multiple connections \ud83d\udca1 Best Practices \u00b6 \u2705 Always protect collections using defensive copying \u2705 Consider using bi-directional relationships when necessary \u2705 Implement proper encapsulation for associated objects \u26a0\ufe0f Be careful with circular references in bi-directional relationships \ud83d\udd12 Use appropriate access modifiers \ud83d\udcdd Document the nature of the relationship When to Use Each Type \u00b6 Choose the appropriate association type based on your business requirements: One-to-One: for unique pairings (Person-Passport) One-to-Many: For hierarchical relationships (Department-Employees) Many-to-Many: For complex relationships requiring multiple connections (Students-Courses) \ud83d\udce6 Aggregation (Has-A) \u00b6 Special form of association Represents ownership Objects can exist independently When to Use Aggregation \u00b6 When one class \"has\" another class When child objects can exist independently When sharing objects across owners public class Department { private List < Professor > professors ; // Aggregation } \ud83e\udde9 Composition (Part-Of) \u00b6 Stronger form of of aggregation Child objects cannot exist without parent Represents a \"part-of\" relationship When to Use Composition \u00b6 When child objects are essential parts of parent When child objects shouldn't exist independently When enforcing tight coupling is desired public class Car { private final Engine engine ; // Composition public Car () { engine = new Engine (); // Engine cannot exist without Car } } \ud83d\udca1 Best Practices \u00b6 1. Class Design \u00b6 Keep classes focused (Single Responsibility Principle) Favor composition over inheritance Use meaningful names Keep inheritance hierarchies shallow 2. Encapsulation \u00b6 Make fields private unless there's a good reason not to Provide getters/setters only when necessary Validate data in setters Use immutable objects when possible 3. Code Organization \u00b6 Group related classes in packages Maintain clear separation of concerns Document public APIs and complex logic Follow consistent naming conventions References \u00b6 Object Oriented Programming Notes OOP Principles Playlist","title":"\ud83d\udd2e Programming Fundamentals"},{"location":"1.Fundamentals/a.%20programming_principles/#programming-fundamentals","text":"","title":"\ud83d\udd2e Programming Fundamentals"},{"location":"1.Fundamentals/a.%20programming_principles/#introduction","text":"As a software engineer, mastering programming fundamentals is fundamental to writing maintainable, scalable, and efficient code. This guide focuses on Object-Oriented Programming (OOP), one of the most important paradigms in modern software development.","title":"Introduction"},{"location":"1.Fundamentals/a.%20programming_principles/#why-object-oriented-programming","text":"I've personally found OOP to be crucial so far in my journey as a software engineer. OOP is important because: It helps manage complex systems by breaking them into manageable pieces Promotes code reuse and reduces redundancy Makes code more maintainable and easier to debug Facilitates team collaboration through clear interfaces","title":"Why Object-Oriented Programming?"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use-oop","text":"When building medium to large-scale applications Working on long-term maintainable projects Developing systems with clear entity relationships Creating frameworks or libraries Working with domain-driven design","title":"\u2705 When to Use OOP"},{"location":"1.Fundamentals/a.%20programming_principles/#when-not-to-use-oop","text":"Simple script-like programs One-off automation tasks Performance-critical systems where procedural code might be more efficient Functional programming scenarios","title":"\u274c When Not to Use OOP"},{"location":"1.Fundamentals/a.%20programming_principles/#core-concepts","text":"","title":"\ud83d\udcd8 Core Concepts"},{"location":"1.Fundamentals/a.%20programming_principles/#classes-and-objects","text":"","title":"\ud83d\udce6 Classes and Objects"},{"location":"1.Fundamentals/a.%20programming_principles/#what-are-they","text":"Class: A blueprint for creating objects, defining their properties and behaviors Object: An instance of a class with actual values","title":"What Are They?"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-create-a-class","text":"When modeling real-world entities (e.g., User, Product) When grouping related functionality When you need multiple instances with similar properties When implementing a design pattern public class User { // Properties (state) private String username ; private String email ; // Constructor public User ( String username , String email ) { this . username = username ; this . email = email ; } // Methods (behavior) public void updateEmail ( String newEmail ) { this . email = newEmail ; } }","title":"When to Create a Class"},{"location":"1.Fundamentals/a.%20programming_principles/#encapsulation","text":"","title":"\ud83d\udd12 Encapsulation"},{"location":"1.Fundamentals/a.%20programming_principles/#what-is-it","text":"Encapsulation bundles data and the methods that it operates on within a single unit, restricting direct access to some of an object's components.","title":"What Is It?"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use","text":"Protecting internal state of objects Controlling access to data Hiding implementation details Enforcing validation logic public class BankAccount { private double balance ; // Encapsulated data public void deposit ( double amount ) { if ( amount > 0 ) { balance += amount ; } else { throw new IllegalArgumentException ( \"Deposit amount must be positive\" ); } } public double getBalance () { return balance ; } }","title":"\u2705 When to Use"},{"location":"1.Fundamentals/a.%20programming_principles/#inheritance","text":"","title":"\ud83e\uddec Inheritance"},{"location":"1.Fundamentals/a.%20programming_principles/#what-is-it_1","text":"Inheritance allows a class to inherit attributes and methods from another class, establishing an \"is-a\" relationship.","title":"What Is It?"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use_1","text":"Creating specialized versions of classes Sharing common functionality among related classes Implementing polymorphic behavior Building class hierarchies","title":"\u2705 When to Use"},{"location":"1.Fundamentals/a.%20programming_principles/#when-not-to-use","text":"When there's no clear \"is-a\" relationship When you need flexibility in changing behavior When inheritance would create deep hierarchies When composition would be more appropriate public abstract class Vehicle { protected String brand ; public abstract void start (); } public class Car extends Vehicle { @Override public void start () { System . out . println ( \"Car starting...\" ); } }","title":"\u274c When Not to Use"},{"location":"1.Fundamentals/a.%20programming_principles/#polymorphism","text":"","title":"\ud83d\udd04 Polymorphism"},{"location":"1.Fundamentals/a.%20programming_principles/#what-is-it_2","text":"Polymorphism allows objects to take multiple forms, enabling you to perform the same action in different ways.","title":"What Is It?"},{"location":"1.Fundamentals/a.%20programming_principles/#types-of-polymorphism","text":"","title":"Types of Polymorphism"},{"location":"1.Fundamentals/a.%20programming_principles/#1-compile-time-method-overloading","text":"Same method name, different parameters Resolve at compile time","title":"1. Compile-time (Method Overloading)"},{"location":"1.Fundamentals/a.%20programming_principles/#2-runtime-method-overriding","text":"Same method signature in parent and child classes Resolved at runtime","title":"2. Runtime (Method Overriding)"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use_2","text":"Creating flexible and extensible APIs Implementing plugins or extensions Working with collections of related objects Building framework-level code // Method Overloading public class Calculator { public int add ( int a , int b ) { return a + b ; } public double add ( double a , double b ) { return a + b ; } } // Method Overriding public interface PaymentProcessor { void processPayment ( double amount ); } public class CreditCardProcessor implements PaymentProcessor { @Override public void processPayment ( double amount ) { // Credit card specific logic } }","title":"\u2705 When to Use"},{"location":"1.Fundamentals/a.%20programming_principles/#association-aggregation-and-composition","text":"","title":"\ud83d\udd17 Association, Aggregation, and Composition"},{"location":"1.Fundamentals/a.%20programming_principles/#association","text":"Represents relationships between objects Can be one-to-one, one-to-many, or many-to-many Objects have independent lifecycles","title":"\ud83e\udd1d Association"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use-association","text":"When objects need to communicate When representing relationships between independent entities When objects can exist independently","title":"\u2705 When to Use Association"},{"location":"1.Fundamentals/a.%20programming_principles/#one-to-one-association","text":"public class Person { private Passport passport ; // One person has exactly one passport public Person () {} public void setPassport ( Passport passport ) { this . passport = passport ; } public Passport getPassport () { return passport ; } } public class Passport { private Person owner ; // One passport belongs to exactly one person private String passportNumber ; public Passport ( String passportNumber ) { this . passportNumber = passportNumber ; } public void setOwner ( Person person ) { this . owner = person ; } }","title":"One-to-One Association"},{"location":"1.Fundamentals/a.%20programming_principles/#one-to-many-association","text":"public class Department { private String name ; private List < Employee > employees ; // One department has many employees public Department ( String name ) { this . name = name ; this . employees = new ArrayList <> (); } public void addEmployee ( Employee employee ) { employees . add ( employee ); } public List < Employee > getEmployees () { return new ArrayList <> ( employees ); // Return copy for encapsulation } } public class Employee { private String name ; private Department department ; // One employee belongs to one department public Employee ( String name ) { this . name = name ; } public void setDepartment ( Department department ) { this . department = department ; } }","title":"One-to-Many Association"},{"location":"1.Fundamentals/a.%20programming_principles/#many-to-many-association","text":"public class Student { private String name ; private List < Course > courses ; // One student can enroll in many courses public Student ( String name ) { this . name = name ; this . courses = new ArrayList <> (); } public void enrollInCourse ( Course course ) { if ( ! courses . contains ( course )) { courses . add ( course ); course . addStudent ( this ); } } public List < Course > getCourses () { return new ArrayList <> ( courses ); } } public class Course { private String courseName ; private List < Student > students ; // One course can have many students public Course ( String courseName ) { this . courseName = courseName ; this . students = new ArrayList <> (); } public void addStudent ( Student student ) { if ( ! students . contains ( student )) { students . add ( student ); } } public List < Student > getStudents () { return new ArrayList <> ( students ); } } // Usage Example public class Main { public static void main ( String [] args ) { // Creating courses Course java = new Course ( \"Java Programming\" ); Course python = new Course ( \"Python Programming\" ); // Creating students Student alice = new Student ( \"Alice\" ); Student bob = new Student ( \"Bob\" ); // Enrolling students in multiple courses alice . enrollInCourse ( java ); alice . enrollInCourse ( python ); bob . enrollInCourse ( java ); // Now: // - Alice is enrolled in both Java and Python courses // - Bob is enrolled in Java course // - Java course has two students (Alice and Bob) // - Python course has one student (Alice) } }","title":"Many-to-Many Association"},{"location":"1.Fundamentals/a.%20programming_principles/#key-points-about-associations","text":"","title":"Key Points About Associations"},{"location":"1.Fundamentals/a.%20programming_principles/#1-one-to-one","text":"Each object is related to exactly one instance of another object Example: Person-Passport relationship Use when: representing unique pairings","title":"1. One-to-One \ud83d\udd17"},{"location":"1.Fundamentals/a.%20programming_principles/#2-one-to-many","text":"One object can be related to multiple instances of another object Example: Department-Employee relationship Use when: representing hierarchical relationships","title":"2. One-to-Many \ud83d\udce6"},{"location":"1.Fundamentals/a.%20programming_principles/#3-many-to-many","text":"Multiple objects can be related to multiple instances of another object Example: Student-Course relationship Use when: representing complex relationships where both sides can have multiple connections","title":"3. Many-to-Many \ud83d\udd04"},{"location":"1.Fundamentals/a.%20programming_principles/#best-practices","text":"\u2705 Always protect collections using defensive copying \u2705 Consider using bi-directional relationships when necessary \u2705 Implement proper encapsulation for associated objects \u26a0\ufe0f Be careful with circular references in bi-directional relationships \ud83d\udd12 Use appropriate access modifiers \ud83d\udcdd Document the nature of the relationship","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use-each-type","text":"Choose the appropriate association type based on your business requirements: One-to-One: for unique pairings (Person-Passport) One-to-Many: For hierarchical relationships (Department-Employees) Many-to-Many: For complex relationships requiring multiple connections (Students-Courses)","title":"When to Use Each Type"},{"location":"1.Fundamentals/a.%20programming_principles/#aggregation-has-a","text":"Special form of association Represents ownership Objects can exist independently","title":"\ud83d\udce6 Aggregation (Has-A)"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use-aggregation","text":"When one class \"has\" another class When child objects can exist independently When sharing objects across owners public class Department { private List < Professor > professors ; // Aggregation }","title":"When to Use Aggregation"},{"location":"1.Fundamentals/a.%20programming_principles/#composition-part-of","text":"Stronger form of of aggregation Child objects cannot exist without parent Represents a \"part-of\" relationship","title":"\ud83e\udde9 Composition (Part-Of)"},{"location":"1.Fundamentals/a.%20programming_principles/#when-to-use-composition","text":"When child objects are essential parts of parent When child objects shouldn't exist independently When enforcing tight coupling is desired public class Car { private final Engine engine ; // Composition public Car () { engine = new Engine (); // Engine cannot exist without Car } }","title":"When to Use Composition"},{"location":"1.Fundamentals/a.%20programming_principles/#best-practices_1","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/a.%20programming_principles/#1-class-design","text":"Keep classes focused (Single Responsibility Principle) Favor composition over inheritance Use meaningful names Keep inheritance hierarchies shallow","title":"1. Class Design"},{"location":"1.Fundamentals/a.%20programming_principles/#2-encapsulation","text":"Make fields private unless there's a good reason not to Provide getters/setters only when necessary Validate data in setters Use immutable objects when possible","title":"2. Encapsulation"},{"location":"1.Fundamentals/a.%20programming_principles/#3-code-organization","text":"Group related classes in packages Maintain clear separation of concerns Document public APIs and complex logic Follow consistent naming conventions","title":"3. Code Organization"},{"location":"1.Fundamentals/a.%20programming_principles/#references","text":"Object Oriented Programming Notes OOP Principles Playlist","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/","text":"\ud83d\udd2e Data Structures \u00b6 \ud83d\udcd8 Introduction \u00b6 Data structures are specialized formats for organizing, processing, retrieving, and storing data. Understanding data structures is fundamental to writing efficient and scalable code. This guide explores various data structures, their implementations, and practical applications in software development. Why Data Structures Matter \u00b6 \ud83c\udfaf Efficient Problem-Solving : Choosing the right data structure can dramatically improve program performance \ud83d\udcbc Career Development : Essential for technical interviews at top tech companies \ud83d\udd27 Code Optimization : Enables writing more efficient and maintainable code \ud83c\udf10 Real-World Applications : Critical for building scalable software systems \ud83c\udfc6 Competitive Edge : Fundamental for algorithmic problem-solving and competitions Guide Structure \u00b6 Each data structure section will cover: - Core concepts and characteristics - Implementation details - Time and space complexities - Common operations - Best practices and use cases - Code examples and tips Categories of Data Structures \u00b6 \ud83d\udcda Linear Data Structures \u00b6 Structures where elements are stored sequentially: Arrays & ArrayLists : Direct access by index Contiguous memory storage Best for: Fixed-size collections with frequent access Linked Lists : Dynamic size Non-contiguous storage Best for: Frequent insertions/deletions Stacks : LIFO (Last-In-First-Out) Best for: Function calls, undo operations Queues : FIFO (First-In-First-Out) Best for: Task scheduling, resource management \ud83c\udf33 Tree-Based Structures \u00b6 Hierarchical structures with parent-child relationships: Priority Queues : Efficient priority-based operations Best for: Scheduling, event handling Binary Trees : Two children per node maximum Best for: Hierarchical data Binary Search Trees : Ordered nodes Best for: Fast search, insert, delete \ud83c\udf32 Advanced Tree-Based Structures \u00b6 Specialized tree structures for specific use cases: AVL Trees : Balanced binary search trees Red-Black Trees : Balanced search with color properties 2-3 Trees : Guaranteed balanced search trees B-Trees : Optimized for disk storage K-D Trees : Space partitioning structure M-Ary Trees : Nodes with multiple children \ud83c\udfaf Hash-Based Structures \u00b6 Structures using hash functions: Hash Tables : Key-value storage O(1) average access Best for: Caching, dictionaries \ud83d\udd78\ufe0f Graph-Based Structures \u00b6 Structures representing connections: Directed Graphs : One-way connections Undirected Graphs : Two-way connections inaphs Coctions with costs Disjoint-Sets : Non-Overlapping group connections \ud83d\udcda Advanced Structures \u00b6 Specialized data structures: Tries : Efficient string operations Best for: Autocomplete, spell checkers Skip Lists : Probabilistic alternative to balanced trees Best for: Fast search with simple implementation Time Complexity Overview \u00b6 \ud83d\udcca Performance Overview \u00b6 Data Structure Access Search Insertion Deletion Space Array O(1) O(n) O(n) O(n) O(n) ArrayList O(1) O(n) O(n)* O(n) O(n) LinkedList O(n) O(n) O(1) O(1) O(n) Stack O(n) O(n) O(1) O(1) O(n) Queue O(n) O(n) O(1) O(1) O(n) Priority Queue O(1)*** O(n) O(log n) O(log n) O(n) Binary Tree O(n) O(n) O(n) O(n) O(n) Binary Search Tree O(log n)* O(log n)* O(log n)* O(log n)* O(n) AVL Tree O(log n) O(log n) O(log n) O(log n) O(n) Red-Black Tree O(log n) O(log n) O(log n) O(log n) O(n) 2-3 Tree O(log n) O(log n) O(log n) O(log n) O(n) B-Tree O(log n) O(log n) O(log n) O(log n) O(n) K-D Tree O(n) O(log n)** O(log n)** O(log n)** O(n) Trie O(m)**** O(m)**** O(m)**** O(m)**** O(n*m) Skip List O(log n)** O(log n)** O(log n)** O(log n)** O(n log n) Hash Table O(1)** O(1)** O(1)** O(1)* * Average case for balanced trees * Average case, assumes good hash function or balanced structure * For peek operation only * ** Where m is the length of the string/pattern \u2020 Amortized time complexity for dynamic resizing~~ References \u00b6 Data Structures and Algorithms Notes \ud83d\udcda LINEAR DATA STRUCTURESine Data Structures \u00b6 \ud83d\udcda ArrayList \u00b6 An ArrayList is a dynamic array implementation that automatically handles resizing as elements are added or removed. It provides fast random access and is one of the most used data structures in Java. Core Characteristics \u00b6 \ud83d\udcc8 Dynamic sizing \ud83d\udcca Contiguous memory storage \ud83d\udd0d Fast random access \ud83d\udcdd Mutable length Implementation Details \u00b6 Structure \u00b6 public class ArrayList < T > { private T [] backingArray ; // Internal array to store elements private int size ; // Number of elements in the ArrayList public static final int INITIAL_CAPACITY = 9 ; } \ud83d\udd27 Core Operations & Time Complexities \u00b6 Adding Elements \u00b6 addToBack(T data) \u00b6 public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } addHelper ( size , data ); } - \u23f1\ufe0f Time Complexity: Amortized O(1) - \ud83d\udcad Best for: Adding elements when order doesn't matter - \u26a0\ufe0f Note: May trigger resizing of backing array addToFront(T data) \u00b6 public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } addHelper ( 0 , data ); } - \u23f1\ufe0f Time Complexity: O(n) - \u26a0\ufe0f Warning: Requires shifting all elements - \ud83d\udcad Use Case: When elements must be added at the beginning \ud83d\udee0\ufe0f Internal Helper Method (Adding) \u00b6 addHelper(int index, T data) \u00b6 @SuppressWarnings ( \"unchecked\" ) private void addHelper ( int index , T data ) { // If array is full, create new array with double capacity if ( size == backingArray . length ) { T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; int i ; // Copy elements before index for ( i = 0 ; i < index ; i ++ ) { newArray [ i ] = backingArray [ i ] ; } // Insert new element newArray [ i ] = data ; // Copy remaining elements for (; i < size ; i ++ ) { newArray [ i + 1 ] = backingArray [ i ] ; } backingArray = newArray ; } else { // Shift elements to make room for new element for ( int i = size ; i > index ; -- i ) { backingArray [ i ] = backingArray [ i - 1 ] ; } backingArray [ index ] = data ; } size ++ ; } ```` #### Removing Elements ##### removeFromBack () ```` java public T removeFromBack () { if ( size == 0 ) { throw new java . util . NoSuchElementException ( \"Cannot remove from an empty list\" ); } return removeHelper ( size - 1 ); } ```` - \u23f1\ufe0f Time Complexity : O ( 1 ) - \ud83d\udcab Most efficient removal operation - \u26a0\ufe0f Checks for empty list ##### removeFromFront () ```` java public T removeFromFront () { if ( size == 0 ) { throw new java . util . NoSuchElementException ( \"Cannot remove from an empty list\" ); } return removeHelper ( 0 ); } ```` - \u23f1\ufe0f Time Complexity : O ( n ) - \u26a0\ufe0f Requires shifting all elements - \ud83d\udcad Use sparingly due to performance cost ##### removeAtIndex ( int index ) ``` java public T removeAtIndex ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index cannot be outside the \" + \"range [0, \" + size + \")\" ); } return removeHelper ( index ); } - \u23f1\ufe0f Time Complexity: - Best Case (last element): O(1) - Average/Worst Case: O(n) - \ud83c\udfaf Purpose: Removes and returns element at specified index - \u26a0\ufe0f Validation: Checks for valid index range - \ud83d\udcab Process: 1. Validates index bounds 2. Calls removeHelper for actual removal 3. Returns removed element \ud83d\udee0\ufe0f Internal Helper Method (Removing) \u00b6 removeHelper(int index) \u00b6 private T removeHelper ( int index ) { T removed = backingArray [ index ] ; // Shift elements to fill the gap for ( int i = index ; i < size - 1 ; i ++ ) { backingArray [ i ] = backingArray [ i + 1 ] ; } backingArray [-- size ] = null ; // Clear last element and decrease size return removed ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83c\udfaf Purpose: Internal method for handling element removal and shifting - \ud83d\udcab Key Operations: 1. Element removal at specified index 2. Left-shifting remaining elements 3. Cleanup and size management Access Operations \u00b6 get(int index) \u00b6 public T get ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index cannot be outside the \" + \"range [0, \" + size + \")\" ); } return backingArray [ index ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83c\udfaf Direct index access - \u26a0\ufe0f Bounds checking included \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Add to Back O(1)* *Amortized Add to Front O(n) Requires shifting Add at Index O(n) Requires shifting Remove from Back O(1) Most efficient removal Remove from Front O(n) Requires shifting Get/Set O(1) Direct access Clear O(1) Memory reset Size O(1) Constant tracking * Amortized time complexity - occasional resizing operations are averaged over many operations \ud83d\udca1 Best Practices \u00b6 1. Initialization \u00b6 State with reasonable initial capacity Consider expected size for optimal performance 2. Usage Tips \u00b6 // Prefer adding to back when possible list . addToBack ( element ); // O(1) // Avoid frequent front operations list . addToFront ( element ); // O(n) - expensive! 3. Memory Management \u00b6 Clear references when removing elements Reset to initial capacity when clearing \ud83c\udfaf Common Use Cases \u00b6 \ud83d\udcdd Dynamic lists of elements \ud83d\udcca Buffer implementation \ud83d\udd04 Stack implementation \ud83d\udcda Collection management \u26a0\ufe0f Common Pitfalls \u00b6 Frequent front operations Not considering capacity growth Not handling null elements Ignoring bounds checking \ud83d\udd0d When to Use ArrayList \u00b6 Need dynamic sizing Frequent random access Mostly back-end operations Memory locality is important \ud83d\udeab When Not to Use ArrayList \u00b6 Frequent insertions/deletions at front/middle Fixed size is sufficient Memory is extremely constrained Need concurrent access References \u00b6 https://youtu.be/PEnFFiQe1pM?si=KfpsngEBI0gesUbC \ud83d\udcda Linked Lists \u00b6 \ud83d\udd17 Singly Linked List \u00b6 A Singly Linked List is a fundamental data structure where elements are stored in nodes, each containing data and a reference to the next node in the sequence. Unlike arrays, linked lists don't require contiguous memory allocation, making them ideal for dynamic data management. Core Characteristics \u00b6 \ud83d\udd04 Dynamic sizing (no fixed capacity) \ud83d\udcdd Sequential access pattern \ud83e\udde9 Node-based structure \ud83c\udfaf Efficient insertions and deletions at known positions \ud83d\udd0d Linear time search operations Implementation Details \u00b6 Structure \u00b6 public class LinkedList < T > { private Node < T > head ; private int size ; private static class Node < T > { private T data ; private Node < T > next ; public Node ( T data ) { this . data = data ; this . next = null ; } } } \ud83d\udd27 Core Operations & Time Complexities \u00b6 Adding Elements \u00b6 addToFront(T data) \u00b6 public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); newNode . next = head ; head = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack-like operations - \u26a0\ufe0f Edge Cases: - Null data - First element (empty list) addToBack(T data) \u00b6 public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); if ( head == null ) { head = newNode ; } else { Node < T > current = head ; while ( current . next != null ) { current = current . next ; } current . next = newNode ; } size ++ ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Queue-like operations - \u26a0\ufe0f Edge Cases: - Null data - Empty list - Consider tracking tail pointer for O(1) operation addAtIndex(int index, T data) \u00b6 public void addAtIndex ( int index , T data ) { if ( index < 0 || index > size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } if ( index == 0 ) { addToFront ( data ); return ; } Node < T > current = head ; for ( int i = 0 ; i < index - 1 ; i ++ ) { current = current . next ; } Node < T > newNode = new Node <> ( data ); newNode . next = current . next ; current . next = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Ordered insertions - \u26a0\ufe0f Edge Cases: - Invalid index - Null data - Front insertion Removing Elements \u00b6 removeFromFront() \u00b6 public T removeFromFront () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = head . data ; head = head . next ; size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element removeFromBack() \u00b6 public T removeFromBack () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } if ( size == 1 ) { T data = head . data ; head = null ; size -- ; return data ; } Node < T > current = head ; while ( current . next . next != null ) { current = current . next ; } T data = current . next . data ; current . next = null ; size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Queue operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element - Consider tail pointer optimization Access Operations \u00b6 get(int index) \u00b6 public T get ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } Node < T > current = head ; for ( int i = 0 ; i < index ; i ++ ) { current = current . next ; } return current . data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Sequential access - \u26a0\ufe0f Edge Cases: - Invalid index - Empty list \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Add to Front O(1) Constant time Add to Back O(n) Linear traversal Add at Index O(n) Traversal to index Remove from Front O(1) Constant time Remove from Back O(n) Linear traversal Get O(n) Linear traversal Size O(1) Tracked variable \ud83d\udca1 Best Practices \u00b6 1. Null Handling \u00b6 private void validateNotNull ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } } 2. Index Validation \u00b6 private void validateIndex ( int index , boolean isAdd ) { int maxIndex = isAdd ? size : size - 1 ; if ( index < 0 || index > maxIndex ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } } 3. Memory Management \u00b6 Clear references when removing nodes Consider garbage collection implications Track size for O(1) length checks \u26a0\ufe0f Common Pitfalls \u00b6 1. Losing References \u00b6 // WRONG - Lost reference to rest of list head = new Node <> ( data ); // Overwrites head reference // CORRECT - Maintain list structure Node < T > newNode = new Node <> ( data ); newNode . next = head ; head = newNode ; 2. Not Handling Edge Cases \u00b6 // WRONG - Assumes non-empty list head . next = newNode ; // CORRECT - Handle empty list if ( head == null ) { head = newNode ; } else { head . next = newNode ; } Reference \u00b6 Singly Linked List Video \ud83d\udd17 Doubly Linked List \u00b6 A Doubly Linked List is a bidirectional linked data structure where each node contains data and references to both the next and previous nodes. This bidirectional linking enables efficient traversal in both directions and simplifies certain operations compared to singly linked lists. Core Characteristics \u00b6 \ud83d\udd04 Bi-directional traversal \ud83d\udcdd Dynamic sizing \ud83c\udfaf O(1) operations at both ends \ud83d\udd0d Efficient insertions and deletions \ud83d\udcbe Higher memory usage per node Implementation Details \u00b6 Structure \u00b6 public class DoublyLinkedList < T > { private Node < T > head ; private Node < T > tail ; private int size ; private static class Node < T > { private T data ; private Node < T > next ; private Node < T > previous ; Node ( T data ) { this . data = data ; this . next = null ; this . previous = null ; } Node ( T data , Node < T > previous , Node < T > next ) { this . data = data ; this . previous = previous ; this . next = next ; } } } \ud83d\udd27 Core Operations & Time Complexities \u00b6 Adding Elements \u00b6 addToFront(T data) \u00b6 public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } head = new Node <> ( data , null , head ); if ( size == 0 ) { tail = head ; // First node is both head and tail } else { head . next . previous = head ; // Link old head back to new head } size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack-like operations, maintaining recent items - \u26a0\ufe0f Edge Cases: - Empty list - Null data - Maintaining tail reference addToBack(T data) \u00b6 public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data , tail , null ); if ( size == 0 ) { head = newNode ; } else { tail . next = newNode ; } tail = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Queue-like operations - \u26a0\ufe0f Edge Cases: - Empty list - Null data - Maintaining head reference addAtIndex(int index, T data) \u00b6 public void addAtIndex ( int index , T data ) { if ( index < 0 || index > size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } if ( index == 0 ) { addToFront ( data ); return ; } if ( index == size ) { addToBack ( data ); return ; } // Choose optimal traversal direction Node < T > current ; if ( index < size / 2 ) { // Start from head current = head ; for ( int i = 0 ; i < index - 1 ; i ++ ) { current = current . next ; } } else { // Start from tail current = tail ; for ( int i = size - 1 ; i > index ; i -- ) { current = current . previous ; } } Node < T > newNode = new Node <> ( data , current , current . next ); current . next . previous = newNode ; current . next = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Optimization: Chooses optimal traversal direction - \u26a0\ufe0f Edge Cases: - Index bounds - Null data - Front/back insertions Remove Elements \u00b6 removeFromFront() \u00b6 public T removeFromFront () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = head . data ; head = head . next ; size -- ; if ( size == 0 ) { tail = null ; } else { head . previous = null ; } return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element - Maintaining tail reference removeFromBack() \u00b6 public T removeFromBack () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = tail . data ; tail = tail . previous ; size -- ; if ( size == 0 ) { head = null ; } else { tail . next = null ; } return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Queue operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element - Maintaining head reference Access Operations \u00b6 get(int index) \u00b6 public T get ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } Node < T > current ; if ( index < size / 2 ) { current = head ; for ( int i = 0 ; i < index ; i ++ ) { current = current . next ; } } else { current = tail ; for ( int i = size - 1 ; i > index ; i -- ) { current = current . previous ; } } return current . data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Optimization: Bi-directional traversal - \u26a0\ufe0f Edge Cases: - Invalid index - Empty list \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Add to Front O(1) Constant time Add to Back O(1) Constant time with tail Add at Index O(n) Optimal traversal direction Remove from Front O(1) Constant time Remove from Back O(1) Constant time with tail Get O(n) Optimal traversal direction Size O(1) Tracked variable \ud83d\udca1 Best Practices \u00b6 1. Bi-directional Link Maintenance \u00b6 // Always update both next and previous references newNode . next = current . next ; newNode . previous = current ; current . next . previous = newNode ; current . next = newNode ; 2. Head/Tail Management \u00b6 // For single element if ( size == 1 ) { head = tail = null ; } else { // Update references appropriately } 3. Traversal Optimization \u00b6 // Choose optimal direction based on index if ( index < size / 2 ) { traverseFromHead (); } else { traverseFromTail (); } \u26a0\ufe0f Common Pitfalls \u00b6 1. Incomplete Link Updates \u00b6 // WRONG - Only updating one direction current . next = newNode ; // CORRECT - Update both directions current . next = newNode ; newNode . previous = current ; 2. Memory Leaks \u00b6 // WRONG - Leaving dangling references head = head . next ; // CORRECT - Clear all references T data = head . data ; Node < T > newHead = head . next ; head . next = null ; // Clear reference if ( newHead != null ) { newHead . previous = null ; } head = newHead ; References \u00b6 Doubly Linked List Video \ud83d\udd04 Circular Singly Linked List \u00b6 A Circular Singly Linked List is a variant of linked lists where the last node points back to the first node, creating a circle. This structure is particularly useful when I need continuous traversal or cyclic operations, like round-robin scheduling. Core Characteristics \u00b6 \ud83d\udd04 Last node connects to first node \ud83d\udcdd Sequential access pattern \ud83c\udfaf No null references \ud83d\udd0d Continuous traversal capability \ud83d\udcab Efficient for cyclic operations Implementation Details \u00b6 Structure \u00b6 public class CircularLinkedList < T > { private Node < T > tail ; // Points to last node private int size ; private static class Node < T > { T data ; Node < T > next ; Node ( T data ) { this . data = data ; this . next = null ; } } } \ud83d\udcad Why track tail instead of head? O(1) insertions at both ends Easy access to both first and last nodes More efficient for common operations \ud83d\udd27 Core Operations \u00b6 Adding Elements \u00b6 addingToFront(T data) \u00b6 public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); if ( isEmpty ()) { newNode . next = newNode ; // Points to itself tail = newNode ; } else { newNode . next = tail . next ; // Point to old first node tail . next = newNode ; // Update tail's next to new node } size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udca1 Important: Maintain circular nature - \u26a0\ufe0f Edge Cases: Empty list handling addToBack(T data) \u00b6 public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); if ( isEmpty ()) { newNode . next = newNode ; } else { newNode . next = tail . next ; // Point to first node tail . next = newNode ; // Update tail's next } tail = newNode ; // Update tail to new node size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udca1 Key Point: Tail reference makes this efficient - \u26a0\ufe0f Edge Cases: Empty list, single element Removing Elements \u00b6 removeFromFront() \u00b6 public T removeFromFront () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = tail . next . data ; // Get first node's data if ( size == 1 ) { tail = null ; } else { tail . next = tail . next . next ; // Skip first node } size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udca1 Key Point: Maintain circular structure - \u26a0\ufe0f Edge Cases: Empty list, single element removeFromBack() \u00b6 public T removeFromBack () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = tail . data ; if ( size == 1 ) { tail = null ; } else { Node < T > current = tail . next ; while ( current . next != tail ) { current = current . next ; } current . next = tail . next ; tail = current ; } size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Note: Requires traversal to find second-to-last node - \u26a0\ufe0f Edge Cases: Empty list, single element Search Operation \u00b6 public boolean contains ( T data ) { if ( isEmpty () || data == null ) { return false ; } Node < T > current = tail . next ; // Start at first node do { if ( data . equals ( current . data )) { return true ; } current = current . next ; } while ( current != tail . next ); return false ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Important: Use do-while for circular traversal - \u26a0\ufe0f Handle: Null data, empty list \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Add to Front O(1) Constant time with tail reference Add to Back O(1) Constant time with tail reference Remove from Front O(1) Constant time operation Remove from Back O(n) Requires traversal Search O(n) Linear traversal Size O(1) Tracked variable \ud83d\udca1 Best Practices \u00b6 1. Circular Reference Maintenance \u00b6 // Always ensure last node points to first tail . next = tail . next . next ; // When removing newNode . next = tail . next ; // When adding 2. Empty List Handling \u00b6 if ( isEmpty ()) { // New node points to itself newNode . next = newNode ; tail = newNode ; } 3. Single Element Handling \u00b6 if ( size == 1 ) { tail = null ; // For removal // OR tail = newNode ; // For insertion } \u26a0\ufe0f Common Pitfalls \u00b6 1. Infinite Loops \u00b6 // WRONG - May loop forever while ( current . next != null ) { // Never true in circular list current = current . next ; } // CORRECT do { current = current . next ; } while ( current != tail . next ); 2. Lost Circular Reference \u00b6 // WRONG - Loses circular structure tail . next = newNode ; // CORRECT - Maintains circular structure newNode . next = tail . next ; tail . next = newNode ; Reference \u00b6 Circular Linked List Playlist \ud83d\udcda Stack \u00b6 Introduction \u00b6 A Stack is a linear data structure that follows the LIFO (Last In First Out) principle. Like a stack of plates, elements are added and removed from the same end, called the top of the stack. This fundamental data structure is ideal for scenarios where we need strict order control over our operations. Core Characteristics \u00b6 \ud83d\udce5 LIFO (Last In, First Out) principle \ud83c\udfaf Single point of access (top) \ud83d\udccf Dynamic sizing through array resizing \ud83d\udd04 Ordered operations \u26a1 Constant time operations (amortized) Implementation Details \u00b6 Structure \u00b6 public class Stack < T > { // Default capacity when no size is specified private static final int DEFAULT_CAPACITY = 10 ; // Internal array to store elements private T [] backingArray ; // Keep track of the next available position private int size ; // Constructor with default capacity @SuppressWarnings ( \"unchecked\" ) public Stack () { backingArray = ( T [] ) new Object [ DEFAULT_CAPACITY ] ; size = 0 ; } // Constructor with specified initial capacity @SuppressWarnings ( \"unchecked\" ) public Stack ( int initialCapacity ) { if ( initialCapacity < 0 ) { throw new IllegalArgumentException ( \"Initial capacity cannot be negative\" ); } backingArray = ( T [] ) new Object [ initialCapacity ] ; size = 0 ; } } \ud83d\udd27 Core Operations \u00b6 Push Operation \u00b6 public void push ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Cannot push null data\" ); } // Check if we need to resize if ( size == backingArray . length ) { resize (); } // Add element and increment size backingArray [ size ++] = data ; } @SuppressWarnings ( \"unchecked\" ) private void resize () { T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ i ] ; } backingArray = newArray ; } \u23f1\ufe0f Time Complexity: O(1) amortized - \ud83d\udcad When to Use: Adding new elements to the stack - \u26a0\ufe0f Key Points: - Handles null check - Automatic resizing - Maintains LIFO order Pop Operation \u00b6 public T pop () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Cannot pop from empty stack\" ); } // Retrieve element and decrement size T data = backingArray [-- size ] ; backingArray [ size ] = null ; // Clear reference for garbage collection return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Removing and retrieving the most recently added element - \u26a0\ufe0f Key Points: - Checks for empty stack - Cleans up references - Maintains LIFO order Peek Operation \u00b6 public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Cannot peek empty stack\" ); } return backingArray [ size - 1 ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Viewing top element without removal - \u26a0\ufe0f Key Points: - No modification to stack - Preserves state - Checks for empty stack Utility Operations \u00b6 // Check if stack is empty public boolean isEmpty () { return size == 0 ; } // Get current number of elements public int size () { return size ; } // Clear all elements @SuppressWarnings ( \"unchecked\" ) public void clear () { backingArray = ( T [] ) new Object [ DEFAULT_CAPACITY ] ; size = 0 ; } \ud83d\udcca Performance Summary \u00b6 \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Push O(1)* Amortized for resizing Pop O(1) Constant time Peek O(1) Constant time isEmpty O(1) Constant time Size O(1) Constant time Clear O(1) New array allocation * Amortized time complexity accounts for occasional resizing operations \ud83d\udca1 Best Practices \u00b6 1. Memory Management \u00b6 // Always clear references when removing elements public T pop () { T data = backingArray [-- size ] ; backingArray [ size ] = null ; // Clear reference return data ; } 2. Capacity Handling \u00b6 // Consider shrinking array when usage is low private void shrinkIfNeeded () { if ( size > 0 && size < backingArray . length / 4 ) { resize ( backingArray . length / 2 ); } } 3. Null Checking \u00b6 // Always validate input public void push ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } // push implementation } \u26a0\ufe0f Common Pitfalls \u00b6 1. Memory Leaks \u00b6 // WRONG - Memory leak public T pop () { return backingArray [-- size ] ; // Reference still held } // CORRECT - Clear reference public T pop () { T data = backingArray [-- size ] ; backingArray [ size ] = null ; // Clear reference return data ; } 2. Bound Checking \u00b6 // WRONG - No empty check public T peek () { return backingArray [ size - 1 ] ; // Possible IndexOutOfBoundsException } // CORRECT - With empty check public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Stack is empty\" ); } return backingArray [ size - 1 ] ; } \ud83c\udfaf Common Use Cases \u00b6 1. Function Call Stack \u00b6 Stack < FunctionCall > callStack = new Stack <> (); callStack . push ( new FunctionCall ( \"main\" )); callStack . push ( new FunctionCall ( \"helper\" )); // Current function is helper callStack . pop (); // Return to main 2. Expression Evaluation \u00b6 Stack < Character > parentheses = new Stack <> (); for ( char c : expression . toCharArray ()) { if ( c == '(' ) { parentheses . push ( c ); } else if ( c == ')' ) { if ( ! parentheses . isEmpty ()) { parentheses . pop (); } else { // Unmatched closing parenthesis } } } 3. Undo/Redo Operations \u00b6 Stack < Command > undoStack = new Stack <> (); Stack < Command > redoStack = new Stack <> (); void executeCommand ( Command cmd ) { cmd . execute (); undoStack . push ( cmd ); redoStack . clear (); // Clear redo history } References \u00b6 Stack Introduction Stack Implementation \ud83c\udfaf Queue \u00b6 Introduction \u00b6 A Queue is a linear data structure following the FIFO (First In, First Out) principle. Using a circular array implementation allows for efficient space usage and constant time operations by reusing array spaces that have been dequeued. Core Characteristics \u00b6 \ud83d\udce5 FIFO (First In, First Out) ordering \ud83d\udd04 Circular array implementation \ud83d\udccf Dynamic sizing \u26a1 Constant time operations (amortized) \ud83c\udfaf Space efficient Implementation Details \u00b6 Structure \u00b6 public class Queue < T > { private T [] backingArray ; private int front ; // Index of the front element private int size ; // Number of elements in queue private static final int INITIAL_CAPACITY = 10 ; @SuppressWarnings ( \"unchecked\" ) public Queue () { backingArray = ( T [] ) new Object [ INITIAL_CAPACITY ] ; front = 0 ; size = 0 ; } } \ud83d\udd27 Core Operations \u00b6 Enqueue Operation \u00b6 public void enqueue ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Cannot enqueue null data\" ); } // Check if we need to resize if ( size == backingArray . length ) { resize (); } // Calculate rear index using modulo for circular behavior int rear = ( front + size ) % backingArray . length ; backingArray [ rear ] = data ; size ++ ; } @SuppressWarnings ( \"unchecked\" ) private void resize () { T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; // Copy elements in order, starting from front for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ ( front + i ) % backingArray . length ] ; } backingArray = newArray ; front = 0 ; // Reset front to beginning of new array } - \u23f1\ufe0f Time Complexity: O(1) amortized - \ud83d\udcad When to Use: Adding elements to queue - \u26a0\ufe0f Key Points: - Handles null check - Circular indexing with modulo - Resizes when full Dequeue Operation \u00b6 public T dequeue () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } T data = backingArray [ front ] ; backingArray [ front ] = null ; // Help GC front = ( front + 1 ) % backingArray . length ; size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Removing elements from front - \u26a0\ufe0f Key Points: - Handles empty queue - Maintains circular structure - Cleans up references Peek Operation \u00b6 public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } return backingArray [ front ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Examining front element - \u26a0\ufe0f Key Points: - No modification to queue - Front element access Utility Operations \u00b6 public boolean isEmpty () { return size == 0 ; } public int size () { return size ; } @SuppressWarnings ( \"unchecked\" ) public void clear () { backingArray = ( T [] ) new Object [ INITIAL_CAPACITY ] ; front = 0 ; size = 0 ; } \ud83d\udcca Performance Summary \u00b6 \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Enqueue O(1)* Amortized for resizing Dequeue O(1) Constant time Peek O(1) Constant time isEmpty O(1) Constant time Size O(1) Constant time Clear O(1) New array allocation * Amortized time complexity accounts for occasional resizing operations \ud83d\udca1 Best Practices \u00b6 1. Circular Index Calculation \u00b6 // Calculate next index with modulo private int getNextIndex ( int currentIndex ) { return ( currentIndex + 1 ) % backingArray . length ; } // Calculate rear index private int getRearIndex () { return ( front + size ) % backingArray . length ; } 2. Resizing Strategy \u00b6 private void resize () { // Double size for amortized O(1) T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; // Copy in order from front to rear for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ ( front + i ) % backingArray . length ] ; } front = 0 ; // Reset front after resize backingArray = newArray ; } 3. Memory Management \u00b6 public T dequeue () { T data = backingArray [ front ] ; backingArray [ front ] = null ; // Clear reference front = ( front + 1 ) % backingArray . length ; size -- ; return data ; } \u26a0\ufe0f Common Pitfalls \u00b6 1. Incorrect Circular Indexing \u00b6 // WRONG - May cause overflow rear = rear + 1 ; if ( rear == backingArray . length ) rear = 0 ; // CORRECT - Use modulo rear = ( rear + 1 ) % backingArray . length ; 2. Resizing Issues \u00b6 // WRONG - Doesn't maintain order System . arraycopy ( backingArray , 0 , newArray , 0 , backingArray . length ); // CORRECT - Maintains order from front for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ ( front + i ) % backingArray . length ] ; } \ud83c\udfaf Common Use Cases \u00b6 1. Task Scheduling \u00b6 Queue < Task > taskQueue = new Queue <> (); taskQueue . enqueue ( new Task ( \"Process payment\" )); taskQueue . enqueue ( new Task ( \"Send email\" )); while ( ! taskQueue . isEmpty ()) { Task nextTask = taskQueue . dequeue (); processTask ( nextTask ); } 2. BFS Implementation \u00b6 public void bfs ( Node root ) { Queue < Node > queue = new Queue <> (); queue . enqueue ( root ); while ( ! queue . isEmpty ()) { Node current = queue . dequeue (); for ( Node child : current . getChildren ()) { queue . enqueue ( child ); } } } 3. Buffer Implementation \u00b6 public class Buffer < T > { private Queue < T > queue = new Queue <> (); private final int capacity ; public void write ( T data ) { if ( queue . size () < capacity ) { queue . enqueue ( data ); } } public T read () { return queue . isEmpty () ? null : queue . dequeue (); } } References \u00b6 Queue Introduction Queue Implementation \ud83c\udf33 Tree-Based Structures \u00b6 \ud83d\udcca Priority Queue \u00b6 Introduction \u00b6 A Priority Queue is an advanced queue that orders elements by their priority rather than insertion order. It's commonly implemented using a heap data structure, typically a min-heap or max-heap. In this implementation, we'll focus on a min-heap based priority queue where lower values have higher priority. Core Characteristics \u00b6 \ud83d\udcc8 Priority-based ordering \ud83c\udf33 Heap-based implementation \ud83d\udccf Dynamic sizing \ud83d\udd04 Self-balancing structure \u26a1 Logarithmic time operations Implementation Details \u00b6 Structure \u00b6 public class PriorityQueue < T extends Comparable <? super T >> { // Initial capacity of the priority queue private static final int INITIAL_CAPACITY = 13 ; // Backing array for the heap private T [] backingArray ; // Number of elements in the queue private int size ; @SuppressWarnings ( \"unchecked\" ) public PriorityQueue () { backingArray = ( T [] ) new Comparable [ INITIAL_CAPACITY ] ; size = 0 ; } } \ud83d\udd27 Core Operations \u00b6 Add Operation \u00b6 public void add ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Cannot add null data\" ); } // Resize if necessary if ( size + 1 == backingArray . length ) { resize (); } // Add element to the end and restore heap property backingArray [++ size ] = data ; upHeap ( size ); } private void upHeap ( int index ) { while ( index > 1 && backingArray [ index ] . compareTo ( backingArray [ index / 2 ] ) < 0 ) { swap ( backingArray , index , index / 2 ); index = index / 2 ; } } - \u23f1\ufe0f Time Complexity: O(log n) - \ud83d\udcad When to Use: Adding new elements with priority - \u26a0\ufe0f Key Points: - Maintains heap property - Handles resizing - Null checking Remove Operation \u00b6 public T remove () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } T removed = backingArray [ 1 ] ; backingArray [ 1 ] = backingArray [ size ] ; backingArray [ size --] = null ; if ( ! isEmpty ()) { downHeap ( 1 ); } return removed ; } private void downHeap ( int index ) { while ( 2 * index <= size ) { int j = 2 * index ; if ( j < size && backingArray [ j ] . compareTo ( backingArray [ j + 1 ] ) > 0 ) { j ++ ; } if ( backingArray [ index ] . compareTo ( backingArray [ j ] ) <= 0 ) { break ; } swap ( backingArray , index , j ); index = j ; } } - \u23f1\ufe0f Time Complexity: O(log n) - \ud83d\udcad When to Use: Removing highest priority element - \u26a0\ufe0f Key Points: - Maintains heap order - Handles empty case - Cleans references Peek Operation \u00b6 public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } return backingArray [ 1 ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Viewing highest priority element - \u26a0\ufe0f Key Points: - No modification to structure - Empty check \ud83d\udcca Performance Summary \u00b6 \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Add/Offer O(log n) Requires upheap Remove/Poll O(log n) Requires downheap Peek O(1) Constant time isEmpty O(1) Constant time Size O(1) Constant time Clear O(1) New array allocation ### \ud83d\udca1 Best Practices #### 1. Maintain Heap Property private void swap ( T [] arr , int i , int j ) { T temp = arr [ i ] ; arr [ i ] = arr [ j ] ; arr [ j ] = temp ; } private int parent ( int index ) { return index / 2 ; } private int leftChild ( int index ) { return 2 * index ; } private int rightChild ( int index ) { return 2 * index + 1 ; } #### 2. Efficient Resizing @SuppressWarnings ( \"unchecked\" ) private void resize () { T [] newArray = ( T [] ) new Comparable [ backingArray . length * 2 ] ; for ( int i = 1 ; i <= size ; i ++ ) { newArray [ i ] = backingArray [ i ] ; } backingArray = newArray ; } #### 3. Handle Special Cases public boolean isEmpty () { return size == 0 ; } @SuppressWarnings ( \"unchecked\" ) public void clear () { backingArray = ( T [] ) new Comparable [ INITIAL_CAPACITY ] ; size = 0 ; } ### \u26a0\ufe0f Common Pitfalls #### 1. Index Management // WRONG - Using 0-based indexing private int parent ( int i ) { return ( i - 1 ) / 2 ; } // CORRECT - Using 1-based indexing private int parent ( int i ) { return i / 2 ; } #### 2. Comparator Consistency // WRONG - Inconsistent comparison if ( a . someValue () < b . someValue ()) { swap ( a , b ); } // CORRECT - Use compareTo if ( a . compareTo ( b ) < 0 ) { swap ( a , b ); } ### \ud83c\udfaf Common Use Cases #### 1. Task Scheduling class Task implements Comparable < Task > { private int priority ; private String description ; @Override public int compareTo ( Task other ) { return Integer . compare ( this . priority , other . priority ); } } PriorityQueue < Task > taskQueue = new PriorityQueue <> (); taskQueue . add ( new Task ( 1 , \"High Priority\" )); taskQueue . add ( new Task ( 3 , \"Low Priority\" )); #### 2. Dijkstra's Algorithm PriorityQueue < Node > pq = new PriorityQueue <> (( a , b ) -> Integer . compare ( a . distance , b . distance )); pq . add ( source ); while ( ! pq . isEmpty ()) { Node current = pq . remove (); // Process node } #### 3. Event Processing class Event implements Comparable < Event > { private long timestamp ; @Override public int compareTo ( Event other ) { return Long . compare ( this . timestamp , other . timestamp ); } } PriorityQueue < Event > events = new PriorityQueue <> (); events . add ( new Event ( System . currentTimeMillis ())); References \u00b6 Priority Queue Introduction Priority Queue Min Heaps and Max Heaps Priority Queue Adding Elements Priority Queue Removing Elements \ud83c\udf33 Binary Tree \u00b6 Introduction \u00b6 A Binary Tree is a hierarchical, non-linear data structure where each node has at most two children, referred to as left child and right child. Unlike arrays or linked lists that store data sequentially, Binary Trees allow for representing hierarchical relationships between elements. Core Characteristics \u00b6 \ud83c\udf3f Each node has at most two children \ud83d\udd1d Single root node \ud83d\udcca Hierarchical structure \ud83d\udd04 Recursive nature \ud83c\udfaf Multiple traversal options Implementation Details \u00b6 Structure \u00b6 public class BinaryTree < T > { private Node < T > root ; private int size ; private static class Node < T > { T data ; Node < T > left ; Node < T > right ; Node ( T data ) { this . data = data ; this . left = null ; this . right = null ; } } public BinaryTree () { root = null ; size = 0 ; } } \ud83d\udd27 Core Operations \u00b6 Traversal Operations \u00b6 // InOrder Traversal (Left, Root, Right) public void inOrderTraversal ( Node < T > node ) { if ( node != null ) { inOrderTraversal ( node . left ); process ( node . data ); inOrderTraversal ( node . right ); } } // PreOrder Traversal (Root, Left, Right) public void preOrderTraversal ( Node < T > node ) { if ( node != null ) { process ( node . data ); preOrderTraversal ( node . left ); preOrderTraversal ( node . right ); } } // PostOrder Traversal (Left, Right, Root) public void postOrderTraversal ( Node < T > node ) { if ( node != null ) { postOrderTraversal ( node . left ); postOrderTraversal ( node . right ); process ( node . data ); } } // Level Order Traversal (BFS) public void levelOrderTraversal () { if ( root == null ) return ; Queue < Node < T >> queue = new LinkedList <> (); queue . offer ( root ); while ( ! queue . isEmpty ()) { Node < T > current = queue . poll (); process ( current . data ); if ( current . left != null ) queue . offer ( current . left ); if ( current . right != null ) queue . offer ( current . right ); } } - \u23f1\ufe0f Time Complexity: O(n) for all traversals - \ud83d\udcad When to Use: Different traversal orders for different needs - \u26a0\ufe0f Key Points: Each traversal visits all nodes exactly once Insertion Operation \u00b6 public void insert ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } if ( root == null ) { root = new Node <> ( data ); size ++ ; return ; } // Level-order insertion Queue < Node < T >> queue = new LinkedList <> (); queue . offer ( root ); while ( ! queue . isEmpty ()) { Node < T > current = queue . poll (); if ( current . left == null ) { current . left = new Node <> ( data ); size ++ ; return ; } else { queue . offer ( current . left ); } if ( current . right == null ) { current . right = new Node <> ( data ); size ++ ; return ; } else { queue . offer ( current . right ); } } } \u23f1\ufe0f Time Complexity: O(n) \ud83d\udcad When to Use: Adding new nodes to the tree \u26a0\ufe0f Key Points: Level-order insertion maintains tree balance Search Operation \u00b6 public boolean contains ( T data ) { return searchHelper ( root , data ); } private boolean searchHelper ( Node < T > node , T data ) { if ( node == null ) return false ; if ( node . data . equals ( data )) return true ; return searchHelper ( node . left , data ) || searchHelper ( node . right , data ); } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad When to Use: Finding elements in the tree - \u26a0\ufe0f Key Points: Must traverse potentially entire tree \ud83d\udcca Performance Summary \u00b6 \ud83d\udcca Performance Summary \u00b6 Operation Time Complexity Notes Insertion O(n) Level-order insertion Search O(n) Worst case traversal Deletion O(n) Find and reorganize Traversal O(n) All traversal types Height O(n) Must visit all nodes Size O(1) Maintained variable isEmpty O(1) Check root null \ud83d\udca1 Best Practices \u00b6 1. Proper Node Handling \u00b6 private void validate ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } } 2. Traversal Selection \u00b6 // Use appropriate traversal for the task // InOrder: Sorted sequence in BST // PreOrder: Copy/serialize tree // PostOrder: Delete tree/calculate size // LevelOrder: Level-based processing 3. Memory Management \u00b6 public void clear () { root = null ; // Allow GC to clean up size = 0 ; } \u26a0\ufe0f Common Pitfalls \u00b6 1. Not Handling Null Cases \u00b6 // WRONG public void process ( Node < T > node ) { process ( node . left ); // NPE if node is null } // CORRECT public void process ( Node < T > node ) { if ( node == null ) return ; process ( node . left ); } 2. Improper Traversal Choice \u00b6 // WRONG - Using inOrder for level-based processing // CORRECT - Use levelOrder for level-based operations public void printLevelByLevel () { levelOrderTraversal (); } \ud83c\udfaf Common Use Cases \u00b6 1. File System Representation \u00b6 class FileNode < T > extends Node < T > { boolean isDirectory ; // File system specific operations } 2. Expression Trees \u00b6 class ExpressionNode < T > extends Node < T > { boolean isOperator ; public double evaluate () { // Evaluation logic } } 3. Decision Trees \u00b6 class DecisionNode < T > extends Node < T > { boolean isLeaf ; public T decide ( Input input ) { // Decision logic } } References \u00b6 Binary Tree Data Structure \ud83c\udf33 Binary Search Tree \u00b6 Introduction \u00b6 A Binary Search Tree (BST) is a binary tree that maintains an ordering property: for each node, all elements in its left subtree are less than the node's value, and all elements in its right subtree are greater. This property makes BSTs efficient for searching, inserting, and deleting elements. Core Characteristics \u00b6 \ud83d\udcca Ordered structure \ud83d\udd0d Efficient searching \ud83c\udfaf Dynamic operations \ud83c\udf3f Binary tree properties \u2696\ufe0f Balance affects performance Implementation Details \u00b6 Structure \u00b6 public class BST < T extends Comparable <? super T >> { private BSTNode < T > root ; private int size ; private static class BSTNode < T > { T data ; BSTNode < T > left ; BSTNode < T > right ; BSTNode ( T data ) { this . data = data ; left = null ; right = null ; } } } \ud83d\udd27 Core Operations \u00b6 Add Operation \u00b6 public void add ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } root = addHelper ( data , root ); } private BSTNode < T > addHelper ( T data , BSTNode < T > node ) { if ( node == null ) { size ++ ; return new BSTNode <> ( data ); } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { node . left = addHelper ( data , node . left ); } else if ( compare > 0 ) { node . right = addHelper ( data , node . right ); } return node ; } - \u23f1\ufe0f Time Complexity: O(log n) average, O(n) worst case - \ud83d\udcad When to Use: Inserting new elements while maintaining order - \u26a0\ufe0f Key Points: - Maintains BST property - Handles duplicates - Recursive implementation Remove Operation \u00b6 public T remove ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } BSTNode < T > dummy = new BSTNode <> ( null ); root = removeHelper ( data , root , dummy ); return dummy . data ; } private BSTNode < T > removeHelper ( T data , BSTNode < T > node , BSTNode < T > dummy ) { if ( node == null ) { throw new NoSuchElementException ( \"Data not found\" ); } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { node . left = removeHelper ( data , node . left , dummy ); } else if ( compare > 0 ) { node . right = removeHelper ( data , node . right , dummy ); } else { dummy . data = node . data ; size -- ; if ( node . left == null ) { return node . right ; } else if ( node . right == null ) { return node . left ; } else { BSTNode < T > successor = findSuccessor ( node . right ); node . data = successor . data ; node . right = removeHelper ( successor . data , node . right , dummy ); } } return node ; } - \u23f1\ufe0f Time Complexity: O(log n) average, O(n) worst case - \ud83d\udcad When to Use: Removing elements while maintaining order - \u26a0\ufe0f Key Points: - Three cases: leaf, one child, two children - Uses successor for two-child case - Maintains BST property Search Operation \u00b6 public T get ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } BSTNode < T > node = getHelper ( data , root ); if ( node == null ) { throw new NoSuchElementException ( \"Data not found\" ); } return node . data ; } private BSTNode < T > getHelper ( T data , BSTNode < T > node ) { if ( node == null ) { return null ; } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { return getHelper ( data , node . left ); } else if ( compare > 0 ) { return getHelper ( data , node . right ); } return node ; } - \u23f1\ufe0f Time Complexity: O(log n) average, O(n) worst case - \ud83d\udcad When to Use: Finding elements in the tree - \u26a0\ufe0f Key Points: - Uses comparisons for direction - Returns stored data - Handles not found case Traversal Operations \u00b6 // In-order traversal (sorted order) public List < T > inorder () { List < T > result = new ArrayList <> (); inorderHelper ( root , result ); return result ; } private void inorderHelper ( BSTNode < T > node , List < T > result ) { if ( node != null ) { inorderHelper ( node . left , result ); result . add ( node . data ); inorderHelper ( node . right , result ); } } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad When to Use: Getting elements in sorted order - \u26a0\ufe0f Key Points: - In-order gives sorted sequence - Pre-order for copying tree - Post-order for deletion \ud83d\udcca Performance Summary \u00b6 Operation Average Case Worst Case Notes Insert O(log n) O(n) Unbalanced case Remove O(log n) O(n) Unbalanced case Search O(log n) O(n) Unbalanced case Traversal O(n) O(n) Visits all nodes Height O(1) O(1) Cached value Size O(1) O(1) Maintained count \ud83d\udca1 Best Practices \u00b6 1. Balance Maintenance \u00b6 // Consider using self-balancing variants for better performance guarantees // AVL or Red-Black trees for automatic balancing 2. Comparison Handling \u00b6 // Use compareTo consistently int compare = data . compareTo ( node . data ); if ( compare < 0 ) { // Go left } else if ( compare > 0 ) { // Go right } 3. Null Handling \u00b6 // Always validate input if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } \u26a0\ufe0f Common Pitfalls \u00b6 1. Unbalanced Trees \u00b6 // WRONG - Adding sorted data creates linear structure bst . add ( 1 ); bst . add ( 2 ); bst . add ( 3 ); // Creates right-skewed tree // BETTER - Balance the tree or use self-balancing variant 2. Memory Management \u00b6 // WRONG - Memory leak in remove node = null ; // Only removes reference // CORRECT - Clean all references node . left = null ; node . right = null ; node . data = null ; node = null ; \ud83c\udfaf Common Use Cases \u00b6 1. Dictionary Implementation \u00b6 BST < String > dictionary = new BST <> (); dictionary . add ( \"apple\" ); dictionary . add ( \"banana\" ); // Fast lookups: O(log n) average 2. Priority Management \u00b6 BST < Task > tasks = new BST <> (); tasks . add ( new Task ( 1 , \"High Priority\" )); tasks . add ( new Task ( 2 , \"Medium Priority\" )); // Natural ordering of tasks 3. Symbol Tables \u00b6 BST < Symbol > symbolTable = new BST <> (); symbolTable . add ( new Symbol ( \"x\" , 10 )); symbolTable . add ( new Symbol ( \"y\" , 20 )); // Efficient symbol lookup References \u00b6 Binary Search Trees Binary Search Tree Introduction Binary Search Tree Insertion Binary Search Tree Removal Binary Search Tree Traversal \ud83c\udf32 Advanced Tree-Based Structures \u00b6 \ud83c\udf33 AVL Trees \u00b6 An AVL Tree is a self-balancing bin tree where the heights of the left and right subtrees of any node differ by at most one. This balance ot ensures that the tree remains approximately balanced during insertion deletions, maintaining O(log n) time complexity for all operations. Core Characteristics \u00b6 \ud83d\udd04 Self-balancing mechanism \ud83d\udccf Height tracking \u2696\ufe0f Balance factor management \ud83c\udfaf BST properties maintained \ud83d\udd0d Guaranteed O(log n) operations Implementation Details \u00b6 Structure \u00b6 public class AVLTree < T extends Comparable <? super T >> { AVLNode < T > root ; private int size ; private static class AVLNode < T > { T data ; AVLNode < T > left ; AVLNode < T > right ; int height ; int balanceFactor ; AVLNode ( T data ) { this . data = data ; this . height = 0 ; this . balanceFactor = 0 ; } } } Node Properties \u00b6 data : Stores the actual value/element left : Reference to left child n lement etil ri clrenco right child node height : Distance to the furthest leaf in its subtree balanceFactor : Difference between left and right subtree heights \ud83d\udd27 Core Operations \u00b6 Balance Helper Methods private int height ( AVLNode < T > node ) { return node == null ? - 1 : node . height ; } private void updateHeightAndBF ( AVLNode < T > node ) { int leftHeight = height ( node . left ); int rightHeight = height ( node . right ); node . height = Math . max ( leftHeight , rightHeight ) + 1 ; node . balanceFactor = leftHeight - rightHeight ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: After any structural changes - \u26a0\ufe0f Key Points: - Height of null node is -1 - Balance factor = leftHeight - rightHeight - Must update after rotations Rotation Operations \u00b6 private AVLNode < T > rotateLeft ( AVLNode < T > node ) { AVLNode < T > newRoot = node . right ; node . right = newRoot . left ; newRoot . left = node ; updateHeightAndBF ( node ); updateHeightAndBF ( newRoot ); return newRoot ; } private AVLNode < T > rotateRight ( AVLNode < T > node ) { AVLNode < T > newRoot = node . left ; node . left = newRoot . right ; newRoot . right = node ; updateHeightAndBF ( node ); updateHeightAndBF ( newRoot ); return newRoot ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Rebalancing after insertions/deletions - \u26a0\ufe0f Key Points: - Update heights after rotation - Maintain BST properties - Return new root of subtree Balance Operation \u00b6 private AVLNode < T > balance ( AVLNode < T > node ) { updateHeightAndBF ( node ); if ( node . balanceFactor < - 1 ) { // Right heavy if ( node . right . balanceFactor > 0 ) { // Right-Left case node . right = rotateRight ( node . right ); } return rotateLeft ( node ); } else if ( node . balanceFactor > 1 ) { // Left heavy if ( node . left . balanceFactor < 0 ) { // Left-Right case node . left = rotateLeft ( node . left ); } return rotateRight ( node ); } return node ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: After modifications that might affect balance - \u26a0\ufe0f Key Points: - Handles all four rotation cases - Updates height before checking balance - Returns balanced subtree root Add Operation \u00b6 public void add ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } root = addHelper ( data , root ); } private AVLNode < T > addHelper ( T data , AVLNode < T > node ) { if ( node == null ) { size ++ ; return new AVLNode <> ( data ); } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { node . left = addHelper ( data , node . left ); } else if ( compare > 0 ) { node . right = addHelper ( data , node . right ); } return balance ( node ); } - \u23f1\ufe0f Time Complexity: O(log n) - \ud83d\udcad When to Use: Adding new elements - \u26a0\ufe0f Key Points: - BST properties maintained - Auto-balancing after insertion - Uses pointer reinforcement \ud83d\udcca Performance Summary \u00b6 Operation Average Case Worst Case Notes Add O(log n) O(log n) Includes rebalancing Remove O(log n) O(log n) Includes rebalancing Search O(log n) O(log n) Same as BST Rotation O(1) O(1) Height updates included Balance O(1) O(1) Maximum two rotations Height O(1) O(1) Cached in node \ud83c\udfaf Visualization of Rotations \u00b6 Left Rotation \u00b6 Before: After: A B \\ / \\ B => A C \\ C Right Rotation \u00b6 Before: After: C B / / \\ B => A C / A Double Rotation (Left-Right) \u00b6 Before: Middle: After: C C B / / / \\ A => B => A C \\ / B A Double Rotation (Right-Left) \u00b6 Before: Middle: After: A A B \\ \\ / \\ C => B => A C / \\ B C \ud83d\udca1 Best Practices \u00b6 1. Height Management \u00b6 // Always update heights bottom-up updateHeightAndBF ( node ); if ( node . parent != null ) { updateHeightAndBF ( node . parent ); } 2. Balance Factor Checks \u00b6 // Check both balance factor and height if ( Math . abs ( node . balanceFactor ) > 1 ) { return balance ( node ); } 3. Rotation Selection \u00b6 // Clear conditions for rotation type if ( node . balanceFactor > 1 ) { // Left heavy if ( node . left . balanceFactor < 0 ) { // Left-Right case node . left = rotateLeft ( node . left ); } return rotateRight ( node ); } \u26a0\ufe0f Common Pitfalls \u00b6 1. Incorrect Height Updates \u00b6 // WRONG - Not updating ancestor heights node = balance ( node ); // CORRECT - Update all affected nodes node = balance ( node ); updateAncestorHeights ( node ); 2. Balance Factor Calculation \u00b6 // WRONG - Swapped height difference balanceFactor = rightHeight - leftHeight ; // CORRECT balanceFactor = leftHeight - rightHeight ; References \u00b6 AVL Trees Simply Explained Red-Black Trees in 4 min 2-3 Trees K-D Trees M-Ary Trees \ud83c\udfaf Hash-Based Structures \u00b6 #\ufe0f\u20e3 HashMaps \u00b6 A HashMap is a data structure that implements the Map ADT, storing key-value pairs for O(1) average-case access time. This implementation uses separate chaining for collision resolution, where collisions are handled by maintaining linked lists at each array index. Core Characteristics \u00b6 \ud83d\udd11 Unique Key Mapping Each key can map to only one value Keys must be immutable Values can be modified or duplicated Perfect for one-to-one relationships \u26a1 Constant-Time Operations O(1) average case for insertions O(1) average case for retrievals O(1) average case for deletions Performance dependent on hash function quality \ud83c\udfaf Hash Distribution Converts keys to array indices via hashing Uses hashCode() method for initial hash Compresses hash to fit array bounds Aims for uniform distribution of keys \u26d3\ufe0f Collision Management Handles key collisions using linked lists Each array index can store multiple entries Entries in same bucket form a chain Search within chain is O(n) worst case \u2696\ufe0f Load Factor Control Maintains ratio of size to capacity Typically keeps load factor below 0.67 Triggers resizing when threshold reached Prevents performance degradation Uses prime number capacities for better distribution \ud83d\udd04 Dynamic Resizing Doubles capacity when load factor exceeded Adds 1 to ensure prime capacity Rehashes all existing entries Maintains performance characteristics Implementation Details \u00b6 Node Structure \u00b6 private static class Node < K , V > { K key ; V value ; Node < K , V > next ; Node ( K key , V value ) { this . key = key ; this . value = value ; this . next = null ; } } Basic Class Structure \u00b6 public class HashMap < K , V > { private Node < K , V >[] table ; private int size ; private static final int INITIAL_CAPACITY = 13 ; // Prime number private static final double MAX_LOAD_FACTOR = 0.67 ; @SuppressWarnings ( \"unchecked\" ) public HashMap () { table = ( Node < K , V >[] ) new Node [ INITIAL_CAPACITY ] ; size = 0 ; } } Core Operations \u00b6 Put Operation \u00b6 public V put ( K key , V value ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } // Check if resize is needed if (( double ) ( size + 1 ) / table . length > MAX_LOAD_FACTOR ) { resize (); } int index = getIndex ( key ); // Check if key already exists Node < K , V > current = table [ index ] ; while ( current != null ) { if ( current . key . equals ( key )) { V oldValue = current . value ; current . value = value ; return oldValue ; } current = current . next ; } // Add new node at the beginning of the chain Node < K , V > newNode = new Node <> ( key , value ); newNode . next = table [ index ] ; table [ index ] = newNode ; size ++ ; return null ; } private int getIndex ( K key ) { return Math . abs ( key . hashCode () % table . length ); } Get Operation \u00b6 public V get ( K key ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } int index = getIndex ( key ); Node < K , V > current = table [ index ] ; while ( current != null ) { if ( current . key . equals ( key )) { return current . value ; } current = current . next ; } return null ; } Remove Operation \u00b6 public V remove ( K key ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } int index = getIndex ( key ); Node < K , V > current = table [ index ] ; Node < K , V > prev = null ; while ( current != null ) { if ( current . key . equals ( key )) { if ( prev == null ) { table [ index ] = current . next ; } else { prev . next = current . next ; } size -- ; return current . value ; } prev = current ; current = current . next ; } return null ; } Resize Operation \u00b6 @SuppressWarnings ( \"unchecked\" ) private void resize () { int newCapacity = ( 2 * table . length ) + 1 ; // Prime number Node < K , V >[] oldTable = table ; table = ( Node < K , V >[] ) new Node [ newCapacity ] ; size = 0 ; // Rehash all existing entries for ( Node < K , V > head : oldTable ) { Node < K , V > current = head ; while ( current != null ) { put ( current . key , current . value ); current = current . next ; } } } Performance Characteristics \u00b6 Operation Average Case Worst Case Notes Put O(1) O(n) When chain degrades to linked list Get O(1) O(n) When chain degrades to linked list Remove O(1) O(n) When chain degrades to linked list Space O(n) O(n) n = number of key-value pairs \ud83d\udca1 Best Practices \u00b6 1. Load Factor Management \u00b6 private boolean needsResize () { return ( double ) size / table . length > MAX_LOAD_FACTOR ; } 2. Key Quality \u00b6 // Override hashCode() in key objects @Override public int hashCode () { int hash = 17 ; hash = 31 * hash + field1 . hashCode (); hash = 31 * hash + field2 . hashCode (); return hash ; } 3. Proper Equals Implementation \u00b6 @Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null || getClass () != obj . getClass ()) return false ; MyKey other = ( MyKey ) obj ; return field1 . equals ( other . field1 ) && field2 . equals ( other . field2 ); } \u26a0\ufe0f Common Pitfalls \u00b6 1. Poor Hash Distribution \u00b6 // WRONG: Poor hash function public int hashCode () { return 1 ; // All items hash to same bucket } // BETTER: Good distribution public int hashCode () { return Objects . hash ( field1 , field2 ); } 2. Missing Null Checks \u00b6 // WRONG: No null check public V put ( K key , V value ) { int index = key . hashCode () % table . length ; // NullPointerException! // CORRECT: With null check public V put ( K key , V value ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } int index = getIndex ( key ); HashMaps provide efficient key-value storage with constant-time average case operations, making them ideal for lookup-intensive applications. The separate chaining implementation offers a good balance between simplicity and performance. References \u00b6 HashTables with Collision Management \ud83d\udd78\ufe0f Graph-Based Structures \u00b6 A Graph is a data structure that models relationships between elements using vertices (nodes) and edges. This implementation represents a directed graph using vertex and edge sets along with an adjacency list representation for efficient neighbor access. Core Characteristics \u00b6 \ud83d\udd0d Vertex Management Each vertex contains generic typed data Vertices are unique based on data equality Supports null-safe vertex operations Maintains a vertex set for O(1) lookups \ud83d\udd17 Edge Properties Directed edges from vertex u to v Weighted connections Maintains edge set for global access Supports undirected graphs via bidirectional edges \ud83d\udcca Adjacency Structure Maps vertices to neighbor lists Includes edge weights in adjacency entries Efficient neighbor access Space-efficient for sparse graphs Implementation Details \u00b6 Vertex Class \u00b6 public class Vertex < T > { private T data ; public Vertex ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null.\" ); } this . data = data ; } public T getData () { return data ; } @Override public boolean equals ( Object o ) { if ( o != null && o instanceof Vertex ) { return data . equals ((( Vertex <?> ) o ). data ); } return false ; } @Override public int hashCode () { return data . hashCode (); } } Edge Class \u00b6 public class Edge < T > implements Comparable < Edge <? super T >> { private Vertex < T > u ; // Source vertex private Vertex < T > v ; // Destination vertex private int weight ; // Edge weight public Edge ( Vertex < T > u , Vertex < T > v , int weight ) { if ( u == null || v == null ) { throw new IllegalArgumentException ( \"Arguments cannot be null.\" ); } this . u = u ; this . v = v ; this . weight = weight ; } public Vertex < T > getU () { return u ; } public Vertex < T > getV () { return v ; } public int getWeight () { return weight ; } @Override public int compareTo ( Edge <? super T > e ) { return weight - e . getWeight (); } } Graph Structure \u00b6 public class Graph < T > { private Set < Vertex < T >> vertices ; private Set < Edge < T >> edges ; private Map < Vertex < T > , List < VertexDistance < T >>> adjList ; public Graph ( Set < Vertex < T >> vertices , Set < Edge < T >> edges ) { if ( vertices == null || edges == null ) { throw new IllegalArgumentException ( \"Arguments cannot be null.\" ); } this . vertices = new HashSet <> ( vertices ); this . edges = new HashSet <> ( edges ); this . adjList = new HashMap <> (); // Initialize adjacency list for ( Vertex < T > v : vertices ) { adjList . put ( v , new ArrayList <> ()); } // Populate adjacency list for ( Edge < T > e : edges ) { if ( adjList . containsKey ( e . getU ())) { adjList . get ( e . getU ()). add ( new VertexDistance <> ( e . getV (), e . getWeight ()) ); } else { throw new IllegalArgumentException ( \"Vertex set must contain all vertices of the graph.\" ); } } } } Vertex Distance Helper \u00b6 public final class VertexDistance < T > implements Comparable < VertexDistance <? super T >> { private final Vertex < T > vertex ; private final int distance ; public VertexDistance ( Vertex < T > vertex , int distance ) { this . vertex = vertex ; this . distance = distance ; } @Override public int compareTo ( VertexDistance <? super T > pair ) { return this . distance - pair . getDistance (); } } Performance Characteristics \u00b6 Operation Average Case Worst Case Notes Add Vertex O(1) O(1) HashSet insertion Add Edge O(1) O(1) HashSet & ArrayList insertion Find Vertex O(1) O(1) HashSet lookup Find Edge O(1) O(1) HashSet lookup Get Neighbors O(1) O(1) HashMap & ArrayList access Space O(V + E) O(V + E) V vertices + E edges Best Practices \u00b6 1. Creating Undirected Edges \u00b6 // Add both directions for undirected edges vertices . add ( vertexA ); vertices . add ( vertexB ); edges . add ( new Edge <> ( vertexA , vertexB , weight )); edges . add ( new Edge <> ( vertexB , vertexA , weight )); 2. Vertex Creation \u00b6 // Ensure data validity public static < T > Vertex < T > createVertex ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Vertex data cannot be null\" ); } return new Vertex <> ( data ); } 4. Edge Validation \u00b6 private boolean isValidEdge ( Edge < T > edge ) { return vertices . contains ( edge . getU ()) && vertices . contains ( edge . getV ()); } \u26a0\ufe0f Common Pitfalls \u00b6 1. Missing Graph Initialization \u00b6 // WRONG: Uninitialized collections public Graph () { // Missing initialization } // CORRECT: Properly initialized collections public Graph ( Set < Vertex < T >> vertices , Set < Edge < T >> edges ) { this . vertices = new HashSet <> ( vertices ); this . edges = new HashSet <> ( edges ); this . adjList = new HashMap <> (); // ... rest of initialization } 2. Improper Edge Direction Handling \u00b6 // WRONG: Assuming bidirectional adjList . get ( edge . getV ()). add ( new VertexDistance <> ( edge . getU (), edge . getWeight ())); // CORRECT: Respecting edge direction adjList . get ( edge . getU ()). add ( new VertexDistance <> ( edge . getV (), edge . getWeight ())); This implementation provides a robust foundation for directed graph operations while maintaining type safety and efficient operations through appropriate data structure choices. References \u00b6 Introduction to Graphs \ud83c\udf33 Disjoint-Sets: Union-Find \u00b6 A Disjoint Set (Union-Find) is a data structure that keeps track of elements partitioned into non-overlapping sets. It provides near-constant time operations to check if two elements are in the same set and to unite two sets, making it essential for algorithms like Kruskal's MST. Core Characteristics \u00b6 \ud83c\udf33 Tree-Based Structure Each set is represented as a tree Elements point to their parent elements Root element represents the set identifier Path compression for efficiency \ud83d\udd0d Find Operation Identifies the set an element belongs to Implements path compression Returns the root element Amortized O(1) time complexity \ud83e\udd1d Union Operation Merges two different sets Uses union by rank Maintains tree balance Prevents deep hierarchies Implementation Details \u00b6 Structure \u00b6 private static class DisjointSetNode < T > { private DisjointSetNode < T > parent ; private T data ; private int rank ; public DisjointSetNode ( T data ) { this . parent = this ; // Node initially points to itself this . data = data ; this . rank = 0 ; } } Base Structure \u00b6 public class DisjointSet < T > { private Map < T , DisjointSetNode < T >> disjointSet ; public DisjointSet () { disjointSet = new HashMap <> (); } } Core Operations \u00b6 Find Operation \u00b6 public T find ( T data ) { if ( ! disjointSet . containsKey ( data )) { disjointSet . put ( data , new DisjointSetNode <> ( data )); } return find ( disjointSet . get ( data )). getData (); } private DisjointSetNode < T > find ( DisjointSetNode < T > curr ) { DisjointSetNode < T > parent = curr . getParent (); if ( parent == curr ) { return curr ; // Found root } // Path compression: Make all nodes point to root parent = find ( curr . getParent ()); curr . setParent ( parent ); return parent ; } \ud83d\udcca Performance Characteristics \u00b6 Operation Amortized Time Worst Case Notes Make Set O(1) O(1) Creates new set Find O(\u03b1(n)) O(log n) With path compression Union O(\u03b1(n)) O(log n) With union by rank Space O(n) O(n) n elements Note: \u03b1(n) is the inverse Ackermann function, which grows extremely slowly and is effectively constant for all practical values of n. \ud83d\udca1 Best Practices \u00b6 1. Path Compression \u00b6 // Always update parent pointers during find private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { if ( node != node . getParent ()) { node . setParent ( find ( node . getParent ())); // Compress path } return node . getParent (); } 2. Union by Rank \u00b6 // Always consider ranks when unioning if ( firstParent . getRank () < secondParent . getRank ()) { firstParent . setParent ( secondParent ); } else { secondParent . setParent ( firstParent ); if ( firstParent . getRank () == secondParent . getRank ()) { firstParent . setRank ( firstParent . getRank () + 1 ); } } 3. Lazy Initialization \u00b6 public T find ( T data ) { if ( ! disjointSet . containsKey ( data )) { disjointSet . put ( data , new DisjointSetNode <> ( data )); } // Continue with find operation } \u26a0\ufe0f Common Pitfalls \u00b6 1. Missing Path Compression \u00b6 // WRONG: No path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { while ( node != node . getParent ()) { node = node . getParent (); } return node ; } // CORRECT: With path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { if ( node != node . getParent ()) { node . setParent ( find ( node . getParent ())); } return node . getParent (); } 2. Incorrect Union Operation \u00b6 // WRONG: No path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { while ( node != node . getParent ()) { node = node . getParent (); } return node ; } // CORRECT: With path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { if ( node != node . getParent ()) { node . setParent ( find ( node . getParent ())); } return node . getParent (); } This implementation provides an efficient foundation for set operations used in graph algorithms, particularly Kruskal's Minimum Spanning Tree algorithm, with optimizations for both time and space complexity. References \u00b6 Union Find Data Structure \ud83d\udcda Other Advanced Structures \u00b6 \ud83d\udd0e Trie \u00b6 Trie \ud83d\udd0e Skip Lists \u00b6 Skip List Introduction Skip Lists Insertion and Deletion","title":"\ud83d\udd2e Data Structures"},{"location":"1.Fundamentals/b.%20data_structures/#data-structures","text":"","title":"\ud83d\udd2e Data Structures"},{"location":"1.Fundamentals/b.%20data_structures/#introduction","text":"Data structures are specialized formats for organizing, processing, retrieving, and storing data. Understanding data structures is fundamental to writing efficient and scalable code. This guide explores various data structures, their implementations, and practical applications in software development.","title":"\ud83d\udcd8 Introduction"},{"location":"1.Fundamentals/b.%20data_structures/#why-data-structures-matter","text":"\ud83c\udfaf Efficient Problem-Solving : Choosing the right data structure can dramatically improve program performance \ud83d\udcbc Career Development : Essential for technical interviews at top tech companies \ud83d\udd27 Code Optimization : Enables writing more efficient and maintainable code \ud83c\udf10 Real-World Applications : Critical for building scalable software systems \ud83c\udfc6 Competitive Edge : Fundamental for algorithmic problem-solving and competitions","title":"Why Data Structures Matter"},{"location":"1.Fundamentals/b.%20data_structures/#guide-structure","text":"Each data structure section will cover: - Core concepts and characteristics - Implementation details - Time and space complexities - Common operations - Best practices and use cases - Code examples and tips","title":"Guide Structure"},{"location":"1.Fundamentals/b.%20data_structures/#categories-of-data-structures","text":"","title":"Categories of Data Structures"},{"location":"1.Fundamentals/b.%20data_structures/#linear-data-structures","text":"Structures where elements are stored sequentially: Arrays & ArrayLists : Direct access by index Contiguous memory storage Best for: Fixed-size collections with frequent access Linked Lists : Dynamic size Non-contiguous storage Best for: Frequent insertions/deletions Stacks : LIFO (Last-In-First-Out) Best for: Function calls, undo operations Queues : FIFO (First-In-First-Out) Best for: Task scheduling, resource management","title":"\ud83d\udcda Linear Data Structures"},{"location":"1.Fundamentals/b.%20data_structures/#tree-based-structures","text":"Hierarchical structures with parent-child relationships: Priority Queues : Efficient priority-based operations Best for: Scheduling, event handling Binary Trees : Two children per node maximum Best for: Hierarchical data Binary Search Trees : Ordered nodes Best for: Fast search, insert, delete","title":"\ud83c\udf33 Tree-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#advanced-tree-based-structures","text":"Specialized tree structures for specific use cases: AVL Trees : Balanced binary search trees Red-Black Trees : Balanced search with color properties 2-3 Trees : Guaranteed balanced search trees B-Trees : Optimized for disk storage K-D Trees : Space partitioning structure M-Ary Trees : Nodes with multiple children","title":"\ud83c\udf32 Advanced Tree-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#hash-based-structures","text":"Structures using hash functions: Hash Tables : Key-value storage O(1) average access Best for: Caching, dictionaries","title":"\ud83c\udfaf Hash-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#graph-based-structures","text":"Structures representing connections: Directed Graphs : One-way connections Undirected Graphs : Two-way connections inaphs Coctions with costs Disjoint-Sets : Non-Overlapping group connections","title":"\ud83d\udd78\ufe0f Graph-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#advanced-structures","text":"Specialized data structures: Tries : Efficient string operations Best for: Autocomplete, spell checkers Skip Lists : Probabilistic alternative to balanced trees Best for: Fast search with simple implementation","title":"\ud83d\udcda Advanced Structures"},{"location":"1.Fundamentals/b.%20data_structures/#time-complexity-overview","text":"","title":"Time Complexity Overview"},{"location":"1.Fundamentals/b.%20data_structures/#performance-overview","text":"Data Structure Access Search Insertion Deletion Space Array O(1) O(n) O(n) O(n) O(n) ArrayList O(1) O(n) O(n)* O(n) O(n) LinkedList O(n) O(n) O(1) O(1) O(n) Stack O(n) O(n) O(1) O(1) O(n) Queue O(n) O(n) O(1) O(1) O(n) Priority Queue O(1)*** O(n) O(log n) O(log n) O(n) Binary Tree O(n) O(n) O(n) O(n) O(n) Binary Search Tree O(log n)* O(log n)* O(log n)* O(log n)* O(n) AVL Tree O(log n) O(log n) O(log n) O(log n) O(n) Red-Black Tree O(log n) O(log n) O(log n) O(log n) O(n) 2-3 Tree O(log n) O(log n) O(log n) O(log n) O(n) B-Tree O(log n) O(log n) O(log n) O(log n) O(n) K-D Tree O(n) O(log n)** O(log n)** O(log n)** O(n) Trie O(m)**** O(m)**** O(m)**** O(m)**** O(n*m) Skip List O(log n)** O(log n)** O(log n)** O(log n)** O(n log n) Hash Table O(1)** O(1)** O(1)** O(1)* * Average case for balanced trees * Average case, assumes good hash function or balanced structure * For peek operation only * ** Where m is the length of the string/pattern \u2020 Amortized time complexity for dynamic resizing~~","title":"\ud83d\udcca Performance Overview"},{"location":"1.Fundamentals/b.%20data_structures/#references","text":"Data Structures and Algorithms Notes","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#linear-data-structuresine-data-structures","text":"","title":"\ud83d\udcda LINEAR DATA STRUCTURESine Data Structures"},{"location":"1.Fundamentals/b.%20data_structures/#arraylist","text":"An ArrayList is a dynamic array implementation that automatically handles resizing as elements are added or removed. It provides fast random access and is one of the most used data structures in Java.","title":"\ud83d\udcda ArrayList"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics","text":"\ud83d\udcc8 Dynamic sizing \ud83d\udcca Contiguous memory storage \ud83d\udd0d Fast random access \ud83d\udcdd Mutable length","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure","text":"public class ArrayList < T > { private T [] backingArray ; // Internal array to store elements private int size ; // Number of elements in the ArrayList public static final int INITIAL_CAPACITY = 9 ; }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations-time-complexities","text":"","title":"\ud83d\udd27 Core Operations &amp; Time Complexities"},{"location":"1.Fundamentals/b.%20data_structures/#adding-elements","text":"","title":"Adding Elements"},{"location":"1.Fundamentals/b.%20data_structures/#addtobackt-data","text":"public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } addHelper ( size , data ); } - \u23f1\ufe0f Time Complexity: Amortized O(1) - \ud83d\udcad Best for: Adding elements when order doesn't matter - \u26a0\ufe0f Note: May trigger resizing of backing array","title":"addToBack(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#addtofrontt-data","text":"public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } addHelper ( 0 , data ); } - \u23f1\ufe0f Time Complexity: O(n) - \u26a0\ufe0f Warning: Requires shifting all elements - \ud83d\udcad Use Case: When elements must be added at the beginning","title":"addToFront(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#internal-helper-method-adding","text":"","title":"\ud83d\udee0\ufe0f Internal Helper Method (Adding)"},{"location":"1.Fundamentals/b.%20data_structures/#addhelperint-index-t-data","text":"@SuppressWarnings ( \"unchecked\" ) private void addHelper ( int index , T data ) { // If array is full, create new array with double capacity if ( size == backingArray . length ) { T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; int i ; // Copy elements before index for ( i = 0 ; i < index ; i ++ ) { newArray [ i ] = backingArray [ i ] ; } // Insert new element newArray [ i ] = data ; // Copy remaining elements for (; i < size ; i ++ ) { newArray [ i + 1 ] = backingArray [ i ] ; } backingArray = newArray ; } else { // Shift elements to make room for new element for ( int i = size ; i > index ; -- i ) { backingArray [ i ] = backingArray [ i - 1 ] ; } backingArray [ index ] = data ; } size ++ ; } ```` #### Removing Elements ##### removeFromBack () ```` java public T removeFromBack () { if ( size == 0 ) { throw new java . util . NoSuchElementException ( \"Cannot remove from an empty list\" ); } return removeHelper ( size - 1 ); } ```` - \u23f1\ufe0f Time Complexity : O ( 1 ) - \ud83d\udcab Most efficient removal operation - \u26a0\ufe0f Checks for empty list ##### removeFromFront () ```` java public T removeFromFront () { if ( size == 0 ) { throw new java . util . NoSuchElementException ( \"Cannot remove from an empty list\" ); } return removeHelper ( 0 ); } ```` - \u23f1\ufe0f Time Complexity : O ( n ) - \u26a0\ufe0f Requires shifting all elements - \ud83d\udcad Use sparingly due to performance cost ##### removeAtIndex ( int index ) ``` java public T removeAtIndex ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index cannot be outside the \" + \"range [0, \" + size + \")\" ); } return removeHelper ( index ); } - \u23f1\ufe0f Time Complexity: - Best Case (last element): O(1) - Average/Worst Case: O(n) - \ud83c\udfaf Purpose: Removes and returns element at specified index - \u26a0\ufe0f Validation: Checks for valid index range - \ud83d\udcab Process: 1. Validates index bounds 2. Calls removeHelper for actual removal 3. Returns removed element","title":"addHelper(int index, T data)"},{"location":"1.Fundamentals/b.%20data_structures/#internal-helper-method-removing","text":"","title":"\ud83d\udee0\ufe0f Internal Helper Method (Removing)"},{"location":"1.Fundamentals/b.%20data_structures/#removehelperint-index","text":"private T removeHelper ( int index ) { T removed = backingArray [ index ] ; // Shift elements to fill the gap for ( int i = index ; i < size - 1 ; i ++ ) { backingArray [ i ] = backingArray [ i + 1 ] ; } backingArray [-- size ] = null ; // Clear last element and decrease size return removed ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83c\udfaf Purpose: Internal method for handling element removal and shifting - \ud83d\udcab Key Operations: 1. Element removal at specified index 2. Left-shifting remaining elements 3. Cleanup and size management","title":"removeHelper(int index)"},{"location":"1.Fundamentals/b.%20data_structures/#access-operations","text":"","title":"Access Operations"},{"location":"1.Fundamentals/b.%20data_structures/#getint-index","text":"public T get ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index cannot be outside the \" + \"range [0, \" + size + \")\" ); } return backingArray [ index ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83c\udfaf Direct index access - \u26a0\ufe0f Bounds checking included","title":"get(int index)"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary","text":"Operation Time Complexity Notes Add to Back O(1)* *Amortized Add to Front O(n) Requires shifting Add at Index O(n) Requires shifting Remove from Back O(1) Most efficient removal Remove from Front O(n) Requires shifting Get/Set O(1) Direct access Clear O(1) Memory reset Size O(1) Constant tracking * Amortized time complexity - occasional resizing operations are averaged over many operations","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-initialization","text":"State with reasonable initial capacity Consider expected size for optimal performance","title":"1. Initialization"},{"location":"1.Fundamentals/b.%20data_structures/#2-usage-tips","text":"// Prefer adding to back when possible list . addToBack ( element ); // O(1) // Avoid frequent front operations list . addToFront ( element ); // O(n) - expensive!","title":"2. Usage Tips"},{"location":"1.Fundamentals/b.%20data_structures/#3-memory-management","text":"Clear references when removing elements Reset to initial capacity when clearing","title":"3. Memory Management"},{"location":"1.Fundamentals/b.%20data_structures/#common-use-cases","text":"\ud83d\udcdd Dynamic lists of elements \ud83d\udcca Buffer implementation \ud83d\udd04 Stack implementation \ud83d\udcda Collection management","title":"\ud83c\udfaf Common Use Cases"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls","text":"Frequent front operations Not considering capacity growth Not handling null elements Ignoring bounds checking","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#when-to-use-arraylist","text":"Need dynamic sizing Frequent random access Mostly back-end operations Memory locality is important","title":"\ud83d\udd0d When to Use ArrayList"},{"location":"1.Fundamentals/b.%20data_structures/#when-not-to-use-arraylist","text":"Frequent insertions/deletions at front/middle Fixed size is sufficient Memory is extremely constrained Need concurrent access","title":"\ud83d\udeab When Not to Use ArrayList"},{"location":"1.Fundamentals/b.%20data_structures/#references_1","text":"https://youtu.be/PEnFFiQe1pM?si=KfpsngEBI0gesUbC","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#linked-lists","text":"","title":"\ud83d\udcda Linked Lists"},{"location":"1.Fundamentals/b.%20data_structures/#singly-linked-list","text":"A Singly Linked List is a fundamental data structure where elements are stored in nodes, each containing data and a reference to the next node in the sequence. Unlike arrays, linked lists don't require contiguous memory allocation, making them ideal for dynamic data management.","title":"\ud83d\udd17 Singly Linked List"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_1","text":"\ud83d\udd04 Dynamic sizing (no fixed capacity) \ud83d\udcdd Sequential access pattern \ud83e\udde9 Node-based structure \ud83c\udfaf Efficient insertions and deletions at known positions \ud83d\udd0d Linear time search operations","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_1","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_1","text":"public class LinkedList < T > { private Node < T > head ; private int size ; private static class Node < T > { private T data ; private Node < T > next ; public Node ( T data ) { this . data = data ; this . next = null ; } } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations-time-complexities_1","text":"","title":"\ud83d\udd27 Core Operations &amp; Time Complexities"},{"location":"1.Fundamentals/b.%20data_structures/#adding-elements_1","text":"","title":"Adding Elements"},{"location":"1.Fundamentals/b.%20data_structures/#addtofrontt-data_1","text":"public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); newNode . next = head ; head = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack-like operations - \u26a0\ufe0f Edge Cases: - Null data - First element (empty list)","title":"addToFront(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#addtobackt-data_1","text":"public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); if ( head == null ) { head = newNode ; } else { Node < T > current = head ; while ( current . next != null ) { current = current . next ; } current . next = newNode ; } size ++ ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Queue-like operations - \u26a0\ufe0f Edge Cases: - Null data - Empty list - Consider tracking tail pointer for O(1) operation","title":"addToBack(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#addatindexint-index-t-data","text":"public void addAtIndex ( int index , T data ) { if ( index < 0 || index > size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } if ( index == 0 ) { addToFront ( data ); return ; } Node < T > current = head ; for ( int i = 0 ; i < index - 1 ; i ++ ) { current = current . next ; } Node < T > newNode = new Node <> ( data ); newNode . next = current . next ; current . next = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Ordered insertions - \u26a0\ufe0f Edge Cases: - Invalid index - Null data - Front insertion","title":"addAtIndex(int index, T data)"},{"location":"1.Fundamentals/b.%20data_structures/#removing-elements","text":"","title":"Removing Elements"},{"location":"1.Fundamentals/b.%20data_structures/#removefromfront","text":"public T removeFromFront () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = head . data ; head = head . next ; size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element","title":"removeFromFront()"},{"location":"1.Fundamentals/b.%20data_structures/#removefromback","text":"public T removeFromBack () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } if ( size == 1 ) { T data = head . data ; head = null ; size -- ; return data ; } Node < T > current = head ; while ( current . next . next != null ) { current = current . next ; } T data = current . next . data ; current . next = null ; size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Queue operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element - Consider tail pointer optimization","title":"removeFromBack()"},{"location":"1.Fundamentals/b.%20data_structures/#access-operations_1","text":"","title":"Access Operations"},{"location":"1.Fundamentals/b.%20data_structures/#getint-index_1","text":"public T get ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } Node < T > current = head ; for ( int i = 0 ; i < index ; i ++ ) { current = current . next ; } return current . data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad Best for: Sequential access - \u26a0\ufe0f Edge Cases: - Invalid index - Empty list","title":"get(int index)"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_1","text":"Operation Time Complexity Notes Add to Front O(1) Constant time Add to Back O(n) Linear traversal Add at Index O(n) Traversal to index Remove from Front O(1) Constant time Remove from Back O(n) Linear traversal Get O(n) Linear traversal Size O(1) Tracked variable","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_1","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-null-handling","text":"private void validateNotNull ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } }","title":"1. Null Handling"},{"location":"1.Fundamentals/b.%20data_structures/#2-index-validation","text":"private void validateIndex ( int index , boolean isAdd ) { int maxIndex = isAdd ? size : size - 1 ; if ( index < 0 || index > maxIndex ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } }","title":"2. Index Validation"},{"location":"1.Fundamentals/b.%20data_structures/#3-memory-management_1","text":"Clear references when removing nodes Consider garbage collection implications Track size for O(1) length checks","title":"3. Memory Management"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_1","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-losing-references","text":"// WRONG - Lost reference to rest of list head = new Node <> ( data ); // Overwrites head reference // CORRECT - Maintain list structure Node < T > newNode = new Node <> ( data ); newNode . next = head ; head = newNode ;","title":"1. Losing References"},{"location":"1.Fundamentals/b.%20data_structures/#2-not-handling-edge-cases","text":"// WRONG - Assumes non-empty list head . next = newNode ; // CORRECT - Handle empty list if ( head == null ) { head = newNode ; } else { head . next = newNode ; }","title":"2. Not Handling Edge Cases"},{"location":"1.Fundamentals/b.%20data_structures/#reference","text":"Singly Linked List Video","title":"Reference"},{"location":"1.Fundamentals/b.%20data_structures/#doubly-linked-list","text":"A Doubly Linked List is a bidirectional linked data structure where each node contains data and references to both the next and previous nodes. This bidirectional linking enables efficient traversal in both directions and simplifies certain operations compared to singly linked lists.","title":"\ud83d\udd17 Doubly Linked List"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_2","text":"\ud83d\udd04 Bi-directional traversal \ud83d\udcdd Dynamic sizing \ud83c\udfaf O(1) operations at both ends \ud83d\udd0d Efficient insertions and deletions \ud83d\udcbe Higher memory usage per node","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_2","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_2","text":"public class DoublyLinkedList < T > { private Node < T > head ; private Node < T > tail ; private int size ; private static class Node < T > { private T data ; private Node < T > next ; private Node < T > previous ; Node ( T data ) { this . data = data ; this . next = null ; this . previous = null ; } Node ( T data , Node < T > previous , Node < T > next ) { this . data = data ; this . previous = previous ; this . next = next ; } } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations-time-complexities_2","text":"","title":"\ud83d\udd27 Core Operations &amp; Time Complexities"},{"location":"1.Fundamentals/b.%20data_structures/#adding-elements_2","text":"","title":"Adding Elements"},{"location":"1.Fundamentals/b.%20data_structures/#addtofrontt-data_2","text":"public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } head = new Node <> ( data , null , head ); if ( size == 0 ) { tail = head ; // First node is both head and tail } else { head . next . previous = head ; // Link old head back to new head } size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack-like operations, maintaining recent items - \u26a0\ufe0f Edge Cases: - Empty list - Null data - Maintaining tail reference","title":"addToFront(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#addtobackt-data_2","text":"public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data , tail , null ); if ( size == 0 ) { head = newNode ; } else { tail . next = newNode ; } tail = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Queue-like operations - \u26a0\ufe0f Edge Cases: - Empty list - Null data - Maintaining head reference","title":"addToBack(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#addatindexint-index-t-data_1","text":"public void addAtIndex ( int index , T data ) { if ( index < 0 || index > size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } if ( index == 0 ) { addToFront ( data ); return ; } if ( index == size ) { addToBack ( data ); return ; } // Choose optimal traversal direction Node < T > current ; if ( index < size / 2 ) { // Start from head current = head ; for ( int i = 0 ; i < index - 1 ; i ++ ) { current = current . next ; } } else { // Start from tail current = tail ; for ( int i = size - 1 ; i > index ; i -- ) { current = current . previous ; } } Node < T > newNode = new Node <> ( data , current , current . next ); current . next . previous = newNode ; current . next = newNode ; size ++ ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Optimization: Chooses optimal traversal direction - \u26a0\ufe0f Edge Cases: - Index bounds - Null data - Front/back insertions","title":"addAtIndex(int index, T data)"},{"location":"1.Fundamentals/b.%20data_structures/#remove-elements","text":"","title":"Remove Elements"},{"location":"1.Fundamentals/b.%20data_structures/#removefromfront_1","text":"public T removeFromFront () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = head . data ; head = head . next ; size -- ; if ( size == 0 ) { tail = null ; } else { head . previous = null ; } return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Stack operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element - Maintaining tail reference","title":"removeFromFront()"},{"location":"1.Fundamentals/b.%20data_structures/#removefromback_1","text":"public T removeFromBack () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = tail . data ; tail = tail . previous ; size -- ; if ( size == 0 ) { head = null ; } else { tail . next = null ; } return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad Best for: Queue operations - \u26a0\ufe0f Edge Cases: - Empty list - Single element - Maintaining head reference","title":"removeFromBack()"},{"location":"1.Fundamentals/b.%20data_structures/#access-operations_2","text":"","title":"Access Operations"},{"location":"1.Fundamentals/b.%20data_structures/#getint-index_2","text":"public T get ( int index ) { if ( index < 0 || index >= size ) { throw new IndexOutOfBoundsException ( \"Index: \" + index + \", Size: \" + size ); } Node < T > current ; if ( index < size / 2 ) { current = head ; for ( int i = 0 ; i < index ; i ++ ) { current = current . next ; } } else { current = tail ; for ( int i = size - 1 ; i > index ; i -- ) { current = current . previous ; } } return current . data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Optimization: Bi-directional traversal - \u26a0\ufe0f Edge Cases: - Invalid index - Empty list","title":"get(int index)"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_2","text":"Operation Time Complexity Notes Add to Front O(1) Constant time Add to Back O(1) Constant time with tail Add at Index O(n) Optimal traversal direction Remove from Front O(1) Constant time Remove from Back O(1) Constant time with tail Get O(n) Optimal traversal direction Size O(1) Tracked variable","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_2","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-bi-directional-link-maintenance","text":"// Always update both next and previous references newNode . next = current . next ; newNode . previous = current ; current . next . previous = newNode ; current . next = newNode ;","title":"1. Bi-directional Link Maintenance"},{"location":"1.Fundamentals/b.%20data_structures/#2-headtail-management","text":"// For single element if ( size == 1 ) { head = tail = null ; } else { // Update references appropriately }","title":"2. Head/Tail Management"},{"location":"1.Fundamentals/b.%20data_structures/#3-traversal-optimization","text":"// Choose optimal direction based on index if ( index < size / 2 ) { traverseFromHead (); } else { traverseFromTail (); }","title":"3. Traversal Optimization"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_2","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-incomplete-link-updates","text":"// WRONG - Only updating one direction current . next = newNode ; // CORRECT - Update both directions current . next = newNode ; newNode . previous = current ;","title":"1. Incomplete Link Updates"},{"location":"1.Fundamentals/b.%20data_structures/#2-memory-leaks","text":"// WRONG - Leaving dangling references head = head . next ; // CORRECT - Clear all references T data = head . data ; Node < T > newHead = head . next ; head . next = null ; // Clear reference if ( newHead != null ) { newHead . previous = null ; } head = newHead ;","title":"2. Memory Leaks"},{"location":"1.Fundamentals/b.%20data_structures/#references_2","text":"Doubly Linked List Video","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#circular-singly-linked-list","text":"A Circular Singly Linked List is a variant of linked lists where the last node points back to the first node, creating a circle. This structure is particularly useful when I need continuous traversal or cyclic operations, like round-robin scheduling.","title":"\ud83d\udd04 Circular Singly Linked List"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_3","text":"\ud83d\udd04 Last node connects to first node \ud83d\udcdd Sequential access pattern \ud83c\udfaf No null references \ud83d\udd0d Continuous traversal capability \ud83d\udcab Efficient for cyclic operations","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_3","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_3","text":"public class CircularLinkedList < T > { private Node < T > tail ; // Points to last node private int size ; private static class Node < T > { T data ; Node < T > next ; Node ( T data ) { this . data = data ; this . next = null ; } } } \ud83d\udcad Why track tail instead of head? O(1) insertions at both ends Easy access to both first and last nodes More efficient for common operations","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations","text":"","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#adding-elements_3","text":"","title":"Adding Elements"},{"location":"1.Fundamentals/b.%20data_structures/#addingtofrontt-data","text":"public void addToFront ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); if ( isEmpty ()) { newNode . next = newNode ; // Points to itself tail = newNode ; } else { newNode . next = tail . next ; // Point to old first node tail . next = newNode ; // Update tail's next to new node } size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udca1 Important: Maintain circular nature - \u26a0\ufe0f Edge Cases: Empty list handling","title":"addingToFront(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#addtobackt-data_3","text":"public void addToBack ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } Node < T > newNode = new Node <> ( data ); if ( isEmpty ()) { newNode . next = newNode ; } else { newNode . next = tail . next ; // Point to first node tail . next = newNode ; // Update tail's next } tail = newNode ; // Update tail to new node size ++ ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udca1 Key Point: Tail reference makes this efficient - \u26a0\ufe0f Edge Cases: Empty list, single element","title":"addToBack(T data)"},{"location":"1.Fundamentals/b.%20data_structures/#removing-elements_1","text":"","title":"Removing Elements"},{"location":"1.Fundamentals/b.%20data_structures/#removefromfront_2","text":"public T removeFromFront () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = tail . next . data ; // Get first node's data if ( size == 1 ) { tail = null ; } else { tail . next = tail . next . next ; // Skip first node } size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udca1 Key Point: Maintain circular structure - \u26a0\ufe0f Edge Cases: Empty list, single element","title":"removeFromFront()"},{"location":"1.Fundamentals/b.%20data_structures/#removefromback_2","text":"public T removeFromBack () { if ( isEmpty ()) { throw new NoSuchElementException ( \"List is empty\" ); } T data = tail . data ; if ( size == 1 ) { tail = null ; } else { Node < T > current = tail . next ; while ( current . next != tail ) { current = current . next ; } current . next = tail . next ; tail = current ; } size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Note: Requires traversal to find second-to-last node - \u26a0\ufe0f Edge Cases: Empty list, single element","title":"removeFromBack()"},{"location":"1.Fundamentals/b.%20data_structures/#search-operation","text":"public boolean contains ( T data ) { if ( isEmpty () || data == null ) { return false ; } Node < T > current = tail . next ; // Start at first node do { if ( data . equals ( current . data )) { return true ; } current = current . next ; } while ( current != tail . next ); return false ; } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udca1 Important: Use do-while for circular traversal - \u26a0\ufe0f Handle: Null data, empty list","title":"Search Operation"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_3","text":"Operation Time Complexity Notes Add to Front O(1) Constant time with tail reference Add to Back O(1) Constant time with tail reference Remove from Front O(1) Constant time operation Remove from Back O(n) Requires traversal Search O(n) Linear traversal Size O(1) Tracked variable","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_3","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-circular-reference-maintenance","text":"// Always ensure last node points to first tail . next = tail . next . next ; // When removing newNode . next = tail . next ; // When adding","title":"1. Circular Reference Maintenance"},{"location":"1.Fundamentals/b.%20data_structures/#2-empty-list-handling","text":"if ( isEmpty ()) { // New node points to itself newNode . next = newNode ; tail = newNode ; }","title":"2. Empty List Handling"},{"location":"1.Fundamentals/b.%20data_structures/#3-single-element-handling","text":"if ( size == 1 ) { tail = null ; // For removal // OR tail = newNode ; // For insertion }","title":"3. Single Element Handling"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_3","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-infinite-loops","text":"// WRONG - May loop forever while ( current . next != null ) { // Never true in circular list current = current . next ; } // CORRECT do { current = current . next ; } while ( current != tail . next );","title":"1. Infinite Loops"},{"location":"1.Fundamentals/b.%20data_structures/#2-lost-circular-reference","text":"// WRONG - Loses circular structure tail . next = newNode ; // CORRECT - Maintains circular structure newNode . next = tail . next ; tail . next = newNode ;","title":"2. Lost Circular Reference"},{"location":"1.Fundamentals/b.%20data_structures/#reference_1","text":"Circular Linked List Playlist","title":"Reference"},{"location":"1.Fundamentals/b.%20data_structures/#stack","text":"","title":"\ud83d\udcda Stack"},{"location":"1.Fundamentals/b.%20data_structures/#introduction_1","text":"A Stack is a linear data structure that follows the LIFO (Last In First Out) principle. Like a stack of plates, elements are added and removed from the same end, called the top of the stack. This fundamental data structure is ideal for scenarios where we need strict order control over our operations.","title":"Introduction"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_4","text":"\ud83d\udce5 LIFO (Last In, First Out) principle \ud83c\udfaf Single point of access (top) \ud83d\udccf Dynamic sizing through array resizing \ud83d\udd04 Ordered operations \u26a1 Constant time operations (amortized)","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_4","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_4","text":"public class Stack < T > { // Default capacity when no size is specified private static final int DEFAULT_CAPACITY = 10 ; // Internal array to store elements private T [] backingArray ; // Keep track of the next available position private int size ; // Constructor with default capacity @SuppressWarnings ( \"unchecked\" ) public Stack () { backingArray = ( T [] ) new Object [ DEFAULT_CAPACITY ] ; size = 0 ; } // Constructor with specified initial capacity @SuppressWarnings ( \"unchecked\" ) public Stack ( int initialCapacity ) { if ( initialCapacity < 0 ) { throw new IllegalArgumentException ( \"Initial capacity cannot be negative\" ); } backingArray = ( T [] ) new Object [ initialCapacity ] ; size = 0 ; } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_1","text":"","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#push-operation","text":"public void push ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Cannot push null data\" ); } // Check if we need to resize if ( size == backingArray . length ) { resize (); } // Add element and increment size backingArray [ size ++] = data ; } @SuppressWarnings ( \"unchecked\" ) private void resize () { T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ i ] ; } backingArray = newArray ; } \u23f1\ufe0f Time Complexity: O(1) amortized - \ud83d\udcad When to Use: Adding new elements to the stack - \u26a0\ufe0f Key Points: - Handles null check - Automatic resizing - Maintains LIFO order","title":"Push Operation"},{"location":"1.Fundamentals/b.%20data_structures/#pop-operation","text":"public T pop () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Cannot pop from empty stack\" ); } // Retrieve element and decrement size T data = backingArray [-- size ] ; backingArray [ size ] = null ; // Clear reference for garbage collection return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Removing and retrieving the most recently added element - \u26a0\ufe0f Key Points: - Checks for empty stack - Cleans up references - Maintains LIFO order","title":"Pop Operation"},{"location":"1.Fundamentals/b.%20data_structures/#peek-operation","text":"public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Cannot peek empty stack\" ); } return backingArray [ size - 1 ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Viewing top element without removal - \u26a0\ufe0f Key Points: - No modification to stack - Preserves state - Checks for empty stack","title":"Peek Operation"},{"location":"1.Fundamentals/b.%20data_structures/#utility-operations","text":"// Check if stack is empty public boolean isEmpty () { return size == 0 ; } // Get current number of elements public int size () { return size ; } // Clear all elements @SuppressWarnings ( \"unchecked\" ) public void clear () { backingArray = ( T [] ) new Object [ DEFAULT_CAPACITY ] ; size = 0 ; }","title":"Utility Operations"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_4","text":"","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_5","text":"Operation Time Complexity Notes Push O(1)* Amortized for resizing Pop O(1) Constant time Peek O(1) Constant time isEmpty O(1) Constant time Size O(1) Constant time Clear O(1) New array allocation * Amortized time complexity accounts for occasional resizing operations","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_4","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-memory-management","text":"// Always clear references when removing elements public T pop () { T data = backingArray [-- size ] ; backingArray [ size ] = null ; // Clear reference return data ; }","title":"1. Memory Management"},{"location":"1.Fundamentals/b.%20data_structures/#2-capacity-handling","text":"// Consider shrinking array when usage is low private void shrinkIfNeeded () { if ( size > 0 && size < backingArray . length / 4 ) { resize ( backingArray . length / 2 ); } }","title":"2. Capacity Handling"},{"location":"1.Fundamentals/b.%20data_structures/#3-null-checking","text":"// Always validate input public void push ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } // push implementation }","title":"3. Null Checking"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_4","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-memory-leaks","text":"// WRONG - Memory leak public T pop () { return backingArray [-- size ] ; // Reference still held } // CORRECT - Clear reference public T pop () { T data = backingArray [-- size ] ; backingArray [ size ] = null ; // Clear reference return data ; }","title":"1. Memory Leaks"},{"location":"1.Fundamentals/b.%20data_structures/#2-bound-checking","text":"// WRONG - No empty check public T peek () { return backingArray [ size - 1 ] ; // Possible IndexOutOfBoundsException } // CORRECT - With empty check public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Stack is empty\" ); } return backingArray [ size - 1 ] ; }","title":"2. Bound Checking"},{"location":"1.Fundamentals/b.%20data_structures/#common-use-cases_1","text":"","title":"\ud83c\udfaf Common Use Cases"},{"location":"1.Fundamentals/b.%20data_structures/#1-function-call-stack","text":"Stack < FunctionCall > callStack = new Stack <> (); callStack . push ( new FunctionCall ( \"main\" )); callStack . push ( new FunctionCall ( \"helper\" )); // Current function is helper callStack . pop (); // Return to main","title":"1. Function Call Stack"},{"location":"1.Fundamentals/b.%20data_structures/#2-expression-evaluation","text":"Stack < Character > parentheses = new Stack <> (); for ( char c : expression . toCharArray ()) { if ( c == '(' ) { parentheses . push ( c ); } else if ( c == ')' ) { if ( ! parentheses . isEmpty ()) { parentheses . pop (); } else { // Unmatched closing parenthesis } } }","title":"2. Expression Evaluation"},{"location":"1.Fundamentals/b.%20data_structures/#3-undoredo-operations","text":"Stack < Command > undoStack = new Stack <> (); Stack < Command > redoStack = new Stack <> (); void executeCommand ( Command cmd ) { cmd . execute (); undoStack . push ( cmd ); redoStack . clear (); // Clear redo history }","title":"3. Undo/Redo Operations"},{"location":"1.Fundamentals/b.%20data_structures/#references_3","text":"Stack Introduction Stack Implementation","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#queue","text":"","title":"\ud83c\udfaf Queue"},{"location":"1.Fundamentals/b.%20data_structures/#introduction_2","text":"A Queue is a linear data structure following the FIFO (First In, First Out) principle. Using a circular array implementation allows for efficient space usage and constant time operations by reusing array spaces that have been dequeued.","title":"Introduction"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_5","text":"\ud83d\udce5 FIFO (First In, First Out) ordering \ud83d\udd04 Circular array implementation \ud83d\udccf Dynamic sizing \u26a1 Constant time operations (amortized) \ud83c\udfaf Space efficient","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_5","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_5","text":"public class Queue < T > { private T [] backingArray ; private int front ; // Index of the front element private int size ; // Number of elements in queue private static final int INITIAL_CAPACITY = 10 ; @SuppressWarnings ( \"unchecked\" ) public Queue () { backingArray = ( T [] ) new Object [ INITIAL_CAPACITY ] ; front = 0 ; size = 0 ; } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_2","text":"","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#enqueue-operation","text":"public void enqueue ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Cannot enqueue null data\" ); } // Check if we need to resize if ( size == backingArray . length ) { resize (); } // Calculate rear index using modulo for circular behavior int rear = ( front + size ) % backingArray . length ; backingArray [ rear ] = data ; size ++ ; } @SuppressWarnings ( \"unchecked\" ) private void resize () { T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; // Copy elements in order, starting from front for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ ( front + i ) % backingArray . length ] ; } backingArray = newArray ; front = 0 ; // Reset front to beginning of new array } - \u23f1\ufe0f Time Complexity: O(1) amortized - \ud83d\udcad When to Use: Adding elements to queue - \u26a0\ufe0f Key Points: - Handles null check - Circular indexing with modulo - Resizes when full","title":"Enqueue Operation"},{"location":"1.Fundamentals/b.%20data_structures/#dequeue-operation","text":"public T dequeue () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } T data = backingArray [ front ] ; backingArray [ front ] = null ; // Help GC front = ( front + 1 ) % backingArray . length ; size -- ; return data ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Removing elements from front - \u26a0\ufe0f Key Points: - Handles empty queue - Maintains circular structure - Cleans up references","title":"Dequeue Operation"},{"location":"1.Fundamentals/b.%20data_structures/#peek-operation_1","text":"public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } return backingArray [ front ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Examining front element - \u26a0\ufe0f Key Points: - No modification to queue - Front element access","title":"Peek Operation"},{"location":"1.Fundamentals/b.%20data_structures/#utility-operations_1","text":"public boolean isEmpty () { return size == 0 ; } public int size () { return size ; } @SuppressWarnings ( \"unchecked\" ) public void clear () { backingArray = ( T [] ) new Object [ INITIAL_CAPACITY ] ; front = 0 ; size = 0 ; }","title":"Utility Operations"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_6","text":"","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_7","text":"Operation Time Complexity Notes Enqueue O(1)* Amortized for resizing Dequeue O(1) Constant time Peek O(1) Constant time isEmpty O(1) Constant time Size O(1) Constant time Clear O(1) New array allocation * Amortized time complexity accounts for occasional resizing operations","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_5","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-circular-index-calculation","text":"// Calculate next index with modulo private int getNextIndex ( int currentIndex ) { return ( currentIndex + 1 ) % backingArray . length ; } // Calculate rear index private int getRearIndex () { return ( front + size ) % backingArray . length ; }","title":"1. Circular Index Calculation"},{"location":"1.Fundamentals/b.%20data_structures/#2-resizing-strategy","text":"private void resize () { // Double size for amortized O(1) T [] newArray = ( T [] ) new Object [ backingArray . length * 2 ] ; // Copy in order from front to rear for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ ( front + i ) % backingArray . length ] ; } front = 0 ; // Reset front after resize backingArray = newArray ; }","title":"2. Resizing Strategy"},{"location":"1.Fundamentals/b.%20data_structures/#3-memory-management_2","text":"public T dequeue () { T data = backingArray [ front ] ; backingArray [ front ] = null ; // Clear reference front = ( front + 1 ) % backingArray . length ; size -- ; return data ; }","title":"3. Memory Management"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_5","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-incorrect-circular-indexing","text":"// WRONG - May cause overflow rear = rear + 1 ; if ( rear == backingArray . length ) rear = 0 ; // CORRECT - Use modulo rear = ( rear + 1 ) % backingArray . length ;","title":"1. Incorrect Circular Indexing"},{"location":"1.Fundamentals/b.%20data_structures/#2-resizing-issues","text":"// WRONG - Doesn't maintain order System . arraycopy ( backingArray , 0 , newArray , 0 , backingArray . length ); // CORRECT - Maintains order from front for ( int i = 0 ; i < size ; i ++ ) { newArray [ i ] = backingArray [ ( front + i ) % backingArray . length ] ; }","title":"2. Resizing Issues"},{"location":"1.Fundamentals/b.%20data_structures/#common-use-cases_2","text":"","title":"\ud83c\udfaf Common Use Cases"},{"location":"1.Fundamentals/b.%20data_structures/#1-task-scheduling","text":"Queue < Task > taskQueue = new Queue <> (); taskQueue . enqueue ( new Task ( \"Process payment\" )); taskQueue . enqueue ( new Task ( \"Send email\" )); while ( ! taskQueue . isEmpty ()) { Task nextTask = taskQueue . dequeue (); processTask ( nextTask ); }","title":"1. Task Scheduling"},{"location":"1.Fundamentals/b.%20data_structures/#2-bfs-implementation","text":"public void bfs ( Node root ) { Queue < Node > queue = new Queue <> (); queue . enqueue ( root ); while ( ! queue . isEmpty ()) { Node current = queue . dequeue (); for ( Node child : current . getChildren ()) { queue . enqueue ( child ); } } }","title":"2. BFS Implementation"},{"location":"1.Fundamentals/b.%20data_structures/#3-buffer-implementation","text":"public class Buffer < T > { private Queue < T > queue = new Queue <> (); private final int capacity ; public void write ( T data ) { if ( queue . size () < capacity ) { queue . enqueue ( data ); } } public T read () { return queue . isEmpty () ? null : queue . dequeue (); } }","title":"3. Buffer Implementation"},{"location":"1.Fundamentals/b.%20data_structures/#references_4","text":"Queue Introduction Queue Implementation","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#tree-based-structures_1","text":"","title":"\ud83c\udf33 Tree-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#priority-queue","text":"","title":"\ud83d\udcca Priority Queue"},{"location":"1.Fundamentals/b.%20data_structures/#introduction_3","text":"A Priority Queue is an advanced queue that orders elements by their priority rather than insertion order. It's commonly implemented using a heap data structure, typically a min-heap or max-heap. In this implementation, we'll focus on a min-heap based priority queue where lower values have higher priority.","title":"Introduction"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_6","text":"\ud83d\udcc8 Priority-based ordering \ud83c\udf33 Heap-based implementation \ud83d\udccf Dynamic sizing \ud83d\udd04 Self-balancing structure \u26a1 Logarithmic time operations","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_6","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_6","text":"public class PriorityQueue < T extends Comparable <? super T >> { // Initial capacity of the priority queue private static final int INITIAL_CAPACITY = 13 ; // Backing array for the heap private T [] backingArray ; // Number of elements in the queue private int size ; @SuppressWarnings ( \"unchecked\" ) public PriorityQueue () { backingArray = ( T [] ) new Comparable [ INITIAL_CAPACITY ] ; size = 0 ; } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_3","text":"","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#add-operation","text":"public void add ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Cannot add null data\" ); } // Resize if necessary if ( size + 1 == backingArray . length ) { resize (); } // Add element to the end and restore heap property backingArray [++ size ] = data ; upHeap ( size ); } private void upHeap ( int index ) { while ( index > 1 && backingArray [ index ] . compareTo ( backingArray [ index / 2 ] ) < 0 ) { swap ( backingArray , index , index / 2 ); index = index / 2 ; } } - \u23f1\ufe0f Time Complexity: O(log n) - \ud83d\udcad When to Use: Adding new elements with priority - \u26a0\ufe0f Key Points: - Maintains heap property - Handles resizing - Null checking","title":"Add Operation"},{"location":"1.Fundamentals/b.%20data_structures/#remove-operation","text":"public T remove () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } T removed = backingArray [ 1 ] ; backingArray [ 1 ] = backingArray [ size ] ; backingArray [ size --] = null ; if ( ! isEmpty ()) { downHeap ( 1 ); } return removed ; } private void downHeap ( int index ) { while ( 2 * index <= size ) { int j = 2 * index ; if ( j < size && backingArray [ j ] . compareTo ( backingArray [ j + 1 ] ) > 0 ) { j ++ ; } if ( backingArray [ index ] . compareTo ( backingArray [ j ] ) <= 0 ) { break ; } swap ( backingArray , index , j ); index = j ; } } - \u23f1\ufe0f Time Complexity: O(log n) - \ud83d\udcad When to Use: Removing highest priority element - \u26a0\ufe0f Key Points: - Maintains heap order - Handles empty case - Cleans references","title":"Remove Operation"},{"location":"1.Fundamentals/b.%20data_structures/#peek-operation_2","text":"public T peek () { if ( isEmpty ()) { throw new NoSuchElementException ( \"Queue is empty\" ); } return backingArray [ 1 ] ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Viewing highest priority element - \u26a0\ufe0f Key Points: - No modification to structure - Empty check","title":"Peek Operation"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_8","text":"","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_9","text":"Operation Time Complexity Notes Add/Offer O(log n) Requires upheap Remove/Poll O(log n) Requires downheap Peek O(1) Constant time isEmpty O(1) Constant time Size O(1) Constant time Clear O(1) New array allocation ### \ud83d\udca1 Best Practices #### 1. Maintain Heap Property private void swap ( T [] arr , int i , int j ) { T temp = arr [ i ] ; arr [ i ] = arr [ j ] ; arr [ j ] = temp ; } private int parent ( int index ) { return index / 2 ; } private int leftChild ( int index ) { return 2 * index ; } private int rightChild ( int index ) { return 2 * index + 1 ; } #### 2. Efficient Resizing @SuppressWarnings ( \"unchecked\" ) private void resize () { T [] newArray = ( T [] ) new Comparable [ backingArray . length * 2 ] ; for ( int i = 1 ; i <= size ; i ++ ) { newArray [ i ] = backingArray [ i ] ; } backingArray = newArray ; } #### 3. Handle Special Cases public boolean isEmpty () { return size == 0 ; } @SuppressWarnings ( \"unchecked\" ) public void clear () { backingArray = ( T [] ) new Comparable [ INITIAL_CAPACITY ] ; size = 0 ; } ### \u26a0\ufe0f Common Pitfalls #### 1. Index Management // WRONG - Using 0-based indexing private int parent ( int i ) { return ( i - 1 ) / 2 ; } // CORRECT - Using 1-based indexing private int parent ( int i ) { return i / 2 ; } #### 2. Comparator Consistency // WRONG - Inconsistent comparison if ( a . someValue () < b . someValue ()) { swap ( a , b ); } // CORRECT - Use compareTo if ( a . compareTo ( b ) < 0 ) { swap ( a , b ); } ### \ud83c\udfaf Common Use Cases #### 1. Task Scheduling class Task implements Comparable < Task > { private int priority ; private String description ; @Override public int compareTo ( Task other ) { return Integer . compare ( this . priority , other . priority ); } } PriorityQueue < Task > taskQueue = new PriorityQueue <> (); taskQueue . add ( new Task ( 1 , \"High Priority\" )); taskQueue . add ( new Task ( 3 , \"Low Priority\" )); #### 2. Dijkstra's Algorithm PriorityQueue < Node > pq = new PriorityQueue <> (( a , b ) -> Integer . compare ( a . distance , b . distance )); pq . add ( source ); while ( ! pq . isEmpty ()) { Node current = pq . remove (); // Process node } #### 3. Event Processing class Event implements Comparable < Event > { private long timestamp ; @Override public int compareTo ( Event other ) { return Long . compare ( this . timestamp , other . timestamp ); } } PriorityQueue < Event > events = new PriorityQueue <> (); events . add ( new Event ( System . currentTimeMillis ()));","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#references_5","text":"Priority Queue Introduction Priority Queue Min Heaps and Max Heaps Priority Queue Adding Elements Priority Queue Removing Elements","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#binary-tree","text":"","title":"\ud83c\udf33 Binary Tree"},{"location":"1.Fundamentals/b.%20data_structures/#introduction_4","text":"A Binary Tree is a hierarchical, non-linear data structure where each node has at most two children, referred to as left child and right child. Unlike arrays or linked lists that store data sequentially, Binary Trees allow for representing hierarchical relationships between elements.","title":"Introduction"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_7","text":"\ud83c\udf3f Each node has at most two children \ud83d\udd1d Single root node \ud83d\udcca Hierarchical structure \ud83d\udd04 Recursive nature \ud83c\udfaf Multiple traversal options","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_7","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_7","text":"public class BinaryTree < T > { private Node < T > root ; private int size ; private static class Node < T > { T data ; Node < T > left ; Node < T > right ; Node ( T data ) { this . data = data ; this . left = null ; this . right = null ; } } public BinaryTree () { root = null ; size = 0 ; } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_4","text":"","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#traversal-operations","text":"// InOrder Traversal (Left, Root, Right) public void inOrderTraversal ( Node < T > node ) { if ( node != null ) { inOrderTraversal ( node . left ); process ( node . data ); inOrderTraversal ( node . right ); } } // PreOrder Traversal (Root, Left, Right) public void preOrderTraversal ( Node < T > node ) { if ( node != null ) { process ( node . data ); preOrderTraversal ( node . left ); preOrderTraversal ( node . right ); } } // PostOrder Traversal (Left, Right, Root) public void postOrderTraversal ( Node < T > node ) { if ( node != null ) { postOrderTraversal ( node . left ); postOrderTraversal ( node . right ); process ( node . data ); } } // Level Order Traversal (BFS) public void levelOrderTraversal () { if ( root == null ) return ; Queue < Node < T >> queue = new LinkedList <> (); queue . offer ( root ); while ( ! queue . isEmpty ()) { Node < T > current = queue . poll (); process ( current . data ); if ( current . left != null ) queue . offer ( current . left ); if ( current . right != null ) queue . offer ( current . right ); } } - \u23f1\ufe0f Time Complexity: O(n) for all traversals - \ud83d\udcad When to Use: Different traversal orders for different needs - \u26a0\ufe0f Key Points: Each traversal visits all nodes exactly once","title":"Traversal Operations"},{"location":"1.Fundamentals/b.%20data_structures/#insertion-operation","text":"public void insert ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } if ( root == null ) { root = new Node <> ( data ); size ++ ; return ; } // Level-order insertion Queue < Node < T >> queue = new LinkedList <> (); queue . offer ( root ); while ( ! queue . isEmpty ()) { Node < T > current = queue . poll (); if ( current . left == null ) { current . left = new Node <> ( data ); size ++ ; return ; } else { queue . offer ( current . left ); } if ( current . right == null ) { current . right = new Node <> ( data ); size ++ ; return ; } else { queue . offer ( current . right ); } } } \u23f1\ufe0f Time Complexity: O(n) \ud83d\udcad When to Use: Adding new nodes to the tree \u26a0\ufe0f Key Points: Level-order insertion maintains tree balance","title":"Insertion Operation"},{"location":"1.Fundamentals/b.%20data_structures/#search-operation_1","text":"public boolean contains ( T data ) { return searchHelper ( root , data ); } private boolean searchHelper ( Node < T > node , T data ) { if ( node == null ) return false ; if ( node . data . equals ( data )) return true ; return searchHelper ( node . left , data ) || searchHelper ( node . right , data ); } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad When to Use: Finding elements in the tree - \u26a0\ufe0f Key Points: Must traverse potentially entire tree","title":"Search Operation"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_10","text":"","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_11","text":"Operation Time Complexity Notes Insertion O(n) Level-order insertion Search O(n) Worst case traversal Deletion O(n) Find and reorganize Traversal O(n) All traversal types Height O(n) Must visit all nodes Size O(1) Maintained variable isEmpty O(1) Check root null","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_6","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-proper-node-handling","text":"private void validate ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } }","title":"1. Proper Node Handling"},{"location":"1.Fundamentals/b.%20data_structures/#2-traversal-selection","text":"// Use appropriate traversal for the task // InOrder: Sorted sequence in BST // PreOrder: Copy/serialize tree // PostOrder: Delete tree/calculate size // LevelOrder: Level-based processing","title":"2. Traversal Selection"},{"location":"1.Fundamentals/b.%20data_structures/#3-memory-management_3","text":"public void clear () { root = null ; // Allow GC to clean up size = 0 ; }","title":"3. Memory Management"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_6","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-not-handling-null-cases","text":"// WRONG public void process ( Node < T > node ) { process ( node . left ); // NPE if node is null } // CORRECT public void process ( Node < T > node ) { if ( node == null ) return ; process ( node . left ); }","title":"1. Not Handling Null Cases"},{"location":"1.Fundamentals/b.%20data_structures/#2-improper-traversal-choice","text":"// WRONG - Using inOrder for level-based processing // CORRECT - Use levelOrder for level-based operations public void printLevelByLevel () { levelOrderTraversal (); }","title":"2. Improper Traversal Choice"},{"location":"1.Fundamentals/b.%20data_structures/#common-use-cases_3","text":"","title":"\ud83c\udfaf Common Use Cases"},{"location":"1.Fundamentals/b.%20data_structures/#1-file-system-representation","text":"class FileNode < T > extends Node < T > { boolean isDirectory ; // File system specific operations }","title":"1. File System Representation"},{"location":"1.Fundamentals/b.%20data_structures/#2-expression-trees","text":"class ExpressionNode < T > extends Node < T > { boolean isOperator ; public double evaluate () { // Evaluation logic } }","title":"2. Expression Trees"},{"location":"1.Fundamentals/b.%20data_structures/#3-decision-trees","text":"class DecisionNode < T > extends Node < T > { boolean isLeaf ; public T decide ( Input input ) { // Decision logic } }","title":"3. Decision Trees"},{"location":"1.Fundamentals/b.%20data_structures/#references_6","text":"Binary Tree Data Structure","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#binary-search-tree","text":"","title":"\ud83c\udf33 Binary Search Tree"},{"location":"1.Fundamentals/b.%20data_structures/#introduction_5","text":"A Binary Search Tree (BST) is a binary tree that maintains an ordering property: for each node, all elements in its left subtree are less than the node's value, and all elements in its right subtree are greater. This property makes BSTs efficient for searching, inserting, and deleting elements.","title":"Introduction"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_8","text":"\ud83d\udcca Ordered structure \ud83d\udd0d Efficient searching \ud83c\udfaf Dynamic operations \ud83c\udf3f Binary tree properties \u2696\ufe0f Balance affects performance","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_8","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_8","text":"public class BST < T extends Comparable <? super T >> { private BSTNode < T > root ; private int size ; private static class BSTNode < T > { T data ; BSTNode < T > left ; BSTNode < T > right ; BSTNode ( T data ) { this . data = data ; left = null ; right = null ; } } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_5","text":"","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#add-operation_1","text":"public void add ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } root = addHelper ( data , root ); } private BSTNode < T > addHelper ( T data , BSTNode < T > node ) { if ( node == null ) { size ++ ; return new BSTNode <> ( data ); } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { node . left = addHelper ( data , node . left ); } else if ( compare > 0 ) { node . right = addHelper ( data , node . right ); } return node ; } - \u23f1\ufe0f Time Complexity: O(log n) average, O(n) worst case - \ud83d\udcad When to Use: Inserting new elements while maintaining order - \u26a0\ufe0f Key Points: - Maintains BST property - Handles duplicates - Recursive implementation","title":"Add Operation"},{"location":"1.Fundamentals/b.%20data_structures/#remove-operation_1","text":"public T remove ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } BSTNode < T > dummy = new BSTNode <> ( null ); root = removeHelper ( data , root , dummy ); return dummy . data ; } private BSTNode < T > removeHelper ( T data , BSTNode < T > node , BSTNode < T > dummy ) { if ( node == null ) { throw new NoSuchElementException ( \"Data not found\" ); } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { node . left = removeHelper ( data , node . left , dummy ); } else if ( compare > 0 ) { node . right = removeHelper ( data , node . right , dummy ); } else { dummy . data = node . data ; size -- ; if ( node . left == null ) { return node . right ; } else if ( node . right == null ) { return node . left ; } else { BSTNode < T > successor = findSuccessor ( node . right ); node . data = successor . data ; node . right = removeHelper ( successor . data , node . right , dummy ); } } return node ; } - \u23f1\ufe0f Time Complexity: O(log n) average, O(n) worst case - \ud83d\udcad When to Use: Removing elements while maintaining order - \u26a0\ufe0f Key Points: - Three cases: leaf, one child, two children - Uses successor for two-child case - Maintains BST property","title":"Remove Operation"},{"location":"1.Fundamentals/b.%20data_structures/#search-operation_2","text":"public T get ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } BSTNode < T > node = getHelper ( data , root ); if ( node == null ) { throw new NoSuchElementException ( \"Data not found\" ); } return node . data ; } private BSTNode < T > getHelper ( T data , BSTNode < T > node ) { if ( node == null ) { return null ; } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { return getHelper ( data , node . left ); } else if ( compare > 0 ) { return getHelper ( data , node . right ); } return node ; } - \u23f1\ufe0f Time Complexity: O(log n) average, O(n) worst case - \ud83d\udcad When to Use: Finding elements in the tree - \u26a0\ufe0f Key Points: - Uses comparisons for direction - Returns stored data - Handles not found case","title":"Search Operation"},{"location":"1.Fundamentals/b.%20data_structures/#traversal-operations_1","text":"// In-order traversal (sorted order) public List < T > inorder () { List < T > result = new ArrayList <> (); inorderHelper ( root , result ); return result ; } private void inorderHelper ( BSTNode < T > node , List < T > result ) { if ( node != null ) { inorderHelper ( node . left , result ); result . add ( node . data ); inorderHelper ( node . right , result ); } } - \u23f1\ufe0f Time Complexity: O(n) - \ud83d\udcad When to Use: Getting elements in sorted order - \u26a0\ufe0f Key Points: - In-order gives sorted sequence - Pre-order for copying tree - Post-order for deletion","title":"Traversal Operations"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_12","text":"Operation Average Case Worst Case Notes Insert O(log n) O(n) Unbalanced case Remove O(log n) O(n) Unbalanced case Search O(log n) O(n) Unbalanced case Traversal O(n) O(n) Visits all nodes Height O(1) O(1) Cached value Size O(1) O(1) Maintained count","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_7","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-balance-maintenance","text":"// Consider using self-balancing variants for better performance guarantees // AVL or Red-Black trees for automatic balancing","title":"1. Balance Maintenance"},{"location":"1.Fundamentals/b.%20data_structures/#2-comparison-handling","text":"// Use compareTo consistently int compare = data . compareTo ( node . data ); if ( compare < 0 ) { // Go left } else if ( compare > 0 ) { // Go right }","title":"2. Comparison Handling"},{"location":"1.Fundamentals/b.%20data_structures/#3-null-handling","text":"// Always validate input if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); }","title":"3. Null Handling"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_7","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-unbalanced-trees","text":"// WRONG - Adding sorted data creates linear structure bst . add ( 1 ); bst . add ( 2 ); bst . add ( 3 ); // Creates right-skewed tree // BETTER - Balance the tree or use self-balancing variant","title":"1. Unbalanced Trees"},{"location":"1.Fundamentals/b.%20data_structures/#2-memory-management","text":"// WRONG - Memory leak in remove node = null ; // Only removes reference // CORRECT - Clean all references node . left = null ; node . right = null ; node . data = null ; node = null ;","title":"2. Memory Management"},{"location":"1.Fundamentals/b.%20data_structures/#common-use-cases_4","text":"","title":"\ud83c\udfaf Common Use Cases"},{"location":"1.Fundamentals/b.%20data_structures/#1-dictionary-implementation","text":"BST < String > dictionary = new BST <> (); dictionary . add ( \"apple\" ); dictionary . add ( \"banana\" ); // Fast lookups: O(log n) average","title":"1. Dictionary Implementation"},{"location":"1.Fundamentals/b.%20data_structures/#2-priority-management","text":"BST < Task > tasks = new BST <> (); tasks . add ( new Task ( 1 , \"High Priority\" )); tasks . add ( new Task ( 2 , \"Medium Priority\" )); // Natural ordering of tasks","title":"2. Priority Management"},{"location":"1.Fundamentals/b.%20data_structures/#3-symbol-tables","text":"BST < Symbol > symbolTable = new BST <> (); symbolTable . add ( new Symbol ( \"x\" , 10 )); symbolTable . add ( new Symbol ( \"y\" , 20 )); // Efficient symbol lookup","title":"3. Symbol Tables"},{"location":"1.Fundamentals/b.%20data_structures/#references_7","text":"Binary Search Trees Binary Search Tree Introduction Binary Search Tree Insertion Binary Search Tree Removal Binary Search Tree Traversal","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#advanced-tree-based-structures_1","text":"","title":"\ud83c\udf32 Advanced Tree-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#avl-trees","text":"An AVL Tree is a self-balancing bin tree where the heights of the left and right subtrees of any node differ by at most one. This balance ot ensures that the tree remains approximately balanced during insertion deletions, maintaining O(log n) time complexity for all operations.","title":"\ud83c\udf33 AVL Trees"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_9","text":"\ud83d\udd04 Self-balancing mechanism \ud83d\udccf Height tracking \u2696\ufe0f Balance factor management \ud83c\udfaf BST properties maintained \ud83d\udd0d Guaranteed O(log n) operations","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_9","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_9","text":"public class AVLTree < T extends Comparable <? super T >> { AVLNode < T > root ; private int size ; private static class AVLNode < T > { T data ; AVLNode < T > left ; AVLNode < T > right ; int height ; int balanceFactor ; AVLNode ( T data ) { this . data = data ; this . height = 0 ; this . balanceFactor = 0 ; } } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#node-properties","text":"data : Stores the actual value/element left : Reference to left child n lement etil ri clrenco right child node height : Distance to the furthest leaf in its subtree balanceFactor : Difference between left and right subtree heights","title":"Node Properties"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_6","text":"Balance Helper Methods private int height ( AVLNode < T > node ) { return node == null ? - 1 : node . height ; } private void updateHeightAndBF ( AVLNode < T > node ) { int leftHeight = height ( node . left ); int rightHeight = height ( node . right ); node . height = Math . max ( leftHeight , rightHeight ) + 1 ; node . balanceFactor = leftHeight - rightHeight ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: After any structural changes - \u26a0\ufe0f Key Points: - Height of null node is -1 - Balance factor = leftHeight - rightHeight - Must update after rotations","title":"\ud83d\udd27 Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#rotation-operations","text":"private AVLNode < T > rotateLeft ( AVLNode < T > node ) { AVLNode < T > newRoot = node . right ; node . right = newRoot . left ; newRoot . left = node ; updateHeightAndBF ( node ); updateHeightAndBF ( newRoot ); return newRoot ; } private AVLNode < T > rotateRight ( AVLNode < T > node ) { AVLNode < T > newRoot = node . left ; node . left = newRoot . right ; newRoot . right = node ; updateHeightAndBF ( node ); updateHeightAndBF ( newRoot ); return newRoot ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: Rebalancing after insertions/deletions - \u26a0\ufe0f Key Points: - Update heights after rotation - Maintain BST properties - Return new root of subtree","title":"Rotation Operations"},{"location":"1.Fundamentals/b.%20data_structures/#balance-operation","text":"private AVLNode < T > balance ( AVLNode < T > node ) { updateHeightAndBF ( node ); if ( node . balanceFactor < - 1 ) { // Right heavy if ( node . right . balanceFactor > 0 ) { // Right-Left case node . right = rotateRight ( node . right ); } return rotateLeft ( node ); } else if ( node . balanceFactor > 1 ) { // Left heavy if ( node . left . balanceFactor < 0 ) { // Left-Right case node . left = rotateLeft ( node . left ); } return rotateRight ( node ); } return node ; } - \u23f1\ufe0f Time Complexity: O(1) - \ud83d\udcad When to Use: After modifications that might affect balance - \u26a0\ufe0f Key Points: - Handles all four rotation cases - Updates height before checking balance - Returns balanced subtree root","title":"Balance Operation"},{"location":"1.Fundamentals/b.%20data_structures/#add-operation_2","text":"public void add ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null\" ); } root = addHelper ( data , root ); } private AVLNode < T > addHelper ( T data , AVLNode < T > node ) { if ( node == null ) { size ++ ; return new AVLNode <> ( data ); } int compare = data . compareTo ( node . data ); if ( compare < 0 ) { node . left = addHelper ( data , node . left ); } else if ( compare > 0 ) { node . right = addHelper ( data , node . right ); } return balance ( node ); } - \u23f1\ufe0f Time Complexity: O(log n) - \ud83d\udcad When to Use: Adding new elements - \u26a0\ufe0f Key Points: - BST properties maintained - Auto-balancing after insertion - Uses pointer reinforcement","title":"Add Operation"},{"location":"1.Fundamentals/b.%20data_structures/#performance-summary_13","text":"Operation Average Case Worst Case Notes Add O(log n) O(log n) Includes rebalancing Remove O(log n) O(log n) Includes rebalancing Search O(log n) O(log n) Same as BST Rotation O(1) O(1) Height updates included Balance O(1) O(1) Maximum two rotations Height O(1) O(1) Cached in node","title":"\ud83d\udcca Performance Summary"},{"location":"1.Fundamentals/b.%20data_structures/#visualization-of-rotations","text":"","title":"\ud83c\udfaf Visualization of Rotations"},{"location":"1.Fundamentals/b.%20data_structures/#left-rotation","text":"Before: After: A B \\ / \\ B => A C \\ C","title":"Left Rotation"},{"location":"1.Fundamentals/b.%20data_structures/#right-rotation","text":"Before: After: C B / / \\ B => A C / A","title":"Right Rotation"},{"location":"1.Fundamentals/b.%20data_structures/#double-rotation-left-right","text":"Before: Middle: After: C C B / / / \\ A => B => A C \\ / B A","title":"Double Rotation (Left-Right)"},{"location":"1.Fundamentals/b.%20data_structures/#double-rotation-right-left","text":"Before: Middle: After: A A B \\ \\ / \\ C => B => A C / \\ B C","title":"Double Rotation (Right-Left)"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_8","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-height-management","text":"// Always update heights bottom-up updateHeightAndBF ( node ); if ( node . parent != null ) { updateHeightAndBF ( node . parent ); }","title":"1. Height Management"},{"location":"1.Fundamentals/b.%20data_structures/#2-balance-factor-checks","text":"// Check both balance factor and height if ( Math . abs ( node . balanceFactor ) > 1 ) { return balance ( node ); }","title":"2. Balance Factor Checks"},{"location":"1.Fundamentals/b.%20data_structures/#3-rotation-selection","text":"// Clear conditions for rotation type if ( node . balanceFactor > 1 ) { // Left heavy if ( node . left . balanceFactor < 0 ) { // Left-Right case node . left = rotateLeft ( node . left ); } return rotateRight ( node ); }","title":"3. Rotation Selection"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_8","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-incorrect-height-updates","text":"// WRONG - Not updating ancestor heights node = balance ( node ); // CORRECT - Update all affected nodes node = balance ( node ); updateAncestorHeights ( node );","title":"1. Incorrect Height Updates"},{"location":"1.Fundamentals/b.%20data_structures/#2-balance-factor-calculation","text":"// WRONG - Swapped height difference balanceFactor = rightHeight - leftHeight ; // CORRECT balanceFactor = leftHeight - rightHeight ;","title":"2. Balance Factor Calculation"},{"location":"1.Fundamentals/b.%20data_structures/#references_8","text":"AVL Trees Simply Explained Red-Black Trees in 4 min 2-3 Trees K-D Trees M-Ary Trees","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#hash-based-structures_1","text":"","title":"\ud83c\udfaf Hash-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#hashmaps","text":"A HashMap is a data structure that implements the Map ADT, storing key-value pairs for O(1) average-case access time. This implementation uses separate chaining for collision resolution, where collisions are handled by maintaining linked lists at each array index.","title":"#\ufe0f\u20e3 HashMaps"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_10","text":"\ud83d\udd11 Unique Key Mapping Each key can map to only one value Keys must be immutable Values can be modified or duplicated Perfect for one-to-one relationships \u26a1 Constant-Time Operations O(1) average case for insertions O(1) average case for retrievals O(1) average case for deletions Performance dependent on hash function quality \ud83c\udfaf Hash Distribution Converts keys to array indices via hashing Uses hashCode() method for initial hash Compresses hash to fit array bounds Aims for uniform distribution of keys \u26d3\ufe0f Collision Management Handles key collisions using linked lists Each array index can store multiple entries Entries in same bucket form a chain Search within chain is O(n) worst case \u2696\ufe0f Load Factor Control Maintains ratio of size to capacity Typically keeps load factor below 0.67 Triggers resizing when threshold reached Prevents performance degradation Uses prime number capacities for better distribution \ud83d\udd04 Dynamic Resizing Doubles capacity when load factor exceeded Adds 1 to ensure prime capacity Rehashes all existing entries Maintains performance characteristics","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_10","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#node-structure","text":"private static class Node < K , V > { K key ; V value ; Node < K , V > next ; Node ( K key , V value ) { this . key = key ; this . value = value ; this . next = null ; } }","title":"Node Structure"},{"location":"1.Fundamentals/b.%20data_structures/#basic-class-structure","text":"public class HashMap < K , V > { private Node < K , V >[] table ; private int size ; private static final int INITIAL_CAPACITY = 13 ; // Prime number private static final double MAX_LOAD_FACTOR = 0.67 ; @SuppressWarnings ( \"unchecked\" ) public HashMap () { table = ( Node < K , V >[] ) new Node [ INITIAL_CAPACITY ] ; size = 0 ; } }","title":"Basic Class Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_7","text":"","title":"Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#put-operation","text":"public V put ( K key , V value ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } // Check if resize is needed if (( double ) ( size + 1 ) / table . length > MAX_LOAD_FACTOR ) { resize (); } int index = getIndex ( key ); // Check if key already exists Node < K , V > current = table [ index ] ; while ( current != null ) { if ( current . key . equals ( key )) { V oldValue = current . value ; current . value = value ; return oldValue ; } current = current . next ; } // Add new node at the beginning of the chain Node < K , V > newNode = new Node <> ( key , value ); newNode . next = table [ index ] ; table [ index ] = newNode ; size ++ ; return null ; } private int getIndex ( K key ) { return Math . abs ( key . hashCode () % table . length ); }","title":"Put Operation"},{"location":"1.Fundamentals/b.%20data_structures/#get-operation","text":"public V get ( K key ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } int index = getIndex ( key ); Node < K , V > current = table [ index ] ; while ( current != null ) { if ( current . key . equals ( key )) { return current . value ; } current = current . next ; } return null ; }","title":"Get Operation"},{"location":"1.Fundamentals/b.%20data_structures/#remove-operation_2","text":"public V remove ( K key ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } int index = getIndex ( key ); Node < K , V > current = table [ index ] ; Node < K , V > prev = null ; while ( current != null ) { if ( current . key . equals ( key )) { if ( prev == null ) { table [ index ] = current . next ; } else { prev . next = current . next ; } size -- ; return current . value ; } prev = current ; current = current . next ; } return null ; }","title":"Remove Operation"},{"location":"1.Fundamentals/b.%20data_structures/#resize-operation","text":"@SuppressWarnings ( \"unchecked\" ) private void resize () { int newCapacity = ( 2 * table . length ) + 1 ; // Prime number Node < K , V >[] oldTable = table ; table = ( Node < K , V >[] ) new Node [ newCapacity ] ; size = 0 ; // Rehash all existing entries for ( Node < K , V > head : oldTable ) { Node < K , V > current = head ; while ( current != null ) { put ( current . key , current . value ); current = current . next ; } } }","title":"Resize Operation"},{"location":"1.Fundamentals/b.%20data_structures/#performance-characteristics","text":"Operation Average Case Worst Case Notes Put O(1) O(n) When chain degrades to linked list Get O(1) O(n) When chain degrades to linked list Remove O(1) O(n) When chain degrades to linked list Space O(n) O(n) n = number of key-value pairs","title":"Performance Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_9","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-load-factor-management","text":"private boolean needsResize () { return ( double ) size / table . length > MAX_LOAD_FACTOR ; }","title":"1. Load Factor Management"},{"location":"1.Fundamentals/b.%20data_structures/#2-key-quality","text":"// Override hashCode() in key objects @Override public int hashCode () { int hash = 17 ; hash = 31 * hash + field1 . hashCode (); hash = 31 * hash + field2 . hashCode (); return hash ; }","title":"2. Key Quality"},{"location":"1.Fundamentals/b.%20data_structures/#3-proper-equals-implementation","text":"@Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null || getClass () != obj . getClass ()) return false ; MyKey other = ( MyKey ) obj ; return field1 . equals ( other . field1 ) && field2 . equals ( other . field2 ); }","title":"3. Proper Equals Implementation"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_9","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-poor-hash-distribution","text":"// WRONG: Poor hash function public int hashCode () { return 1 ; // All items hash to same bucket } // BETTER: Good distribution public int hashCode () { return Objects . hash ( field1 , field2 ); }","title":"1. Poor Hash Distribution"},{"location":"1.Fundamentals/b.%20data_structures/#2-missing-null-checks","text":"// WRONG: No null check public V put ( K key , V value ) { int index = key . hashCode () % table . length ; // NullPointerException! // CORRECT: With null check public V put ( K key , V value ) { if ( key == null ) { throw new IllegalArgumentException ( \"Key cannot be null\" ); } int index = getIndex ( key ); HashMaps provide efficient key-value storage with constant-time average case operations, making them ideal for lookup-intensive applications. The separate chaining implementation offers a good balance between simplicity and performance.","title":"2. Missing Null Checks"},{"location":"1.Fundamentals/b.%20data_structures/#references_9","text":"HashTables with Collision Management","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#graph-based-structures_1","text":"A Graph is a data structure that models relationships between elements using vertices (nodes) and edges. This implementation represents a directed graph using vertex and edge sets along with an adjacency list representation for efficient neighbor access.","title":"\ud83d\udd78\ufe0f Graph-Based Structures"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_11","text":"\ud83d\udd0d Vertex Management Each vertex contains generic typed data Vertices are unique based on data equality Supports null-safe vertex operations Maintains a vertex set for O(1) lookups \ud83d\udd17 Edge Properties Directed edges from vertex u to v Weighted connections Maintains edge set for global access Supports undirected graphs via bidirectional edges \ud83d\udcca Adjacency Structure Maps vertices to neighbor lists Includes edge weights in adjacency entries Efficient neighbor access Space-efficient for sparse graphs","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_11","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#vertex-class","text":"public class Vertex < T > { private T data ; public Vertex ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Data cannot be null.\" ); } this . data = data ; } public T getData () { return data ; } @Override public boolean equals ( Object o ) { if ( o != null && o instanceof Vertex ) { return data . equals ((( Vertex <?> ) o ). data ); } return false ; } @Override public int hashCode () { return data . hashCode (); } }","title":"Vertex Class"},{"location":"1.Fundamentals/b.%20data_structures/#edge-class","text":"public class Edge < T > implements Comparable < Edge <? super T >> { private Vertex < T > u ; // Source vertex private Vertex < T > v ; // Destination vertex private int weight ; // Edge weight public Edge ( Vertex < T > u , Vertex < T > v , int weight ) { if ( u == null || v == null ) { throw new IllegalArgumentException ( \"Arguments cannot be null.\" ); } this . u = u ; this . v = v ; this . weight = weight ; } public Vertex < T > getU () { return u ; } public Vertex < T > getV () { return v ; } public int getWeight () { return weight ; } @Override public int compareTo ( Edge <? super T > e ) { return weight - e . getWeight (); } }","title":"Edge Class"},{"location":"1.Fundamentals/b.%20data_structures/#graph-structure","text":"public class Graph < T > { private Set < Vertex < T >> vertices ; private Set < Edge < T >> edges ; private Map < Vertex < T > , List < VertexDistance < T >>> adjList ; public Graph ( Set < Vertex < T >> vertices , Set < Edge < T >> edges ) { if ( vertices == null || edges == null ) { throw new IllegalArgumentException ( \"Arguments cannot be null.\" ); } this . vertices = new HashSet <> ( vertices ); this . edges = new HashSet <> ( edges ); this . adjList = new HashMap <> (); // Initialize adjacency list for ( Vertex < T > v : vertices ) { adjList . put ( v , new ArrayList <> ()); } // Populate adjacency list for ( Edge < T > e : edges ) { if ( adjList . containsKey ( e . getU ())) { adjList . get ( e . getU ()). add ( new VertexDistance <> ( e . getV (), e . getWeight ()) ); } else { throw new IllegalArgumentException ( \"Vertex set must contain all vertices of the graph.\" ); } } } }","title":"Graph Structure"},{"location":"1.Fundamentals/b.%20data_structures/#vertex-distance-helper","text":"public final class VertexDistance < T > implements Comparable < VertexDistance <? super T >> { private final Vertex < T > vertex ; private final int distance ; public VertexDistance ( Vertex < T > vertex , int distance ) { this . vertex = vertex ; this . distance = distance ; } @Override public int compareTo ( VertexDistance <? super T > pair ) { return this . distance - pair . getDistance (); } }","title":"Vertex Distance Helper"},{"location":"1.Fundamentals/b.%20data_structures/#performance-characteristics_1","text":"Operation Average Case Worst Case Notes Add Vertex O(1) O(1) HashSet insertion Add Edge O(1) O(1) HashSet & ArrayList insertion Find Vertex O(1) O(1) HashSet lookup Find Edge O(1) O(1) HashSet lookup Get Neighbors O(1) O(1) HashMap & ArrayList access Space O(V + E) O(V + E) V vertices + E edges","title":"Performance Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_10","text":"","title":"Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-creating-undirected-edges","text":"// Add both directions for undirected edges vertices . add ( vertexA ); vertices . add ( vertexB ); edges . add ( new Edge <> ( vertexA , vertexB , weight )); edges . add ( new Edge <> ( vertexB , vertexA , weight ));","title":"1. Creating Undirected Edges"},{"location":"1.Fundamentals/b.%20data_structures/#2-vertex-creation","text":"// Ensure data validity public static < T > Vertex < T > createVertex ( T data ) { if ( data == null ) { throw new IllegalArgumentException ( \"Vertex data cannot be null\" ); } return new Vertex <> ( data ); }","title":"2. Vertex Creation"},{"location":"1.Fundamentals/b.%20data_structures/#4-edge-validation","text":"private boolean isValidEdge ( Edge < T > edge ) { return vertices . contains ( edge . getU ()) && vertices . contains ( edge . getV ()); }","title":"4. Edge Validation"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_10","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-missing-graph-initialization","text":"// WRONG: Uninitialized collections public Graph () { // Missing initialization } // CORRECT: Properly initialized collections public Graph ( Set < Vertex < T >> vertices , Set < Edge < T >> edges ) { this . vertices = new HashSet <> ( vertices ); this . edges = new HashSet <> ( edges ); this . adjList = new HashMap <> (); // ... rest of initialization }","title":"1. Missing Graph Initialization"},{"location":"1.Fundamentals/b.%20data_structures/#2-improper-edge-direction-handling","text":"// WRONG: Assuming bidirectional adjList . get ( edge . getV ()). add ( new VertexDistance <> ( edge . getU (), edge . getWeight ())); // CORRECT: Respecting edge direction adjList . get ( edge . getU ()). add ( new VertexDistance <> ( edge . getV (), edge . getWeight ())); This implementation provides a robust foundation for directed graph operations while maintaining type safety and efficient operations through appropriate data structure choices.","title":"2. Improper Edge Direction Handling"},{"location":"1.Fundamentals/b.%20data_structures/#references_10","text":"Introduction to Graphs","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#disjoint-sets-union-find","text":"A Disjoint Set (Union-Find) is a data structure that keeps track of elements partitioned into non-overlapping sets. It provides near-constant time operations to check if two elements are in the same set and to unite two sets, making it essential for algorithms like Kruskal's MST.","title":"\ud83c\udf33 Disjoint-Sets: Union-Find"},{"location":"1.Fundamentals/b.%20data_structures/#core-characteristics_12","text":"\ud83c\udf33 Tree-Based Structure Each set is represented as a tree Elements point to their parent elements Root element represents the set identifier Path compression for efficiency \ud83d\udd0d Find Operation Identifies the set an element belongs to Implements path compression Returns the root element Amortized O(1) time complexity \ud83e\udd1d Union Operation Merges two different sets Uses union by rank Maintains tree balance Prevents deep hierarchies","title":"Core Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#implementation-details_12","text":"","title":"Implementation Details"},{"location":"1.Fundamentals/b.%20data_structures/#structure_10","text":"private static class DisjointSetNode < T > { private DisjointSetNode < T > parent ; private T data ; private int rank ; public DisjointSetNode ( T data ) { this . parent = this ; // Node initially points to itself this . data = data ; this . rank = 0 ; } }","title":"Structure"},{"location":"1.Fundamentals/b.%20data_structures/#base-structure","text":"public class DisjointSet < T > { private Map < T , DisjointSetNode < T >> disjointSet ; public DisjointSet () { disjointSet = new HashMap <> (); } }","title":"Base Structure"},{"location":"1.Fundamentals/b.%20data_structures/#core-operations_8","text":"","title":"Core Operations"},{"location":"1.Fundamentals/b.%20data_structures/#find-operation","text":"public T find ( T data ) { if ( ! disjointSet . containsKey ( data )) { disjointSet . put ( data , new DisjointSetNode <> ( data )); } return find ( disjointSet . get ( data )). getData (); } private DisjointSetNode < T > find ( DisjointSetNode < T > curr ) { DisjointSetNode < T > parent = curr . getParent (); if ( parent == curr ) { return curr ; // Found root } // Path compression: Make all nodes point to root parent = find ( curr . getParent ()); curr . setParent ( parent ); return parent ; }","title":"Find Operation"},{"location":"1.Fundamentals/b.%20data_structures/#performance-characteristics_2","text":"Operation Amortized Time Worst Case Notes Make Set O(1) O(1) Creates new set Find O(\u03b1(n)) O(log n) With path compression Union O(\u03b1(n)) O(log n) With union by rank Space O(n) O(n) n elements Note: \u03b1(n) is the inverse Ackermann function, which grows extremely slowly and is effectively constant for all practical values of n.","title":"\ud83d\udcca Performance Characteristics"},{"location":"1.Fundamentals/b.%20data_structures/#best-practices_11","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/b.%20data_structures/#1-path-compression","text":"// Always update parent pointers during find private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { if ( node != node . getParent ()) { node . setParent ( find ( node . getParent ())); // Compress path } return node . getParent (); }","title":"1. Path Compression"},{"location":"1.Fundamentals/b.%20data_structures/#2-union-by-rank","text":"// Always consider ranks when unioning if ( firstParent . getRank () < secondParent . getRank ()) { firstParent . setParent ( secondParent ); } else { secondParent . setParent ( firstParent ); if ( firstParent . getRank () == secondParent . getRank ()) { firstParent . setRank ( firstParent . getRank () + 1 ); } }","title":"2. Union by Rank"},{"location":"1.Fundamentals/b.%20data_structures/#3-lazy-initialization","text":"public T find ( T data ) { if ( ! disjointSet . containsKey ( data )) { disjointSet . put ( data , new DisjointSetNode <> ( data )); } // Continue with find operation }","title":"3. Lazy Initialization"},{"location":"1.Fundamentals/b.%20data_structures/#common-pitfalls_11","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/b.%20data_structures/#1-missing-path-compression","text":"// WRONG: No path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { while ( node != node . getParent ()) { node = node . getParent (); } return node ; } // CORRECT: With path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { if ( node != node . getParent ()) { node . setParent ( find ( node . getParent ())); } return node . getParent (); }","title":"1. Missing Path Compression"},{"location":"1.Fundamentals/b.%20data_structures/#2-incorrect-union-operation","text":"// WRONG: No path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { while ( node != node . getParent ()) { node = node . getParent (); } return node ; } // CORRECT: With path compression private DisjointSetNode < T > find ( DisjointSetNode < T > node ) { if ( node != node . getParent ()) { node . setParent ( find ( node . getParent ())); } return node . getParent (); } This implementation provides an efficient foundation for set operations used in graph algorithms, particularly Kruskal's Minimum Spanning Tree algorithm, with optimizations for both time and space complexity.","title":"2. Incorrect Union Operation"},{"location":"1.Fundamentals/b.%20data_structures/#references_11","text":"Union Find Data Structure","title":"References"},{"location":"1.Fundamentals/b.%20data_structures/#other-advanced-structures","text":"","title":"\ud83d\udcda Other Advanced Structures"},{"location":"1.Fundamentals/b.%20data_structures/#trie","text":"Trie","title":"\ud83d\udd0e Trie"},{"location":"1.Fundamentals/b.%20data_structures/#skip-lists","text":"Skip List Introduction Skip Lists Insertion and Deletion","title":"\ud83d\udd0e Skip Lists"},{"location":"1.Fundamentals/c.%20algorithms/","text":"\ud83d\udcd8 Introduction to Algorithms \u00b6 Algorithms are systematic procedures for solving computational problems and manipulating data. Understanding algorithms is crucial for developing efficient software solutions and optimizing program performance. This guide explores essential algorithms, their implementations, and practical applications in software engineering. \ud83c\udfaf Why Algorithms Matter \u00b6 \ud83d\ude80 Performance Optimization : Choose the right algorithm to dramatically improve execution speed \ud83d\udcbb System Scalability : Build solutions that efficiently handle growing data volumes \ud83d\udcbc Technical Interviews : Essential knowledge for coding interviews at top tech companies \ud83d\udd04 Problem-Solving : Master fundamental approaches to computational challenges \ud83c\udf1f Competitive Programming : Critical for algorithmic contests and competitions \ud83d\udcda Guide Structure \u00b6 Each algorithm section covers: Step-by-step explanation Implementation details Time and space complexity analysis Common optimization techniques Best practices and use cases Code examples and gotchas \ud83d\uddc2\ufe0f Categories of Algorithms \u00b6 \ud83d\udcca Sorting Algorithms \u00b6 Transform unordered collections into ordered sequences: Bubble Sort : Simple comparison-based sorting Best for: Educational purposes, tiny datasets Selection Sort : In-place comparison sorting Best for: Small arrays, minimal memory Insertion Sort : Adaptive, stable sorting Best for: Nearly sorted data, online sorting Heap Sort : Comparison-based sorting using heap Best for: Large datasets, guaranteed performance Quick Sort : Divide-and-conquer approach Best for: General-purpose sorting, large datasets Merge Sort : Stable, divide-and-conquer sorting Best for: Linked lists, external sorting \ud83d\udd0d Searching Algorithms \u00b6 Efficiently locate elements in datasets: Linear Search : Sequential element checking Best for: Small or unsorted datasets Binary Search : Divide-and-conquer searching Best for: Sorted arrays, large datasets \ud83d\udd78\ufe0f Graph Algorithms \u00b6 Navigate and analyze network structures: Breadth First Search (BFS) : Level-by-level traversal Best for: Shortest paths, web crawling Depth First Search (DFS) : Deep traversal exploration Best for: Maze solving, topological sorting Bellman Ford's Algorithm : Single-source shortest paths Best for: Graphs with negative edges Dijkstra's Algorithm : Efficient shortest path finding Best for: GPS, network routing __A_ Algorithm_*: Heuristic pathfinding Best for: Game AI, navigation systems \ud83c\udfaf Greedy Algorithms \u00b6 Make locally optimal choices: Huffman Coding : Data compression Best for: File compression, encoding Kruskal's Algorithm : Minimum spanning tree Best for: Network design Ford-Fulkerson Algorithm : Maximum flow problems Best for: Network flow optimization Prim's Algorithm : Minimum spanning tree Best for: Dense graphs \ud83d\udd24 Substring Search Algorithms \u00b6 Pattern matching in text: Brute Force Search : Simple pattern matching Best for: Short patterns Rabin-Karp : Hash-based pattern matching Best for: Multiple pattern search Knuth-Morris-Pratt : Efficient single pattern matching Best for: Single pattern in large text Boyer-Moore : Fast pattern matching Best for: Long patterns \u23f1\ufe0f Time Complexity Overview \u00b6 Algorithm Best Case Average Case Worst Case Space Bubble Sort O(n) O(n\u00b2) O(n\u00b2) O(1) Selection Sort O(n\u00b2) O(n\u00b2) O(n\u00b2) O(1) Insertion Sort O(n) O(n\u00b2) O(n\u00b2) O(1) Heap Sort O(n log n) O(n log n) O(n log n) O(1) Quick Sort O(n log n) O(n log n) O(n\u00b2) O(log n) Merge Sort O(n log n) O(n log n) O(n log n) O(n) Linear Search O(1) O(n) O(n) O(1) Binary Search O(1) O(log n) O(log n) O(1) BFS O(V + E) O(V + E) O(V + E) O(V) DFS O(V + E) O(V + E) O(V + E) O(V) Bellman Ford O(VE) O(VE) O(VE) O(V) Dijkstra O(E log V) O(E log V) O(E log V) O(V) A* O(E) O(E) O(V\u00b2) O(V) Huffman Coding O(n log n) O(n log n) O(n log n) O(n) Kruskal's Algorithm O(E log E) O(E log E) O(E log E) O(V) Ford-Fulkerson O(EF)* O(EF)* O(EF)* O(V + E) Prim's Algorithm O(E log V) O(E log V) O(E log V) O(V) Brute Force Search O(n) O(mn) O(mn) O(1) Rabin-Karp O(m + n) O(m + n) O(mn) O(1) Knuth-Morris-Pratt O(m + n) O(m + n) O(m + n) O(m) Boyer-Moore O(n/m) O(n) O(mn) O(m) References \u00b6 Data Structures and Algorithms Notes \ud83d\udd04 Sorting Algorithms \u00b6 Introduction \u00b6 Sorting algorithms are fundamental procedures that arrange elements in a specific order, typically in ascending or descending sequence. Understanding these algorithms is crucial for efficient data manipulation and problem-solving in software development. \ud83d\udcd8 Overview \u00b6 Sorting algorithms are fundamental procedures that organize data in a specific order. Understanding these algorithms is crucial for: \ud83c\udfaf Efficient Data Organization : Transform unordered data into ordered sequences \ud83d\udcbb Performance Optimization : Choose the right algorithm for your data size and type \ud83d\udd0d Interview Preparation : Common technical interview topic \ud83e\uddee Algorithm Foundation : Building block for more complex algorithms \ud83d\udcca Data Analysis : Essential for data processing and analysis \ud83d\udcdd Common Characteristics \u00b6 \ud83c\udfaf Algorithm Properties \u00b6 Stability : Whether relative order of equal elements is preserved In-Place : Whether additional space is required Adaptivity : Whether performance improves with partially sorted data \u26a1 Performance Metrics \u00b6 Time Complexity : How runtime scales with input size Space Complexity : How memory usage scales with input size Best/Worst Cases : Performance bounds under different conditions \ud83d\udd0d Basic Sorting Algorithms \u00b6 \ud83d\udd0e Implementation Details \u00b6 1\ufe0f\u20e3 Bubble Sort \u00b6 A simple comparison-based algorithm that repeatedly steps through the list. \ud83d\udcca Properties \u00b6 \u2705 In-place sorting \u2705 Stable algorithm \u2705 Adaptive behavior \ud83d\udd04 Time: O(n\u00b2) worst/average, O(n) best \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Educational purposes Tiny datasets When simplicity is preferred over efficiency Teaching sorting concepts public static < T > void bubbleSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { boolean swapped = false ; for ( int j = 0 ; j < arr . length - i - 1 ; j ++ ) { if ( comparator . compare ( arr [ j ] , arr [ j + 1 ] ) > 0 ) { // Swap elements T temp = arr [ j ] ; arr [ j ] = arr [ j + 1 ] ; arr [ j + 1 ] = temp ; swapped = true ; } } // If no swapping occurred, array is sorted if ( ! swapped ) break ; } } \ud83d\udd11 Key Tips: \u00b6 Use swapped flag to optimize for already sorted arrays Each pass bubbles up the largest element Consider cocktail sort variation for better performance Good for visualizing sorting algorithms Reference \u00b6 Bubble Sort 2\ufe0f\u20e3 Selection Sort \u00b6 An in-place comparison sorting algorithm that divides the input into a sorted and unsorted region. \ud83d\udcca Properties \u00b6 \u2705 In-place sorting \u274c Not stable \u274c Not adaptive \ud83d\udd04 Time: O(n\u00b2) all cases \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Small arrays When memory is limited When number of swaps needs to be minimized Systems where write operations are costly public static < T > void selectionSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { int minIndex = i ; for ( int j = i + 1 ; j < arr . length ; j ++ ) { if ( comparator . compare ( arr [ j ] , arr [ minIndex ] ) < 0 ) { minIndex = j ; } } // Swap with minimum element T temp = arr [ minIndex ] ; arr [ minIndex ] = arr [ i ] ; arr [ i ] = temp ; } } \ud83d\udd11 Key Tips: \u00b6 Makes minimum number of swaps (O(n)) Good when memory writes are expensive Always performs O(n\u00b2) comparisons Can be modified to be stable with additional space References \u00b6 Selection Sort 3\ufe0f\u20e3 Insertion Sort \u00b6 A simple and adaptive sorting algorithm that builds the final sorted array one element at a time. \ud83d\udcca Properties \u00b6 \u2705 In-place sorting \u2705 Stable algorithm \u2705 Adaptive behavior \ud83d\udd04 Time: O(n\u00b2) worst/average, O(n) best \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Small datasets (< 50 elements) Nearly sorted arrays Online sorting (real-time data) When simplicity is required public static < T > void insertionSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 1 ; i < arr . length ; i ++ ) { T key = arr [ i ] ; int j = i - 1 ; while ( j >= 0 && comparator . compare ( arr [ j ] , key ) > 0 ) { arr [ j + 1 ] = arr [ j ] ; j -- ; } arr [ j + 1 ] = key ; } } \ud83d\udd11 Key Tips: \u00b6 Excellent for small datasets Very efficient for nearly sorted arrays Works well with continuous insertions Often used in hybrid sorting algorithms \ud83d\udcda Common Implementation Pitfalls \u00b6 \u26a0\ufe0f Forgetting null checks for array and comparator \u26a0\ufe0f Incorrect boundary conditions in loops \u26a0\ufe0f Unnecessary swaps that can be avoided \u26a0\ufe0f Not considering stability requirements References \u00b6 Insertion Sort \ud83d\udca1 Quick Tips for Basic Sorting \u00b6 \ud83c\udfaf Choose Insertion Sort for tiny arrays or nearly sorted data \ud83d\udd04 Use Selection Sort when memory writes are expensive \ud83d\udcca Bubble Sort is mainly for educational purposes \ud83e\uddea Test with different input sizes and patterns \ud83d\udcdd Consider stability requirements when choosing an algorithm \ud83d\udd04 Advanced Sorting Algorithms \u00b6 \ud83d\ude80 Overview \u00b6 These algorithms represent more sophisticated sorting approaches, offering better performance for larger datasets: \ud83d\udcc8 Scalable Performance : Efficient for large datasets \ud83d\udd04 Divide & Conquer : Break complex problems into smaller ones \ud83d\udcab Advanced Techniques : Utilize sophisticated sorting strategies \ud83c\udfaf Production Ready : Commonly used in real-world applications \ud83d\udd0d Implementation Details \u00b6 1\ufe0f\u20e3 Heap Sort \u00b6 A comparison-based sorting algorithm using a binary heap data structure. \ud83d\udcca Properties \u00b6 \u2705 In-place sorting \u274c Not stable \u274c Not adaptive \ud83d\udd04 Time: O(n log n) all cases \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Large datasets Memory-constrained systems When stable sorting isn't required Systems requiring guaranteed O(n log n) public static int [] heapSort ( List < Integer > data ) { if ( data == null ) { throw new IllegalArgumentException ( \"List cannot be null\" ); } // Using Java's PriorityQueue for heap implementation PriorityQueue < Integer > heap = new PriorityQueue <> ( data ); int [] sorted = new int [ data . size () ] ; // Extract elements from heap in sorted order for ( int i = 0 ; ! heap . isEmpty (); i ++ ) { sorted [ i ] = heap . remove (); } return sorted ; } \ud83d\udd11 Key Tips: \u00b6 Use built-in PriorityQueue for simple implementation Helpful for implementing priority scheduling Excellent for top-K problems In-place sorting saves memory References \u00b6 Heap Sort 2\ufe0f\u20e3 Quick Sort \u00b6 A highly efficient, comparison-based algorithm using divide-and-conquer strategy. \ud83d\udcca Properties \u00b6 \u2705 In-place sorting \u274c Not stable \u274c Not adaptive \ud83d\udd04 Time: O(n\u00b2) worst, O(n log n) average/best \ud83d\udcbe Space: O(log n) \ud83d\udca1 Best Used For: \u00b6 Large datasets Systems with good cache locality General-purpose sorting When average case performance is important public static < T > void quickSort ( T [] arr , Comparator < T > comparator , Random rand ) { if ( arr == null || comparator == null || rand == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } quickSortHelper ( arr , comparator , rand , 0 , arr . length - 1 ); } private static < T > void quickSortHelper ( T [] arr , Comparator < T > comp , Random rand , int start , int end ) { if ( start < end ) { // Choose random pivot int pivotIdx = rand . nextInt ( end - start + 1 ) + start ; T pivot = arr [ pivotIdx ] ; // Move pivot to start swap ( arr , start , pivotIdx ); // Partition int i = start + 1 ; int j = end ; while ( i <= j ) { while ( i <= j && comp . compare ( arr [ i ] , pivot ) <= 0 ) i ++ ; while ( i <= j && comp . compare ( arr [ j ] , pivot ) > 0 ) j -- ; if ( i < j ) swap ( arr , i , j ); } // Place pivot in correct position swap ( arr , start , j ); // Recursive calls quickSortHelper ( arr , comp , rand , start , j - 1 ); quickSortHelper ( arr , comp , rand , j + 1 , end ); } } \ud83d\udd11 Key Tips: \u00b6 Use random pivot selection to avoid worst case Consider median-of-three for pivot selection Switch to insertion sort for small subarrays Be cautious with already sorted arrays References \u00b6 Quick Sort 3\ufe0f\u20e3 Merge Sort \u00b6 A stable, divide-and-conquer algorithm with guaranteed performance. \ud83d\udcca Properties \u00b6 \u274c Not in-place \u2705 Stable algorithm \u274c Not adaptive \ud83d\udd04 Time: O(n log n) all cases \ud83d\udcbe Space: O(n) \ud83d\udca1 Best Used For: \u00b6 Large datasets When stability is required External sorting Linked list sorting public static < T > void mergeSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } if ( arr . length > 1 ) { T [] firstHalf = ( T [] ) new Object [ arr . length / 2 ] ; T [] secondHalf = ( T [] ) new Object [ arr . length - arr . length / 2 ] ; // Split array into halves System . arraycopy ( arr , 0 , firstHalf , 0 , firstHalf . length ); System . arraycopy ( arr , firstHalf . length , secondHalf , 0 , secondHalf . length ); // Recursive sorting mergeSort ( firstHalf , comparator ); mergeSort ( secondHalf , comparator ); merge ( firstHalf , secondHalf , arr , comparator ); } } private static < T > void merge ( T [] firstHalf , T [] secondHalf , T [] arr , Comparator < T > comparator ) { int i = 0 ; // Index for firstHalf array int j = 0 ; // Index for secondHalf array int k = 0 ; // Index for merged array // Compare and merge elements from both halves while ( i < firstHalf . length && j < secondHalf . length ) { if ( comparator . compare ( firstHalf [ i ] , secondHalf [ j ] ) <= 0 ) { arr [ k ++] = firstHalf [ i ++] ; } else { arr [ k ++] = secondHalf [ j ++] ; } } // Copy remaining elements from firstHalf (if any) while ( i < firstHalf . length ) { arr [ k ++] = firstHalf [ i ++] ; } // Copy remaining elements from secondHalf (if any) while ( j < secondHalf . length ) { arr [ k ++] = secondHalf [ j ++] ; } } \ud83d\udd11 Key Tips: \u00b6 Perfect for external sorting Great for parallel processing Stable sorting guaranteed Consider in-place merge for space optimization \ud83d\udd11 Additional Merge Tips: \u00b6 The <= in the comparison ensures stability Using separate arrays avoids complex in-place merging Sequential access pattern is cache-friendly Can be optimized for nearly sorted arrays References \u00b6 Merge Sort \ud83c\udfaf Advanced Implementation Strategies \u00b6 \ud83d\udca1 Optimization Tips \u00b6 \ud83d\udd04 Use hybrid approaches for better performance \ud83d\udcca Consider input size for algorithm selection \ud83d\udcbe Balance memory usage vs. speed \u26a1 Optimize for cache efficiency \u26a0\ufe0f Common Pitfalls \u00b6 Memory management in recursive implementations Pivot selection in QuickSort Improper handling of equal elements Not considering stability requirements \u26a0\ufe0f Merge Function Pitfalls: \u00b6 Not handling empty arrays properly Incorrect index management Forgetting to copy remaining elements Improper comparison for stability \ud83d\udd0d Searching Algorithms \u00b6 \ud83d\udcd8 Introduction \u00b6 Searching algorithms are fundamental techniques for finding specific elements within data structures. Understanding these algorithms is crucial for: \ud83c\udfaf Data Retrieval : Efficiently locate specific elements \ud83d\udcbb Algorithm Design : Foundation for more complex algorithms \ud83d\udd0d Interview Preparation : Common technical interview topic \ud83e\uddee Problem Solving : Essential for many programming tasks \ud83d\udcca Performance Optimization : Choose right approach for your data \ud83d\udd0d Basic Search Algorithms \u00b6 1\ufe0f\u20e3 Linear Search \u00b6 A simple sequential search algorithm that checks each element until a match is found. \ud83d\udcca Properties \u00b6 \u2705 Works on unsorted data \u2705 Simple implementation \u2705 Minimal space requirement \ud83d\udd04 Time: O(n) worst/average, O(1) best \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Small datasets Unsorted collections One-time searches When simplicity is preferred Finding all occurrences public static < T > int linearSearch ( T [] arr , T target , Comparator < T > comparator ) { if ( arr == null || target == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 0 ; i < arr . length ; i ++ ) { if ( comparator . compare ( arr [ i ] , target ) == 0 ) { return i ; // Element found, return index } } return - 1 ; // Element not found } \ud83d\udd11 Key Tips: \u00b6 Consider early termination if possible Use for unsorted or small datasets Good for finding multiple occurrences Consider parallel search for large datasets 2\ufe0f\u20e3 Binary Search \u00b6 An efficient algorithm that requires sorted data and uses divide-and-conquer strategy. \ud83d\udcca Properties \u00b6 \u2705 Very efficient for large datasets \u274c Requires sorted data \u2705 Logarithmic time complexity \ud83d\udd04 Time: O(log n) worst/average, O(1) best \ud83d\udcbe Space: O(1) iterative, O(log n) recursive \ud83d\udca1 Best Used For: \u00b6 Large sorted datasets Frequent searches When data is already sorted Finding insertion points Range queries // Iterative Implementation public static < T > int binarySearch ( T [] arr , T target , Comparator < T > comparator ) { if ( arr == null || target == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } int left = 0 ; int right = arr . length - 1 ; while ( left <= right ) { int mid = left + ( right - left ) / 2 ; int comparison = comparator . compare ( arr [ mid ] , target ); if ( comparison == 0 ) { return mid ; // Element found } else if ( comparison < 0 ) { left = mid + 1 ; // Search right half } else { right = mid - 1 ; // Search left half } } return - 1 ; // Element not found } // Recursive Implementation public static < T > int binarySearchRecursive ( T [] arr , T target , Comparator < T > comparator ) { if ( arr == null || target == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } return binarySearchHelper ( arr , target , comparator , 0 , arr . length - 1 ); } private static < T > int binarySearchHelper ( T [] arr , T target , Comparator < T > comparator , int left , int right ) { if ( left > right ) { return - 1 ; } int mid = left + ( right - left ) / 2 ; int comparison = comparator . compare ( arr [ mid ] , target ); if ( comparison == 0 ) { return mid ; } else if ( comparison < 0 ) { return binarySearchHelper ( arr , target , comparator , mid + 1 , right ); } else { return binarySearchHelper ( arr , target , comparator , left , mid - 1 ); } } \ud83d\udd11 Key Tips: \u00b6 Use left + (right - left) / 2 to avoid integer overflow Consider iterative vs recursive based on needs Useful for finding insertion points Can be modified for fuzzy searching References \u00b6 Binary Search \ud83d\udcca Algorithm Comparison \u00b6 Feature Linear Search Binary Search Time Complexity (Worst) O(n) O(log n) Time Complexity (Best) O(1) O(1) Space Complexity O(1) O(1) iterative, O(log n) recursive Sorted Data Required No Yes Multiple Occurrences Easy to find all Finds one occurrence Implementation Complexity Simple Moderate Cache Performance Good for small data May have cache misses \ud83d\udca1 Implementation Best Practices \u00b6 \ud83c\udfaf General Tips \u00b6 Always validate input parameters Handle edge cases (empty arrays, null values) Consider return type (index vs boolean vs element) Use appropriate comparator functions \u26a0\ufe0f Common Pitfalls \u00b6 Off-by-one errors in binary search Not checking for null values Assuming data is sorted for binary search Integer overflow in mid-point calculation \ud83d\udd0d Advanced Considerations \u00b6 Duplicate elements handling Custom comparison logic Parallel search for large datasets Cache-friendly implementations \ud83c\udfaf When to Use Each \u00b6 \ud83d\udccc Linear Search : Small datasets Unsorted data Finding all occurrences Simple implementation needed \ud83d\udccc Binary Search : Large sorted datasets Frequent searches Finding insertion points Performance critical operations \ud83d\udd78\ufe0f Graph Algorithms \u00b6 \ud83d\udcd8 Introduction \u00b6 Graph algorithms are essential techniques for solving problems that involve network-like structures. Understanding these algorithms is crucial for: \ud83d\uddfa\ufe0f Network Analysis : Navigate and analyze complex networks \ud83d\udd0d Path Finding : Find optimal routes between nodes \ud83c\udf10 Web Crawling : Systematically browse and analyze web pages \ud83c\udfae Game Development : Power AI and navigation systems \ud83d\udcf1 Social Networks : Analyze relationships and connections \ud83d\udd11 Key Graph Concepts \u00b6 Vertex (Node) : Points in the graph Edge : Connections between vertices Path : Sequence of vertices connected by edges Cycle : Path that starts and ends at same vertex Connected Component : Group of connected vertices \ud83d\udd0d Basic Graph Traversal \u00b6 1\ufe0f\u20e3 Breadth First Search (BFS) \u00b6 A traversal algorithm that explores a graph level by level. \ud83d\udcca Properties \u00b6 \u2705 Finds shortest path in unweighted graphs \u2705 Explores nodes level by level \u2705 Uses queue data structure \ud83d\udd04 Time: O(V + E) \ud83d\udcbe Space: O(V) \ud83d\udca1 Best Used For: \u00b6 Finding shortest paths Level-order traversal Web crawling Network broadcasting Finding connected components public class Graph { private Map < Vertex , List < Vertex >> adjList ; public void bfs ( Vertex start ) { if ( start == null ) { throw new IllegalArgumentException ( \"Start vertex cannot be null\" ); } Queue < Vertex > queue = new LinkedList <> (); Set < Vertex > visited = new HashSet <> (); // Start the traversal queue . offer ( start ); visited . add ( start ); while ( ! queue . isEmpty ()) { Vertex current = queue . poll (); System . out . println ( \"Visiting: \" + current . getValue ()); // Process all neighbors for ( Vertex neighbor : adjList . get ( current )) { if ( ! visited . contains ( neighbor )) { visited . add ( neighbor ); queue . offer ( neighbor ); } } } } // Version that tracks paths public Map < Vertex , Vertex > bfsWithPaths ( Vertex start ) { Queue < Vertex > queue = new LinkedList <> (); Map < Vertex , Vertex > parentMap = new HashMap <> (); queue . offer ( start ); parentMap . put ( start , null ); while ( ! queue . isEmpty ()) { Vertex current = queue . poll (); for ( Vertex neighbor : adjList . get ( current )) { if ( ! parentMap . containsKey ( neighbor )) { parentMap . put ( neighbor , current ); queue . offer ( neighbor ); } } } return parentMap ; } } \ud83d\udd11 Key Tips: \u00b6 Use for shortest path in unweighted graphs Great for level-by-level exploration Consider space requirements for large graphs Can be modified to find shortest path References \u00b6 Breadth First Search 2\ufe0f\u20e3 Depth First Search (DFS) \u00b6 A traversal algorithm that explores a graph by going as deep as possible before backtracking. \ud83d\udcca Properties \u00b6 \u2705 Memory efficient for deep graphs \u2705 Natural recursive implementation \u2705 Can detect cycles \ud83d\udd04 Time: O(V + E) \ud83d\udcbe Space: O(V) worst case \ud83d\udca1 Best Used For: \u00b6 Topological sorting Cycle detection Maze solving Path finding Connected components public class Graph { private Map < Vertex , List < Vertex >> adjList ; // Recursive DFS public void dfs ( Vertex start ) { if ( start == null ) { throw new IllegalArgumentException ( \"Start vertex cannot be null\" ); } Set < Vertex > visited = new HashSet <> (); dfsHelper ( start , visited ); } private void dfsHelper ( Vertex current , Set < Vertex > visited ) { visited . add ( current ); System . out . println ( \"Visiting: \" + current . getValue ()); for ( Vertex neighbor : adjList . get ( current )) { if ( ! visited . contains ( neighbor )) { dfsHelper ( neighbor , visited ); } } } // Iterative DFS using Stack public void dfsIterative ( Vertex start ) { if ( start == null ) { throw new IllegalArgumentException ( \"Start vertex cannot be null\" ); } Stack < Vertex > stack = new Stack <> (); Set < Vertex > visited = new HashSet <> (); stack . push ( start ); while ( ! stack . isEmpty ()) { Vertex current = stack . pop (); if ( ! visited . contains ( current )) { visited . add ( current ); System . out . println ( \"Visiting: \" + current . getValue ()); // Add all unvisited neighbors to stack for ( Vertex neighbor : adjList . get ( current )) { if ( ! visited . contains ( neighbor )) { stack . push ( neighbor ); } } } } } } \ud83d\udd11 Key Tips: \u00b6 Choose between recursive and iterative based on graph depth Use for finding paths in mazes Efficient for deep graph structures Can be modified for cycle detection References \u00b6 Depth First Search \ud83d\udcca Algorithm Comparison \u00b6 Feature BFS DFS Time Complexity O(V + E) O(V + E) Space Complexity O(V) O(V) Implementation Queue-based Stack/Recursive Path Finding Shortest in unweighted Any valid path Memory Usage More for wide graphs More for deep graphs Use Case Level-wise traversal Deep traversal Completeness Complete Complete \ud83d\udca1 Implementation Best Practices \u00b6 \ud83c\udfaf General Tips \u00b6 Always validate input parameters Handle disconnected components Consider space-time tradeoffs Use appropriate data structures \u26a0\ufe0f Common Pitfalls \u00b6 Forgetting to mark nodes as visited Infinite loops in cyclic graphs Stack overflow in recursive DFS Not handling disconnected components \ud83d\udd0d Advanced Considerations \u00b6 Graph representation choice Memory management Performance optimization Edge case handling \ud83d\udee3\ufe0f Shortest Path Algorithms \u00b6 \ud83d\udcd8 Overview \u00b6 Shortest path algorithms are essential for finding optimal routes between vertices in a graph. These algorithms are crucial for: \ud83d\uddfa\ufe0f Navigation Systems : Finding optimal routes \ud83c\udf10 Network Routing : Optimizing network traffic \ud83d\udcb0 Financial Markets : Currency exchange optimization \ud83c\udfae Game Development : Path-finding for AI \ud83d\udce1 Network Design : Infrastructure planning \ud83d\udd0d Advanced Path-Finding Algorithms \u00b6 1\ufe0f\u20e3 Bellman-Ford Algorithm \u00b6 An algorithm that finds shortest paths from a source vertex to all other vertices, even with negative edge weights. \ud83d\udcca Properties \u00b6 \u2705 Handles negative edge weights \u2705 Detects negative cycles \u2705 Simple implementation \ud83d\udd04 Time: O(VE) \ud83d\udcbe Space: O(V) \ud83d\udca1 Best Used For: \u00b6 Graphs with negative weights Detecting negative cycles Currency exchange calculations Network routing protocols When edge weights can be negative public class Graph { private List < Edge > edges ; private int V ; // Number of vertices public class Edge { int source , destination , weight ; Edge ( int source , int destination , int weight ) { this . source = source ; this . destination = destination ; this . weight = weight ; } } public int [] bellmanFord ( int source ) { // Initialize distances int [] distances = new int [ V ] ; Arrays . fill ( distances , Integer . MAX_VALUE ); distances [ source ] = 0 ; // Relax all edges V-1 times for ( int i = 0 ; i < V - 1 ; i ++ ) { for ( Edge edge : edges ) { int u = edge . source ; int v = edge . destination ; int weight = edge . weight ; if ( distances [ u ] != Integer . MAX_VALUE && distances [ u ] + weight < distances [ v ] ) { distances [ v ] = distances [ u ] + weight ; } } } // Check for negative weight cycles for ( Edge edge : edges ) { int u = edge . source ; int v = edge . destination ; int weight = edge . weight ; if ( distances [ u ] != Integer . MAX_VALUE && distances [ u ] + weight < distances [ v ] ) { throw new IllegalStateException ( \"Graph contains negative weight cycle\" ); } } return distances ; } } \ud83d\udd11 Key Tips: \u00b6 Use for detecting negative cycles Good for small to medium graphs Consider memory efficiency Handle infinity values carefully References \u00b6 Shortest Path Algorithms (Bellman Ford & Dijkstra) 2\ufe0f\u20e3 Dijkstra's Algorithm \u00b6 A greedy algorithm that finds the shortest path between nodes in a graph with non-negative edge weights. \ud83d\udcca Properties \u00b6 \u2705 Efficient for non-negative weights \u2705 Finds optimal paths \u274c Doesn't work with negative weights \ud83d\udd04 Time: O(E log V) with binary heap \ud83d\udcbe Space: O(V) \ud83d\udca1 Best Used For: \u00b6 Road navigation systems Network routing Social networks Games pathfinding Resource distribution public class Graph { private Map < Integer , List < Edge >> adjList ; public class Edge { int destination ; int weight ; Edge ( int destination , int weight ) { this . destination = destination ; this . weight = weight ; } } public Map < Integer , Integer > dijkstra ( int source ) { // Priority queue for vertices with their distances PriorityQueue < Node > pq = new PriorityQueue <> ( Comparator . comparingInt ( node -> node . distance ) ); // Track distances and previous nodes Map < Integer , Integer > distances = new HashMap <> (); Map < Integer , Integer > previous = new HashMap <> (); // Initialize distances for ( int vertex : adjList . keySet ()) { distances . put ( vertex , Integer . MAX_VALUE ); } distances . put ( source , 0 ); pq . offer ( new Node ( source , 0 )); while ( ! pq . isEmpty ()) { Node current = pq . poll (); int u = current . vertex ; // Skip if we've found a better path if ( current . distance > distances . get ( u )) { continue ; } // Check all neighboring vertices for ( Edge edge : adjList . get ( u )) { int v = edge . destination ; int newDist = distances . get ( u ) + edge . weight ; if ( newDist < distances . get ( v )) { distances . put ( v , newDist ); previous . put ( v , u ); pq . offer ( new Node ( v , newDist )); } } } return distances ; } private class Node { int vertex ; int distance ; Node ( int vertex , int distance ) { this . vertex = vertex ; this . distance = distance ; } } } \ud83d\udd11 Key Tips: \u00b6 Use priority queue for efficiency Only works with non-negative weights Consider path reconstruction Can be optimized for specific use cases \ud83d\udcca Algorithm Comparison \u00b6 Feature Bellman-Ford Dijkstra Time Complexity O(VE) O(E log V) Space Complexity O(V) O(V) Handles Negative Weights Yes No Detects Negative Cycles Yes N/A Implementation Simple Moderate Use Case Negative weights Positive weights Performance Slower Faster Memory Usage Lower Higher ### \ud83d\udca1 Implementation Best Practices \ud83c\udfaf General Tips \u00b6 Validate input graphs and weights Handle unreachable vertices Consider path reconstruction Implement proper error handling \u26a0\ufe0f Common Pitfalls \u00b6 Integer overflow in distance calculations Not handling disconnected components Improper handling of infinity values Forgetting to check for negative cycles \ud83d\udd0d Advanced Optimizations \u00b6 Use Fibonacci heap for better theoretical performance Bidirectional search for specific endpoints A* modifications for heuristic improvements Early termination for single-target searches References \u00b6 Shortest Path Algorithms (Bellman Ford & Dijkstras) \ud83d\udcab Greedy Algorithms \u00b6 \ud83d\udcd8 Introduction \u00b6 Greedy algorithms make locally optimal choices at each step, aiming for a global optimum. These algorithms are essential for: \ud83c\udfaf Optimization Problems : Finding best solutions efficiently \ud83d\udcbb Resource Management : Allocating resources optimally \ud83c\udf10 Network Design : Creating efficient network structures \ud83d\udcca Data Compression : Reducing data size effectively \ud83d\udd04 Dynamic Solutions : Solving problems step by step \ud83d\udd0d Algorithm Deep Dive \u00b6 1\ufe0f\u20e3 Huffman Coding \u00b6 A data compression technique that assigns variable-length codes to characters based on their frequencies. \ud83d\udcca Properties \u00b6 \u2705 Optimal prefix codes \u2705 Lossless compression \u2705 Variable-length encoding \ud83d\udd04 Time: O(n log n) \ud83d\udcbe Space: O(n) \ud83d\udca1 How It Works \u00b6 Frequency Analysis : Count frequency of each character Create leaf nodes for each character Tree Construction : Create min-heap of nodes Repeatedly merge two lowest frequency nodes New node's frequency = sum of children Code Generation : Traverse tree from root to leaves Left edge = 0, Right edge = 1 Path to leaf = character's code \ud83c\udfaf Example \u00b6 For string: \"HELLO WORLD\" Character frequencies : H : 1 , E : 1 , L : 3 , O : 2 , W : 1 , R : 1 , D : 1 , ( space ): 1 Resulting codes might be : L : 00 O : 01 H : 100 E : 101 W : 110 R : 1110 D : 1111 ( space ): 1000 \ud83d\udd11 Key Applications \u00b6 Text file compression Data transmission Multimedia encoding Network protocols Storage optimization References \u00b6 Huffman Coding 2\ufe0f\u20e3 Kruskal's Algorithm \u00b6 A minimum spanning tree algorithm that builds the tree by selecting edges in increasing order of weight. \ud83d\udcca Properties \u00b6 \u2705 Finds global minimum \u2705 Works on disconnected graphs \u2705 Edge-focused approach \ud83d\udd04 Time: O(E log E) \ud83d\udcbe Space: O(V) \ud83d\udca1 How It Works \u00b6 Sort all edges by weight Process edges in ascending order Add edge if it doesn't create cycle Use Union-Find data structure to detect cycles public class KruskalMST { private static class Edge implements Comparable < Edge > { int src , dest , weight ; Edge ( int src , int dest , int weight ) { this . src = src ; this . dest = dest ; this . weight = weight ; } @Override public int compareTo ( Edge other ) { return Integer . compare ( this . weight , other . weight ); } } private static class UnionFind { private final int [] parent ; private final int [] rank ; UnionFind ( int size ) { parent = new int [ size ] ; rank = new int [ size ] ; // Initialize each vertex as its own set for ( int i = 0 ; i < size ; i ++ ) { parent [ i ] = i ; } } // Find with path compression int find ( int x ) { if ( parent [ x ] != x ) { parent [ x ] = find ( parent [ x ] ); } return parent [ x ] ; } // Union by rank void union ( int x , int y ) { int rootX = find ( x ); int rootY = find ( y ); if ( rootX != rootY ) { if ( rank [ rootX ] < rank [ rootY ] ) { parent [ rootX ] = rootY ; } else if ( rank [ rootX ] > rank [ rootY ] ) { parent [ rootY ] = rootX ; } else { parent [ rootY ] = rootX ; rank [ rootX ]++ ; } } } } public List < Edge > findMST ( int V , List < Edge > edges ) { List < Edge > mst = new ArrayList <> (); UnionFind uf = new UnionFind ( V ); // Sort edges by weight edges . sort ( Edge :: compareTo ); for ( Edge edge : edges ) { // If including this edge doesn't create a cycle if ( uf . find ( edge . src ) != uf . find ( edge . dest )) { mst . add ( edge ); uf . union ( edge . src , edge . dest ); } } return mst ; } } \ud83d\udd11 Key Tips \u00b6 Edge Sorting : Sort edges first for optimal selection Consider custom comparator for complex weights Union-Find Optimization : Use path compression Implement union by rank Keep track of set sizes Implementation Considerations : Handle disconnected components Validate input edges Consider edge cases (empty graph, single vertex) Performance Optimization : Use efficient sorting algorithm Optimize Union-Find operations Consider early termination References \u00b6 Kruskal's Algorithm Introduction Kruskal's Algorithm in 2 mins \ud83d\udcca Algorithm Comparison \u00b6 Feature Huffman Coding Kruskal's Algorithm Time Complexity O(n log n) O(E log E) Space Complexity O(n) O(V) Primary Use Data Compression Network Design Data Structure Priority Queue & Tree Union-Find Approach Bottom-up Global Greedy Implementation Moderate Moderate Output Prefix Codes Minimum Spanning Tree \ud83d\udca1 Best Practices \u00b6 \ud83c\udfaf General Tips \u00b6 Validate input data Handle edge cases Use appropriate data structures Consider performance optimizations \u26a0\ufe0f Common Pitfalls \u00b6 Not handling empty inputs Incorrect cycle detection Inefficient set operations Poor edge weight handling \ud83c\udf0a Advanced Greedy Algorithms \u00b6 \ud83d\udcd8 Network Flow and Spanning Tree Algorithms \u00b6 These algorithms solve complex network optimization problems, essential for: \ud83c\udf10 Network Flow : Maximizing throughput in networks \ud83d\udd04 Resource Allocation : Optimal distribution of resources \ud83c\udf33 Tree Construction : Building optimal spanning trees \ud83d\udcca Network Design : Creating efficient network topologies \ud83d\udeb0 Flow Networks : Modeling pipeline and traffic systems \ud83d\udd0d Algorithm Details \u00b6 1\ufe0f\u20e3 Ford-Fulkerson Algorithm \u00b6 A method for computing maximum flow in a flow network. \ud83d\udcca Properties \u00b6 \u2705 Finds maximum flow \u2705 Uses augmenting paths \u2705 Iterative improvement \ud83d\udd04 Time: O(EF) where F is max flow \ud83d\udcbe Space: O(V + E) \ud83d\udca1 Best Used For: \u00b6 Network capacity planning Traffic routing Resource distribution Bipartite matching Pipeline optimization public class FordFulkerson { private static class Edge { int dest , capacity , flow ; Edge reverse ; // Reference to reverse edge Edge ( int dest , int capacity ) { this . dest = dest ; this . capacity = capacity ; this . flow = 0 ; } int remainingCapacity () { return capacity - flow ; } void addFlow ( int amount ) { flow += amount ; reverse . flow -= amount ; } } private final List < List < Edge >> graph ; private final int V ; public FordFulkerson ( int vertices ) { this . V = vertices ; this . graph = new ArrayList <> ( V ); for ( int i = 0 ; i < V ; i ++ ) { graph . add ( new ArrayList <> ()); } } public void addEdge ( int from , int to , int capacity ) { // Create forward and reverse edges Edge forward = new Edge ( to , capacity ); Edge reverse = new Edge ( from , 0 ); // Link the edges forward . reverse = reverse ; reverse . reverse = forward ; // Add edges to graph graph . get ( from ). add ( forward ); graph . get ( to ). add ( reverse ); } public int maxFlow ( int source , int sink ) { int maxFlow = 0 ; while ( true ) { // Find augmenting path using BFS int [] parent = new int [ V ] ; Edge [] parentEdge = new Edge [ V ] ; Arrays . fill ( parent , - 1 ); Queue < Integer > queue = new LinkedList <> (); queue . offer ( source ); parent [ source ] = source ; while ( ! queue . isEmpty () && parent [ sink ] == - 1 ) { int current = queue . poll (); for ( Edge edge : graph . get ( current )) { if ( parent [ edge . dest ] == - 1 && edge . remainingCapacity () > 0 ) { parent [ edge . dest ] = current ; parentEdge [ edge . dest ] = edge ; queue . offer ( edge . dest ); } } } // If no augmenting path found, break if ( parent [ sink ] == - 1 ) break ; // Find minimum residual capacity along the path int bottleneck = Integer . MAX_VALUE ; for ( int v = sink ; v != source ; v = parent [ v ] ) { bottleneck = Math . min ( bottleneck , parentEdge [ v ] . remainingCapacity ()); } // Update flow along the path for ( int v = sink ; v != source ; v = parent [ v ] ) { parentEdge [ v ] . addFlow ( bottleneck ); } maxFlow += bottleneck ; } return maxFlow ; } } \ud83d\udd11 Key Tips: \u00b6 Implement residual graph carefully Use BFS for finding augmenting paths Track reverse edges Handle bottleneck calculations properly References \u00b6 Ford-Fulkerson Algorithm Ford-Fulkerson Algorithm 2\ufe0f\u20e3 Prim's Algorithm \u00b6 A greedy approach for finding minimum spanning tree, growing from a single vertex. \ud83d\udcca Properties \u00b6 \u2705 Optimal solution \u2705 Local optimization \u2705 Vertex-based approach \ud83d\udd04 Time: O(E log V) \ud83d\udcbe Space: O(V) \ud83d\udca1 Best Used For: \u00b6 Network design Cluster analysis Circuit design Cost minimization Network optimization public class PrimMST { private static class Edge { int dest , weight ; Edge ( int dest , int weight ) { this . dest = dest ; this . weight = weight ; } } private static class Vertex implements Comparable < Vertex > { int id , key ; Vertex ( int id , int key ) { this . id = id ; this . key = key ; } @Override public int compareTo ( Vertex other ) { return Integer . compare ( this . key , other . key ); } } public List < Edge > findMST ( List < List < Edge >> graph ) { int V = graph . size (); List < Edge > mst = new ArrayList <> (); // Priority queue for selecting minimum weight edge PriorityQueue < Vertex > pq = new PriorityQueue <> (); int [] key = new int [ V ] ; int [] parent = new int [ V ] ; boolean [] inMST = new boolean [ V ] ; // Initialize keys and parent Arrays . fill ( key , Integer . MAX_VALUE ); Arrays . fill ( parent , - 1 ); // Start with vertex 0 key [ 0 ] = 0 ; pq . offer ( new Vertex ( 0 , 0 )); while ( ! pq . isEmpty ()) { int u = pq . poll (). id ; // Skip if already processed if ( inMST [ u ] ) continue ; inMST [ u ] = true ; // Add edge to MST if not root if ( parent [ u ] != - 1 ) { mst . add ( new Edge ( u , key [ u ] )); } // Update keys of adjacent vertices for ( Edge edge : graph . get ( u )) { int v = edge . dest ; if ( ! inMST [ v ] && edge . weight < key [ v ] ) { key [ v ] = edge . weight ; parent [ v ] = u ; pq . offer ( new Vertex ( v , key [ v ] )); } } } return mst ; } } \ud83d\udd11 Key Tips: \u00b6 Use priority queue for efficiency Maintain key values properly Handle disconnected components Consider dense vs sparse graphs References \u00b6 Prim's Algorithm Prim's MST Algorithm \ud83d\udcca Algorithm Comparison \u00b6 Feature Ford-Fulkerson Prim's Algorithm Time Complexity O(EF) O(E log V) Space Complexity O(V + E) O(V) Primary Use Max Flow Minimum Spanning Tree Data Structure Residual Graph Priority Queue Approach Iterative Improvement Greedy Growth Graph Type Directed Undirected Key Feature Augmenting Paths Local Optimization \ud83d\udca1 Implementation Best Practices \u00b6 \ud83c\udfaf General Tips \u00b6 Validate input graphs Handle edge cases Use efficient data structures Consider performance optimizations \u26a0\ufe0f Common Pitfalls \u00b6 Incorrect flow updates Memory management issues Infinite loops Edge weight handling \ud83d\udd0d Substring Search Algorithms Guide \u00b6 \ud83d\udcd8 Introduction \u00b6 Substring search algorithms are fundamental techniques for finding pattern matches within text. These algorithms are essential for: \ud83d\udcdd Text Processing : Finding words or patterns in documents \ud83d\udd0e Search Engines : Locating specific content \ud83e\uddec DNA Sequence Analysis : Finding genetic patterns \ud83d\udcda Plagiarism Detection : Identifying text matches \ud83d\udd04 Data Validation : Pattern matching in strings \ud83d\udd0d Basic Search Algorithms \u00b6 1\ufe0f\u20e3 Brute Force Search \u00b6 A straightforward approach that checks every possible position in the text. \ud83d\udcca Properties \u00b6 \u2705 Simple implementation \u2705 No preprocessing required \u2705 Works with any pattern \ud83d\udd04 Time: O(mn) \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Short patterns Short texts Simple implementations When preprocessing overhead isn't worth it When pattern varies frequently public static List < Integer > bruteForce ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); int n = text . length (); int m = pattern . length (); // Check each possible position in text for ( int i = 0 ; i <= n - m ; i ++ ) { boolean found = true ; // Check pattern match starting at position i for ( int j = 0 ; j < m ; j ++ ) { if ( comparator . compare ( pattern . charAt ( j ), text . charAt ( i + j )) != 0 ) { found = false ; break ; } } if ( found ) { matches . add ( i ); } } return matches ; } \ud83d\udd11 Key Tips: \u00b6 Early termination on mismatch Handle edge cases properly Consider text/pattern lengths Validate inputs carefully 2\ufe0f\u20e3 Rabin-Karp Algorithm \u00b6 Uses hashing to find exact pattern matches in text. \ud83d\udcca Properties \u00b6 \u2705 Efficient for multiple patterns \u2705 Rolling hash function \u2705 Good average case \ud83d\udd04 Time: Average O(n+m), Worst O(mn) \ud83d\udcbe Space: O(1) \ud83d\udca1 Best Used For: \u00b6 Multiple pattern matching Long texts Pattern finding in streams Plagiarism detection When preprocessing pattern is beneficial public static List < Integer > rabinKarp ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); int m = pattern . length (); int n = text . length (); if ( m > n ) return matches ; // Calculate pattern hash and first window hash int base = 113 ; // Prime base int patternHash = 0 ; int windowHash = 0 ; int highestPow = 1 ; // Calculate highest power of base needed for ( int i = 0 ; i < m - 1 ; i ++ ) { highestPow = highestPow * base ; } // Calculate initial hashes for ( int i = 0 ; i < m ; i ++ ) { patternHash = patternHash * base + pattern . charAt ( i ); windowHash = windowHash * base + text . charAt ( i ); } // Slide window and check matches for ( int i = 0 ; i <= n - m ; i ++ ) { if ( patternHash == windowHash ) { // Verify character by character boolean match = true ; for ( int j = 0 ; j < m ; j ++ ) { if ( comparator . compare ( pattern . charAt ( j ), text . charAt ( i + j )) != 0 ) { match = false ; break ; } } if ( match ) { matches . add ( i ); } } // Calculate hash for next window if ( i < n - m ) { windowHash = ( windowHash - text . charAt ( i ) * highestPow ) * base + text . charAt ( i + m ); } } return matches ; } \ud83d\udd11 Key Tips: \u00b6 Choose appropriate hash function Handle hash collisions Use efficient rolling hash Consider modulo operations for large texts References \u00b6 Rabin Karp Algorithm \ud83d\udcca Algorithm Comparison \u00b6 Feature Brute Force Rabin-Karp Time Complexity (Worst) O(mn) O(mn) Time Complexity (Average) O(mn) O(n+m) Space Complexity O(1) O(1) Preprocessing No Yes Multiple Patterns Inefficient Efficient Implementation Simple Moderate Best Case O(n) O(n+m) Hash Function N/A Yes \ud83d\udca1 Implementation Best Practices \u00b6 \ud83c\udfaf General Tips \u00b6 Validate input parameters Handle edge cases Consider pattern/text lengths Use appropriate data structures \u26a0\ufe0f Common Pitfalls \u00b6 Integer overflow in hash calculation Not handling collisions Inefficient hash updates Missing edge cases \ud83d\udd0d Advanced Substring Search Algorithms \u00b6 \ud83d\udcd8 Overview \u00b6 These advanced substring search algorithms use preprocessing for more efficient pattern matching. They are crucial for: \ud83d\ude80 High Performance Search : Fast pattern matching \ud83d\udcca Big Data Analysis : Processing large text efficiently \ud83d\udd04 Real-time Matching : Stream processing \ud83d\udcdd Text Editors : Efficient find/replace operations \ud83e\uddec Bioinformatics : DNA sequence matching \ud83d\udd0d Advanced Algorithms \u00b6 1\ufe0f\u20e3 Knuth-Morris-Pratt (KMP) \u00b6 An efficient pattern matching algorithm that utilizes a failure table to avoid unnecessary comparisons. \ud83d\udcca Properties \u00b6 \u2705 Linear time complexity \u2705 Preprocesses pattern \u2705 No backward movement in text \ud83d\udd04 Time: O(n + m) \ud83d\udcbe Space: O(m) \ud83d\udca1 Best Used For: \u00b6 Long patterns Repetitive patterns Streaming data Real-time matching When text cannot be buffered public static List < Integer > kmp ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); if ( pattern . length () > text . length ()) { return matches ; } // Build failure table int [] failureTable = buildFailureTable ( pattern , comparator ); int i = 0 ; // text index int j = 0 ; // pattern index while ( i <= text . length () - pattern . length ()) { while ( j < pattern . length () && comparator . compare ( text . charAt ( i + j ), pattern . charAt ( j )) == 0 ) { j ++ ; } if ( j == 0 ) { i ++ ; } else { if ( j == pattern . length ()) { matches . add ( i ); } int nextAlignment = failureTable [ j - 1 ] ; i = i + j - nextAlignment ; j = nextAlignment ; } } return matches ; } public static int [] buildFailureTable ( CharSequence pattern , CharacterComparator comparator ) { int [] failureTable = new int [ pattern . length () ] ; int i = 0 ; int j = 1 ; failureTable [ 0 ] = 0 ; while ( j < pattern . length ()) { if ( comparator . compare ( pattern . charAt ( i ), pattern . charAt ( j )) == 0 ) { failureTable [ j ] = i + 1 ; i ++ ; j ++ ; } else { if ( i == 0 ) { failureTable [ j ] = 0 ; j ++ ; } else { i = failureTable [ i - 1 ] ; } } } return failureTable ; } \ud83d\udd11 Key Tips: \u00b6 Build failure table efficiently Handle pattern prefixes Avoid backing up in text Consider pattern preprocessing time References \u00b6 Knuth-Morris-Pratt Algorithm 2\ufe0f\u20e3 Boyer-Moore Algorithm \u00b6 A pattern matching algorithm that uses two heuristics: bad character and good suffix rules. \ud83d\udcca Properties \u00b6 \u2705 Sublinear time in practice \u2705 Two preprocessing tables \u2705 Right-to-left scanning \ud83d\udd04 Time: O(n/m) best, O(mn) worst \ud83d\udcbe Space: O(k) where k is alphabet size \ud83d\udca1 Best Used For: \u00b6 Long patterns Large alphabets Natural language text When pattern is rare in text When preprocessing time is acceptable public static List < Integer > boyerMoore ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); if ( pattern . length () > text . length ()) { return matches ; } // Build last occurrence table Map < Character , Integer > lastTable = buildLastTable ( pattern ); int i = 0 ; while ( i <= text . length () - pattern . length ()) { int j = pattern . length () - 1 ; // Match pattern from right to left while ( j >= 0 && comparator . compare ( pattern . charAt ( j ), text . charAt ( i + j )) == 0 ) { j -- ; } if ( j == - 1 ) { matches . add ( i ); i ++ ; } else { // Get last occurrence of mismatched character char mismatchChar = text . charAt ( i + j ); int lastOccurrence = lastTable . getOrDefault ( mismatchChar , - 1 ); // Calculate shift if ( lastOccurrence < j ) { i += j - lastOccurrence ; } else { i ++ ; } } } return matches ; } public static Map < Character , Integer > buildLastTable ( CharSequence pattern ) { Map < Character , Integer > lastTable = new HashMap <> (); // Record last occurrence of each character in pattern for ( int i = 0 ; i < pattern . length (); i ++ ) { lastTable . put ( pattern . charAt ( i ), i ); } return lastTable ; } \ud83d\udd11 Key Tips: \u00b6 Implement both heuristics correctly Handle character set efficiently Consider preprocessing overhead Use appropriate shift calculations References \u00b6 Boyer-Moore Algorithm \ud83d\udcca Algorithm Comparison \u00b6 Feature KMP Boyer-Moore Time Complexity (Worst) O(n + m) O(mn) Time Complexity (Average) O(n + m) O(n/m) Space Complexity O(m) O(k) Pattern Scan Direction Left to Right Right to Left Preprocessing Failure Table Last Occurrence Table Best Case O(n) O(n/m) Text Scan Direction Forward Only Can Skip Characters Implementation Moderate Complex \ud83d\udca1 Implementation Best Practices \u00b6 \ud83c\udfaf General Tips \u00b6 Use efficient preprocessing Handle border cases Consider alphabet size Choose algorithm based on pattern characteristics \u26a0\ufe0f Common Pitfalls \u00b6 Incorrect preprocessing tables Inefficient character comparisons Wrong shift calculations Missing edge cases Final Reference to Algorithm Notes \u00b6 CS 1332 Data Structures and Algorithms","title":"\ud83d\udcd8 Introduction to Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#introduction-to-algorithms","text":"Algorithms are systematic procedures for solving computational problems and manipulating data. Understanding algorithms is crucial for developing efficient software solutions and optimizing program performance. This guide explores essential algorithms, their implementations, and practical applications in software engineering.","title":"\ud83d\udcd8 Introduction to Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#why-algorithms-matter","text":"\ud83d\ude80 Performance Optimization : Choose the right algorithm to dramatically improve execution speed \ud83d\udcbb System Scalability : Build solutions that efficiently handle growing data volumes \ud83d\udcbc Technical Interviews : Essential knowledge for coding interviews at top tech companies \ud83d\udd04 Problem-Solving : Master fundamental approaches to computational challenges \ud83c\udf1f Competitive Programming : Critical for algorithmic contests and competitions","title":"\ud83c\udfaf Why Algorithms Matter"},{"location":"1.Fundamentals/c.%20algorithms/#guide-structure","text":"Each algorithm section covers: Step-by-step explanation Implementation details Time and space complexity analysis Common optimization techniques Best practices and use cases Code examples and gotchas","title":"\ud83d\udcda Guide Structure"},{"location":"1.Fundamentals/c.%20algorithms/#categories-of-algorithms","text":"","title":"\ud83d\uddc2\ufe0f Categories of Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#sorting-algorithms","text":"Transform unordered collections into ordered sequences: Bubble Sort : Simple comparison-based sorting Best for: Educational purposes, tiny datasets Selection Sort : In-place comparison sorting Best for: Small arrays, minimal memory Insertion Sort : Adaptive, stable sorting Best for: Nearly sorted data, online sorting Heap Sort : Comparison-based sorting using heap Best for: Large datasets, guaranteed performance Quick Sort : Divide-and-conquer approach Best for: General-purpose sorting, large datasets Merge Sort : Stable, divide-and-conquer sorting Best for: Linked lists, external sorting","title":"\ud83d\udcca Sorting Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#searching-algorithms","text":"Efficiently locate elements in datasets: Linear Search : Sequential element checking Best for: Small or unsorted datasets Binary Search : Divide-and-conquer searching Best for: Sorted arrays, large datasets","title":"\ud83d\udd0d Searching Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#graph-algorithms","text":"Navigate and analyze network structures: Breadth First Search (BFS) : Level-by-level traversal Best for: Shortest paths, web crawling Depth First Search (DFS) : Deep traversal exploration Best for: Maze solving, topological sorting Bellman Ford's Algorithm : Single-source shortest paths Best for: Graphs with negative edges Dijkstra's Algorithm : Efficient shortest path finding Best for: GPS, network routing __A_ Algorithm_*: Heuristic pathfinding Best for: Game AI, navigation systems","title":"\ud83d\udd78\ufe0f Graph Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#greedy-algorithms","text":"Make locally optimal choices: Huffman Coding : Data compression Best for: File compression, encoding Kruskal's Algorithm : Minimum spanning tree Best for: Network design Ford-Fulkerson Algorithm : Maximum flow problems Best for: Network flow optimization Prim's Algorithm : Minimum spanning tree Best for: Dense graphs","title":"\ud83c\udfaf Greedy Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#substring-search-algorithms","text":"Pattern matching in text: Brute Force Search : Simple pattern matching Best for: Short patterns Rabin-Karp : Hash-based pattern matching Best for: Multiple pattern search Knuth-Morris-Pratt : Efficient single pattern matching Best for: Single pattern in large text Boyer-Moore : Fast pattern matching Best for: Long patterns","title":"\ud83d\udd24 Substring Search Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#time-complexity-overview","text":"Algorithm Best Case Average Case Worst Case Space Bubble Sort O(n) O(n\u00b2) O(n\u00b2) O(1) Selection Sort O(n\u00b2) O(n\u00b2) O(n\u00b2) O(1) Insertion Sort O(n) O(n\u00b2) O(n\u00b2) O(1) Heap Sort O(n log n) O(n log n) O(n log n) O(1) Quick Sort O(n log n) O(n log n) O(n\u00b2) O(log n) Merge Sort O(n log n) O(n log n) O(n log n) O(n) Linear Search O(1) O(n) O(n) O(1) Binary Search O(1) O(log n) O(log n) O(1) BFS O(V + E) O(V + E) O(V + E) O(V) DFS O(V + E) O(V + E) O(V + E) O(V) Bellman Ford O(VE) O(VE) O(VE) O(V) Dijkstra O(E log V) O(E log V) O(E log V) O(V) A* O(E) O(E) O(V\u00b2) O(V) Huffman Coding O(n log n) O(n log n) O(n log n) O(n) Kruskal's Algorithm O(E log E) O(E log E) O(E log E) O(V) Ford-Fulkerson O(EF)* O(EF)* O(EF)* O(V + E) Prim's Algorithm O(E log V) O(E log V) O(E log V) O(V) Brute Force Search O(n) O(mn) O(mn) O(1) Rabin-Karp O(m + n) O(m + n) O(mn) O(1) Knuth-Morris-Pratt O(m + n) O(m + n) O(m + n) O(m) Boyer-Moore O(n/m) O(n) O(mn) O(m)","title":"\u23f1\ufe0f Time Complexity Overview"},{"location":"1.Fundamentals/c.%20algorithms/#references","text":"Data Structures and Algorithms Notes","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#sorting-algorithms_1","text":"","title":"\ud83d\udd04 Sorting Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#introduction","text":"Sorting algorithms are fundamental procedures that arrange elements in a specific order, typically in ascending or descending sequence. Understanding these algorithms is crucial for efficient data manipulation and problem-solving in software development.","title":"Introduction"},{"location":"1.Fundamentals/c.%20algorithms/#overview","text":"Sorting algorithms are fundamental procedures that organize data in a specific order. Understanding these algorithms is crucial for: \ud83c\udfaf Efficient Data Organization : Transform unordered data into ordered sequences \ud83d\udcbb Performance Optimization : Choose the right algorithm for your data size and type \ud83d\udd0d Interview Preparation : Common technical interview topic \ud83e\uddee Algorithm Foundation : Building block for more complex algorithms \ud83d\udcca Data Analysis : Essential for data processing and analysis","title":"\ud83d\udcd8 Overview"},{"location":"1.Fundamentals/c.%20algorithms/#common-characteristics","text":"","title":"\ud83d\udcdd Common Characteristics"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-properties","text":"Stability : Whether relative order of equal elements is preserved In-Place : Whether additional space is required Adaptivity : Whether performance improves with partially sorted data","title":"\ud83c\udfaf Algorithm Properties"},{"location":"1.Fundamentals/c.%20algorithms/#performance-metrics","text":"Time Complexity : How runtime scales with input size Space Complexity : How memory usage scales with input size Best/Worst Cases : Performance bounds under different conditions","title":"\u26a1 Performance Metrics"},{"location":"1.Fundamentals/c.%20algorithms/#basic-sorting-algorithms","text":"","title":"\ud83d\udd0d Basic Sorting Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-details","text":"","title":"\ud83d\udd0e Implementation Details"},{"location":"1.Fundamentals/c.%20algorithms/#1-bubble-sort","text":"A simple comparison-based algorithm that repeatedly steps through the list.","title":"1\ufe0f\u20e3 Bubble Sort"},{"location":"1.Fundamentals/c.%20algorithms/#properties","text":"\u2705 In-place sorting \u2705 Stable algorithm \u2705 Adaptive behavior \ud83d\udd04 Time: O(n\u00b2) worst/average, O(n) best \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for","text":"Educational purposes Tiny datasets When simplicity is preferred over efficiency Teaching sorting concepts public static < T > void bubbleSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { boolean swapped = false ; for ( int j = 0 ; j < arr . length - i - 1 ; j ++ ) { if ( comparator . compare ( arr [ j ] , arr [ j + 1 ] ) > 0 ) { // Swap elements T temp = arr [ j ] ; arr [ j ] = arr [ j + 1 ] ; arr [ j + 1 ] = temp ; swapped = true ; } } // If no swapping occurred, array is sorted if ( ! swapped ) break ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips","text":"Use swapped flag to optimize for already sorted arrays Each pass bubbles up the largest element Consider cocktail sort variation for better performance Good for visualizing sorting algorithms","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#reference","text":"Bubble Sort","title":"Reference"},{"location":"1.Fundamentals/c.%20algorithms/#2-selection-sort","text":"An in-place comparison sorting algorithm that divides the input into a sorted and unsorted region.","title":"2\ufe0f\u20e3 Selection Sort"},{"location":"1.Fundamentals/c.%20algorithms/#properties_1","text":"\u2705 In-place sorting \u274c Not stable \u274c Not adaptive \ud83d\udd04 Time: O(n\u00b2) all cases \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_1","text":"Small arrays When memory is limited When number of swaps needs to be minimized Systems where write operations are costly public static < T > void selectionSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { int minIndex = i ; for ( int j = i + 1 ; j < arr . length ; j ++ ) { if ( comparator . compare ( arr [ j ] , arr [ minIndex ] ) < 0 ) { minIndex = j ; } } // Swap with minimum element T temp = arr [ minIndex ] ; arr [ minIndex ] = arr [ i ] ; arr [ i ] = temp ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_1","text":"Makes minimum number of swaps (O(n)) Good when memory writes are expensive Always performs O(n\u00b2) comparisons Can be modified to be stable with additional space","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_1","text":"Selection Sort","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#3-insertion-sort","text":"A simple and adaptive sorting algorithm that builds the final sorted array one element at a time.","title":"3\ufe0f\u20e3 Insertion Sort"},{"location":"1.Fundamentals/c.%20algorithms/#properties_2","text":"\u2705 In-place sorting \u2705 Stable algorithm \u2705 Adaptive behavior \ud83d\udd04 Time: O(n\u00b2) worst/average, O(n) best \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_2","text":"Small datasets (< 50 elements) Nearly sorted arrays Online sorting (real-time data) When simplicity is required public static < T > void insertionSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 1 ; i < arr . length ; i ++ ) { T key = arr [ i ] ; int j = i - 1 ; while ( j >= 0 && comparator . compare ( arr [ j ] , key ) > 0 ) { arr [ j + 1 ] = arr [ j ] ; j -- ; } arr [ j + 1 ] = key ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_2","text":"Excellent for small datasets Very efficient for nearly sorted arrays Works well with continuous insertions Often used in hybrid sorting algorithms","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#common-implementation-pitfalls","text":"\u26a0\ufe0f Forgetting null checks for array and comparator \u26a0\ufe0f Incorrect boundary conditions in loops \u26a0\ufe0f Unnecessary swaps that can be avoided \u26a0\ufe0f Not considering stability requirements","title":"\ud83d\udcda Common Implementation Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#references_2","text":"Insertion Sort","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#quick-tips-for-basic-sorting","text":"\ud83c\udfaf Choose Insertion Sort for tiny arrays or nearly sorted data \ud83d\udd04 Use Selection Sort when memory writes are expensive \ud83d\udcca Bubble Sort is mainly for educational purposes \ud83e\uddea Test with different input sizes and patterns \ud83d\udcdd Consider stability requirements when choosing an algorithm","title":"\ud83d\udca1 Quick Tips for Basic Sorting"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-sorting-algorithms","text":"","title":"\ud83d\udd04 Advanced Sorting Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#overview_1","text":"These algorithms represent more sophisticated sorting approaches, offering better performance for larger datasets: \ud83d\udcc8 Scalable Performance : Efficient for large datasets \ud83d\udd04 Divide & Conquer : Break complex problems into smaller ones \ud83d\udcab Advanced Techniques : Utilize sophisticated sorting strategies \ud83c\udfaf Production Ready : Commonly used in real-world applications","title":"\ud83d\ude80 Overview"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-details_1","text":"","title":"\ud83d\udd0d Implementation Details"},{"location":"1.Fundamentals/c.%20algorithms/#1-heap-sort","text":"A comparison-based sorting algorithm using a binary heap data structure.","title":"1\ufe0f\u20e3 Heap Sort"},{"location":"1.Fundamentals/c.%20algorithms/#properties_3","text":"\u2705 In-place sorting \u274c Not stable \u274c Not adaptive \ud83d\udd04 Time: O(n log n) all cases \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_3","text":"Large datasets Memory-constrained systems When stable sorting isn't required Systems requiring guaranteed O(n log n) public static int [] heapSort ( List < Integer > data ) { if ( data == null ) { throw new IllegalArgumentException ( \"List cannot be null\" ); } // Using Java's PriorityQueue for heap implementation PriorityQueue < Integer > heap = new PriorityQueue <> ( data ); int [] sorted = new int [ data . size () ] ; // Extract elements from heap in sorted order for ( int i = 0 ; ! heap . isEmpty (); i ++ ) { sorted [ i ] = heap . remove (); } return sorted ; }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_3","text":"Use built-in PriorityQueue for simple implementation Helpful for implementing priority scheduling Excellent for top-K problems In-place sorting saves memory","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_3","text":"Heap Sort","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#2-quick-sort","text":"A highly efficient, comparison-based algorithm using divide-and-conquer strategy.","title":"2\ufe0f\u20e3 Quick Sort"},{"location":"1.Fundamentals/c.%20algorithms/#properties_4","text":"\u2705 In-place sorting \u274c Not stable \u274c Not adaptive \ud83d\udd04 Time: O(n\u00b2) worst, O(n log n) average/best \ud83d\udcbe Space: O(log n)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_4","text":"Large datasets Systems with good cache locality General-purpose sorting When average case performance is important public static < T > void quickSort ( T [] arr , Comparator < T > comparator , Random rand ) { if ( arr == null || comparator == null || rand == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } quickSortHelper ( arr , comparator , rand , 0 , arr . length - 1 ); } private static < T > void quickSortHelper ( T [] arr , Comparator < T > comp , Random rand , int start , int end ) { if ( start < end ) { // Choose random pivot int pivotIdx = rand . nextInt ( end - start + 1 ) + start ; T pivot = arr [ pivotIdx ] ; // Move pivot to start swap ( arr , start , pivotIdx ); // Partition int i = start + 1 ; int j = end ; while ( i <= j ) { while ( i <= j && comp . compare ( arr [ i ] , pivot ) <= 0 ) i ++ ; while ( i <= j && comp . compare ( arr [ j ] , pivot ) > 0 ) j -- ; if ( i < j ) swap ( arr , i , j ); } // Place pivot in correct position swap ( arr , start , j ); // Recursive calls quickSortHelper ( arr , comp , rand , start , j - 1 ); quickSortHelper ( arr , comp , rand , j + 1 , end ); } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_4","text":"Use random pivot selection to avoid worst case Consider median-of-three for pivot selection Switch to insertion sort for small subarrays Be cautious with already sorted arrays","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_4","text":"Quick Sort","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#3-merge-sort","text":"A stable, divide-and-conquer algorithm with guaranteed performance.","title":"3\ufe0f\u20e3 Merge Sort"},{"location":"1.Fundamentals/c.%20algorithms/#properties_5","text":"\u274c Not in-place \u2705 Stable algorithm \u274c Not adaptive \ud83d\udd04 Time: O(n log n) all cases \ud83d\udcbe Space: O(n)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_5","text":"Large datasets When stability is required External sorting Linked list sorting public static < T > void mergeSort ( T [] arr , Comparator < T > comparator ) { if ( arr == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } if ( arr . length > 1 ) { T [] firstHalf = ( T [] ) new Object [ arr . length / 2 ] ; T [] secondHalf = ( T [] ) new Object [ arr . length - arr . length / 2 ] ; // Split array into halves System . arraycopy ( arr , 0 , firstHalf , 0 , firstHalf . length ); System . arraycopy ( arr , firstHalf . length , secondHalf , 0 , secondHalf . length ); // Recursive sorting mergeSort ( firstHalf , comparator ); mergeSort ( secondHalf , comparator ); merge ( firstHalf , secondHalf , arr , comparator ); } } private static < T > void merge ( T [] firstHalf , T [] secondHalf , T [] arr , Comparator < T > comparator ) { int i = 0 ; // Index for firstHalf array int j = 0 ; // Index for secondHalf array int k = 0 ; // Index for merged array // Compare and merge elements from both halves while ( i < firstHalf . length && j < secondHalf . length ) { if ( comparator . compare ( firstHalf [ i ] , secondHalf [ j ] ) <= 0 ) { arr [ k ++] = firstHalf [ i ++] ; } else { arr [ k ++] = secondHalf [ j ++] ; } } // Copy remaining elements from firstHalf (if any) while ( i < firstHalf . length ) { arr [ k ++] = firstHalf [ i ++] ; } // Copy remaining elements from secondHalf (if any) while ( j < secondHalf . length ) { arr [ k ++] = secondHalf [ j ++] ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_5","text":"Perfect for external sorting Great for parallel processing Stable sorting guaranteed Consider in-place merge for space optimization","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#additional-merge-tips","text":"The <= in the comparison ensures stability Using separate arrays avoids complex in-place merging Sequential access pattern is cache-friendly Can be optimized for nearly sorted arrays","title":"\ud83d\udd11 Additional Merge Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_5","text":"Merge Sort","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-implementation-strategies","text":"","title":"\ud83c\udfaf Advanced Implementation Strategies"},{"location":"1.Fundamentals/c.%20algorithms/#optimization-tips","text":"\ud83d\udd04 Use hybrid approaches for better performance \ud83d\udcca Consider input size for algorithm selection \ud83d\udcbe Balance memory usage vs. speed \u26a1 Optimize for cache efficiency","title":"\ud83d\udca1 Optimization Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls","text":"Memory management in recursive implementations Pivot selection in QuickSort Improper handling of equal elements Not considering stability requirements","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#merge-function-pitfalls","text":"Not handling empty arrays properly Incorrect index management Forgetting to copy remaining elements Improper comparison for stability","title":"\u26a0\ufe0f Merge Function Pitfalls:"},{"location":"1.Fundamentals/c.%20algorithms/#searching-algorithms_1","text":"","title":"\ud83d\udd0d Searching Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#introduction_1","text":"Searching algorithms are fundamental techniques for finding specific elements within data structures. Understanding these algorithms is crucial for: \ud83c\udfaf Data Retrieval : Efficiently locate specific elements \ud83d\udcbb Algorithm Design : Foundation for more complex algorithms \ud83d\udd0d Interview Preparation : Common technical interview topic \ud83e\uddee Problem Solving : Essential for many programming tasks \ud83d\udcca Performance Optimization : Choose right approach for your data","title":"\ud83d\udcd8 Introduction"},{"location":"1.Fundamentals/c.%20algorithms/#basic-search-algorithms","text":"","title":"\ud83d\udd0d Basic Search Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#1-linear-search","text":"A simple sequential search algorithm that checks each element until a match is found.","title":"1\ufe0f\u20e3 Linear Search"},{"location":"1.Fundamentals/c.%20algorithms/#properties_6","text":"\u2705 Works on unsorted data \u2705 Simple implementation \u2705 Minimal space requirement \ud83d\udd04 Time: O(n) worst/average, O(1) best \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_6","text":"Small datasets Unsorted collections One-time searches When simplicity is preferred Finding all occurrences public static < T > int linearSearch ( T [] arr , T target , Comparator < T > comparator ) { if ( arr == null || target == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } for ( int i = 0 ; i < arr . length ; i ++ ) { if ( comparator . compare ( arr [ i ] , target ) == 0 ) { return i ; // Element found, return index } } return - 1 ; // Element not found }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_6","text":"Consider early termination if possible Use for unsorted or small datasets Good for finding multiple occurrences Consider parallel search for large datasets","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#2-binary-search","text":"An efficient algorithm that requires sorted data and uses divide-and-conquer strategy.","title":"2\ufe0f\u20e3 Binary Search"},{"location":"1.Fundamentals/c.%20algorithms/#properties_7","text":"\u2705 Very efficient for large datasets \u274c Requires sorted data \u2705 Logarithmic time complexity \ud83d\udd04 Time: O(log n) worst/average, O(1) best \ud83d\udcbe Space: O(1) iterative, O(log n) recursive","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_7","text":"Large sorted datasets Frequent searches When data is already sorted Finding insertion points Range queries // Iterative Implementation public static < T > int binarySearch ( T [] arr , T target , Comparator < T > comparator ) { if ( arr == null || target == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } int left = 0 ; int right = arr . length - 1 ; while ( left <= right ) { int mid = left + ( right - left ) / 2 ; int comparison = comparator . compare ( arr [ mid ] , target ); if ( comparison == 0 ) { return mid ; // Element found } else if ( comparison < 0 ) { left = mid + 1 ; // Search right half } else { right = mid - 1 ; // Search left half } } return - 1 ; // Element not found } // Recursive Implementation public static < T > int binarySearchRecursive ( T [] arr , T target , Comparator < T > comparator ) { if ( arr == null || target == null || comparator == null ) { throw new IllegalArgumentException ( \"Inputs cannot be null\" ); } return binarySearchHelper ( arr , target , comparator , 0 , arr . length - 1 ); } private static < T > int binarySearchHelper ( T [] arr , T target , Comparator < T > comparator , int left , int right ) { if ( left > right ) { return - 1 ; } int mid = left + ( right - left ) / 2 ; int comparison = comparator . compare ( arr [ mid ] , target ); if ( comparison == 0 ) { return mid ; } else if ( comparison < 0 ) { return binarySearchHelper ( arr , target , comparator , mid + 1 , right ); } else { return binarySearchHelper ( arr , target , comparator , left , mid - 1 ); } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_7","text":"Use left + (right - left) / 2 to avoid integer overflow Consider iterative vs recursive based on needs Useful for finding insertion points Can be modified for fuzzy searching","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_6","text":"Binary Search","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison","text":"Feature Linear Search Binary Search Time Complexity (Worst) O(n) O(log n) Time Complexity (Best) O(1) O(1) Space Complexity O(1) O(1) iterative, O(log n) recursive Sorted Data Required No Yes Multiple Occurrences Easy to find all Finds one occurrence Implementation Complexity Simple Moderate Cache Performance Good for small data May have cache misses","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-best-practices","text":"","title":"\ud83d\udca1 Implementation Best Practices"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips","text":"Always validate input parameters Handle edge cases (empty arrays, null values) Consider return type (index vs boolean vs element) Use appropriate comparator functions","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_1","text":"Off-by-one errors in binary search Not checking for null values Assuming data is sorted for binary search Integer overflow in mid-point calculation","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-considerations","text":"Duplicate elements handling Custom comparison logic Parallel search for large datasets Cache-friendly implementations","title":"\ud83d\udd0d Advanced Considerations"},{"location":"1.Fundamentals/c.%20algorithms/#when-to-use-each","text":"\ud83d\udccc Linear Search : Small datasets Unsorted data Finding all occurrences Simple implementation needed \ud83d\udccc Binary Search : Large sorted datasets Frequent searches Finding insertion points Performance critical operations","title":"\ud83c\udfaf When to Use Each"},{"location":"1.Fundamentals/c.%20algorithms/#graph-algorithms_1","text":"","title":"\ud83d\udd78\ufe0f Graph Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#introduction_2","text":"Graph algorithms are essential techniques for solving problems that involve network-like structures. Understanding these algorithms is crucial for: \ud83d\uddfa\ufe0f Network Analysis : Navigate and analyze complex networks \ud83d\udd0d Path Finding : Find optimal routes between nodes \ud83c\udf10 Web Crawling : Systematically browse and analyze web pages \ud83c\udfae Game Development : Power AI and navigation systems \ud83d\udcf1 Social Networks : Analyze relationships and connections","title":"\ud83d\udcd8 Introduction"},{"location":"1.Fundamentals/c.%20algorithms/#key-graph-concepts","text":"Vertex (Node) : Points in the graph Edge : Connections between vertices Path : Sequence of vertices connected by edges Cycle : Path that starts and ends at same vertex Connected Component : Group of connected vertices","title":"\ud83d\udd11 Key Graph Concepts"},{"location":"1.Fundamentals/c.%20algorithms/#basic-graph-traversal","text":"","title":"\ud83d\udd0d Basic Graph Traversal"},{"location":"1.Fundamentals/c.%20algorithms/#1-breadth-first-search-bfs","text":"A traversal algorithm that explores a graph level by level.","title":"1\ufe0f\u20e3 Breadth First Search (BFS)"},{"location":"1.Fundamentals/c.%20algorithms/#properties_8","text":"\u2705 Finds shortest path in unweighted graphs \u2705 Explores nodes level by level \u2705 Uses queue data structure \ud83d\udd04 Time: O(V + E) \ud83d\udcbe Space: O(V)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_8","text":"Finding shortest paths Level-order traversal Web crawling Network broadcasting Finding connected components public class Graph { private Map < Vertex , List < Vertex >> adjList ; public void bfs ( Vertex start ) { if ( start == null ) { throw new IllegalArgumentException ( \"Start vertex cannot be null\" ); } Queue < Vertex > queue = new LinkedList <> (); Set < Vertex > visited = new HashSet <> (); // Start the traversal queue . offer ( start ); visited . add ( start ); while ( ! queue . isEmpty ()) { Vertex current = queue . poll (); System . out . println ( \"Visiting: \" + current . getValue ()); // Process all neighbors for ( Vertex neighbor : adjList . get ( current )) { if ( ! visited . contains ( neighbor )) { visited . add ( neighbor ); queue . offer ( neighbor ); } } } } // Version that tracks paths public Map < Vertex , Vertex > bfsWithPaths ( Vertex start ) { Queue < Vertex > queue = new LinkedList <> (); Map < Vertex , Vertex > parentMap = new HashMap <> (); queue . offer ( start ); parentMap . put ( start , null ); while ( ! queue . isEmpty ()) { Vertex current = queue . poll (); for ( Vertex neighbor : adjList . get ( current )) { if ( ! parentMap . containsKey ( neighbor )) { parentMap . put ( neighbor , current ); queue . offer ( neighbor ); } } } return parentMap ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_8","text":"Use for shortest path in unweighted graphs Great for level-by-level exploration Consider space requirements for large graphs Can be modified to find shortest path","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_7","text":"Breadth First Search","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#2-depth-first-search-dfs","text":"A traversal algorithm that explores a graph by going as deep as possible before backtracking.","title":"2\ufe0f\u20e3 Depth First Search (DFS)"},{"location":"1.Fundamentals/c.%20algorithms/#properties_9","text":"\u2705 Memory efficient for deep graphs \u2705 Natural recursive implementation \u2705 Can detect cycles \ud83d\udd04 Time: O(V + E) \ud83d\udcbe Space: O(V) worst case","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_9","text":"Topological sorting Cycle detection Maze solving Path finding Connected components public class Graph { private Map < Vertex , List < Vertex >> adjList ; // Recursive DFS public void dfs ( Vertex start ) { if ( start == null ) { throw new IllegalArgumentException ( \"Start vertex cannot be null\" ); } Set < Vertex > visited = new HashSet <> (); dfsHelper ( start , visited ); } private void dfsHelper ( Vertex current , Set < Vertex > visited ) { visited . add ( current ); System . out . println ( \"Visiting: \" + current . getValue ()); for ( Vertex neighbor : adjList . get ( current )) { if ( ! visited . contains ( neighbor )) { dfsHelper ( neighbor , visited ); } } } // Iterative DFS using Stack public void dfsIterative ( Vertex start ) { if ( start == null ) { throw new IllegalArgumentException ( \"Start vertex cannot be null\" ); } Stack < Vertex > stack = new Stack <> (); Set < Vertex > visited = new HashSet <> (); stack . push ( start ); while ( ! stack . isEmpty ()) { Vertex current = stack . pop (); if ( ! visited . contains ( current )) { visited . add ( current ); System . out . println ( \"Visiting: \" + current . getValue ()); // Add all unvisited neighbors to stack for ( Vertex neighbor : adjList . get ( current )) { if ( ! visited . contains ( neighbor )) { stack . push ( neighbor ); } } } } } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_9","text":"Choose between recursive and iterative based on graph depth Use for finding paths in mazes Efficient for deep graph structures Can be modified for cycle detection","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_8","text":"Depth First Search","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison_1","text":"Feature BFS DFS Time Complexity O(V + E) O(V + E) Space Complexity O(V) O(V) Implementation Queue-based Stack/Recursive Path Finding Shortest in unweighted Any valid path Memory Usage More for wide graphs More for deep graphs Use Case Level-wise traversal Deep traversal Completeness Complete Complete","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-best-practices_1","text":"","title":"\ud83d\udca1 Implementation Best Practices"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips_1","text":"Always validate input parameters Handle disconnected components Consider space-time tradeoffs Use appropriate data structures","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_2","text":"Forgetting to mark nodes as visited Infinite loops in cyclic graphs Stack overflow in recursive DFS Not handling disconnected components","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-considerations_1","text":"Graph representation choice Memory management Performance optimization Edge case handling","title":"\ud83d\udd0d Advanced Considerations"},{"location":"1.Fundamentals/c.%20algorithms/#shortest-path-algorithms","text":"","title":"\ud83d\udee3\ufe0f Shortest Path Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#overview_2","text":"Shortest path algorithms are essential for finding optimal routes between vertices in a graph. These algorithms are crucial for: \ud83d\uddfa\ufe0f Navigation Systems : Finding optimal routes \ud83c\udf10 Network Routing : Optimizing network traffic \ud83d\udcb0 Financial Markets : Currency exchange optimization \ud83c\udfae Game Development : Path-finding for AI \ud83d\udce1 Network Design : Infrastructure planning","title":"\ud83d\udcd8 Overview"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-path-finding-algorithms","text":"","title":"\ud83d\udd0d Advanced Path-Finding Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#1-bellman-ford-algorithm","text":"An algorithm that finds shortest paths from a source vertex to all other vertices, even with negative edge weights.","title":"1\ufe0f\u20e3 Bellman-Ford Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_10","text":"\u2705 Handles negative edge weights \u2705 Detects negative cycles \u2705 Simple implementation \ud83d\udd04 Time: O(VE) \ud83d\udcbe Space: O(V)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_10","text":"Graphs with negative weights Detecting negative cycles Currency exchange calculations Network routing protocols When edge weights can be negative public class Graph { private List < Edge > edges ; private int V ; // Number of vertices public class Edge { int source , destination , weight ; Edge ( int source , int destination , int weight ) { this . source = source ; this . destination = destination ; this . weight = weight ; } } public int [] bellmanFord ( int source ) { // Initialize distances int [] distances = new int [ V ] ; Arrays . fill ( distances , Integer . MAX_VALUE ); distances [ source ] = 0 ; // Relax all edges V-1 times for ( int i = 0 ; i < V - 1 ; i ++ ) { for ( Edge edge : edges ) { int u = edge . source ; int v = edge . destination ; int weight = edge . weight ; if ( distances [ u ] != Integer . MAX_VALUE && distances [ u ] + weight < distances [ v ] ) { distances [ v ] = distances [ u ] + weight ; } } } // Check for negative weight cycles for ( Edge edge : edges ) { int u = edge . source ; int v = edge . destination ; int weight = edge . weight ; if ( distances [ u ] != Integer . MAX_VALUE && distances [ u ] + weight < distances [ v ] ) { throw new IllegalStateException ( \"Graph contains negative weight cycle\" ); } } return distances ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_10","text":"Use for detecting negative cycles Good for small to medium graphs Consider memory efficiency Handle infinity values carefully","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_9","text":"Shortest Path Algorithms (Bellman Ford & Dijkstra)","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#2-dijkstras-algorithm","text":"A greedy algorithm that finds the shortest path between nodes in a graph with non-negative edge weights.","title":"2\ufe0f\u20e3 Dijkstra's Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_11","text":"\u2705 Efficient for non-negative weights \u2705 Finds optimal paths \u274c Doesn't work with negative weights \ud83d\udd04 Time: O(E log V) with binary heap \ud83d\udcbe Space: O(V)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_11","text":"Road navigation systems Network routing Social networks Games pathfinding Resource distribution public class Graph { private Map < Integer , List < Edge >> adjList ; public class Edge { int destination ; int weight ; Edge ( int destination , int weight ) { this . destination = destination ; this . weight = weight ; } } public Map < Integer , Integer > dijkstra ( int source ) { // Priority queue for vertices with their distances PriorityQueue < Node > pq = new PriorityQueue <> ( Comparator . comparingInt ( node -> node . distance ) ); // Track distances and previous nodes Map < Integer , Integer > distances = new HashMap <> (); Map < Integer , Integer > previous = new HashMap <> (); // Initialize distances for ( int vertex : adjList . keySet ()) { distances . put ( vertex , Integer . MAX_VALUE ); } distances . put ( source , 0 ); pq . offer ( new Node ( source , 0 )); while ( ! pq . isEmpty ()) { Node current = pq . poll (); int u = current . vertex ; // Skip if we've found a better path if ( current . distance > distances . get ( u )) { continue ; } // Check all neighboring vertices for ( Edge edge : adjList . get ( u )) { int v = edge . destination ; int newDist = distances . get ( u ) + edge . weight ; if ( newDist < distances . get ( v )) { distances . put ( v , newDist ); previous . put ( v , u ); pq . offer ( new Node ( v , newDist )); } } } return distances ; } private class Node { int vertex ; int distance ; Node ( int vertex , int distance ) { this . vertex = vertex ; this . distance = distance ; } } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_11","text":"Use priority queue for efficiency Only works with non-negative weights Consider path reconstruction Can be optimized for specific use cases","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison_2","text":"Feature Bellman-Ford Dijkstra Time Complexity O(VE) O(E log V) Space Complexity O(V) O(V) Handles Negative Weights Yes No Detects Negative Cycles Yes N/A Implementation Simple Moderate Use Case Negative weights Positive weights Performance Slower Faster Memory Usage Lower Higher ### \ud83d\udca1 Implementation Best Practices","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips_2","text":"Validate input graphs and weights Handle unreachable vertices Consider path reconstruction Implement proper error handling","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_3","text":"Integer overflow in distance calculations Not handling disconnected components Improper handling of infinity values Forgetting to check for negative cycles","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-optimizations","text":"Use Fibonacci heap for better theoretical performance Bidirectional search for specific endpoints A* modifications for heuristic improvements Early termination for single-target searches","title":"\ud83d\udd0d Advanced Optimizations"},{"location":"1.Fundamentals/c.%20algorithms/#references_10","text":"Shortest Path Algorithms (Bellman Ford & Dijkstras)","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#greedy-algorithms_1","text":"","title":"\ud83d\udcab Greedy Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#introduction_3","text":"Greedy algorithms make locally optimal choices at each step, aiming for a global optimum. These algorithms are essential for: \ud83c\udfaf Optimization Problems : Finding best solutions efficiently \ud83d\udcbb Resource Management : Allocating resources optimally \ud83c\udf10 Network Design : Creating efficient network structures \ud83d\udcca Data Compression : Reducing data size effectively \ud83d\udd04 Dynamic Solutions : Solving problems step by step","title":"\ud83d\udcd8 Introduction"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-deep-dive","text":"","title":"\ud83d\udd0d Algorithm Deep Dive"},{"location":"1.Fundamentals/c.%20algorithms/#1-huffman-coding","text":"A data compression technique that assigns variable-length codes to characters based on their frequencies.","title":"1\ufe0f\u20e3 Huffman Coding"},{"location":"1.Fundamentals/c.%20algorithms/#properties_12","text":"\u2705 Optimal prefix codes \u2705 Lossless compression \u2705 Variable-length encoding \ud83d\udd04 Time: O(n log n) \ud83d\udcbe Space: O(n)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#how-it-works","text":"Frequency Analysis : Count frequency of each character Create leaf nodes for each character Tree Construction : Create min-heap of nodes Repeatedly merge two lowest frequency nodes New node's frequency = sum of children Code Generation : Traverse tree from root to leaves Left edge = 0, Right edge = 1 Path to leaf = character's code","title":"\ud83d\udca1 How It Works"},{"location":"1.Fundamentals/c.%20algorithms/#example","text":"For string: \"HELLO WORLD\" Character frequencies : H : 1 , E : 1 , L : 3 , O : 2 , W : 1 , R : 1 , D : 1 , ( space ): 1 Resulting codes might be : L : 00 O : 01 H : 100 E : 101 W : 110 R : 1110 D : 1111 ( space ): 1000","title":"\ud83c\udfaf Example"},{"location":"1.Fundamentals/c.%20algorithms/#key-applications","text":"Text file compression Data transmission Multimedia encoding Network protocols Storage optimization","title":"\ud83d\udd11 Key Applications"},{"location":"1.Fundamentals/c.%20algorithms/#references_11","text":"Huffman Coding","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#2-kruskals-algorithm","text":"A minimum spanning tree algorithm that builds the tree by selecting edges in increasing order of weight.","title":"2\ufe0f\u20e3 Kruskal's Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_13","text":"\u2705 Finds global minimum \u2705 Works on disconnected graphs \u2705 Edge-focused approach \ud83d\udd04 Time: O(E log E) \ud83d\udcbe Space: O(V)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#how-it-works_1","text":"Sort all edges by weight Process edges in ascending order Add edge if it doesn't create cycle Use Union-Find data structure to detect cycles public class KruskalMST { private static class Edge implements Comparable < Edge > { int src , dest , weight ; Edge ( int src , int dest , int weight ) { this . src = src ; this . dest = dest ; this . weight = weight ; } @Override public int compareTo ( Edge other ) { return Integer . compare ( this . weight , other . weight ); } } private static class UnionFind { private final int [] parent ; private final int [] rank ; UnionFind ( int size ) { parent = new int [ size ] ; rank = new int [ size ] ; // Initialize each vertex as its own set for ( int i = 0 ; i < size ; i ++ ) { parent [ i ] = i ; } } // Find with path compression int find ( int x ) { if ( parent [ x ] != x ) { parent [ x ] = find ( parent [ x ] ); } return parent [ x ] ; } // Union by rank void union ( int x , int y ) { int rootX = find ( x ); int rootY = find ( y ); if ( rootX != rootY ) { if ( rank [ rootX ] < rank [ rootY ] ) { parent [ rootX ] = rootY ; } else if ( rank [ rootX ] > rank [ rootY ] ) { parent [ rootY ] = rootX ; } else { parent [ rootY ] = rootX ; rank [ rootX ]++ ; } } } } public List < Edge > findMST ( int V , List < Edge > edges ) { List < Edge > mst = new ArrayList <> (); UnionFind uf = new UnionFind ( V ); // Sort edges by weight edges . sort ( Edge :: compareTo ); for ( Edge edge : edges ) { // If including this edge doesn't create a cycle if ( uf . find ( edge . src ) != uf . find ( edge . dest )) { mst . add ( edge ); uf . union ( edge . src , edge . dest ); } } return mst ; } }","title":"\ud83d\udca1 How It Works"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_12","text":"Edge Sorting : Sort edges first for optimal selection Consider custom comparator for complex weights Union-Find Optimization : Use path compression Implement union by rank Keep track of set sizes Implementation Considerations : Handle disconnected components Validate input edges Consider edge cases (empty graph, single vertex) Performance Optimization : Use efficient sorting algorithm Optimize Union-Find operations Consider early termination","title":"\ud83d\udd11 Key Tips"},{"location":"1.Fundamentals/c.%20algorithms/#references_12","text":"Kruskal's Algorithm Introduction Kruskal's Algorithm in 2 mins","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison_3","text":"Feature Huffman Coding Kruskal's Algorithm Time Complexity O(n log n) O(E log E) Space Complexity O(n) O(V) Primary Use Data Compression Network Design Data Structure Priority Queue & Tree Union-Find Approach Bottom-up Global Greedy Implementation Moderate Moderate Output Prefix Codes Minimum Spanning Tree","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#best-practices","text":"","title":"\ud83d\udca1 Best Practices"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips_3","text":"Validate input data Handle edge cases Use appropriate data structures Consider performance optimizations","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_4","text":"Not handling empty inputs Incorrect cycle detection Inefficient set operations Poor edge weight handling","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-greedy-algorithms","text":"","title":"\ud83c\udf0a Advanced Greedy Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#network-flow-and-spanning-tree-algorithms","text":"These algorithms solve complex network optimization problems, essential for: \ud83c\udf10 Network Flow : Maximizing throughput in networks \ud83d\udd04 Resource Allocation : Optimal distribution of resources \ud83c\udf33 Tree Construction : Building optimal spanning trees \ud83d\udcca Network Design : Creating efficient network topologies \ud83d\udeb0 Flow Networks : Modeling pipeline and traffic systems","title":"\ud83d\udcd8 Network Flow and Spanning Tree Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-details","text":"","title":"\ud83d\udd0d Algorithm Details"},{"location":"1.Fundamentals/c.%20algorithms/#1-ford-fulkerson-algorithm","text":"A method for computing maximum flow in a flow network.","title":"1\ufe0f\u20e3 Ford-Fulkerson Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_14","text":"\u2705 Finds maximum flow \u2705 Uses augmenting paths \u2705 Iterative improvement \ud83d\udd04 Time: O(EF) where F is max flow \ud83d\udcbe Space: O(V + E)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_12","text":"Network capacity planning Traffic routing Resource distribution Bipartite matching Pipeline optimization public class FordFulkerson { private static class Edge { int dest , capacity , flow ; Edge reverse ; // Reference to reverse edge Edge ( int dest , int capacity ) { this . dest = dest ; this . capacity = capacity ; this . flow = 0 ; } int remainingCapacity () { return capacity - flow ; } void addFlow ( int amount ) { flow += amount ; reverse . flow -= amount ; } } private final List < List < Edge >> graph ; private final int V ; public FordFulkerson ( int vertices ) { this . V = vertices ; this . graph = new ArrayList <> ( V ); for ( int i = 0 ; i < V ; i ++ ) { graph . add ( new ArrayList <> ()); } } public void addEdge ( int from , int to , int capacity ) { // Create forward and reverse edges Edge forward = new Edge ( to , capacity ); Edge reverse = new Edge ( from , 0 ); // Link the edges forward . reverse = reverse ; reverse . reverse = forward ; // Add edges to graph graph . get ( from ). add ( forward ); graph . get ( to ). add ( reverse ); } public int maxFlow ( int source , int sink ) { int maxFlow = 0 ; while ( true ) { // Find augmenting path using BFS int [] parent = new int [ V ] ; Edge [] parentEdge = new Edge [ V ] ; Arrays . fill ( parent , - 1 ); Queue < Integer > queue = new LinkedList <> (); queue . offer ( source ); parent [ source ] = source ; while ( ! queue . isEmpty () && parent [ sink ] == - 1 ) { int current = queue . poll (); for ( Edge edge : graph . get ( current )) { if ( parent [ edge . dest ] == - 1 && edge . remainingCapacity () > 0 ) { parent [ edge . dest ] = current ; parentEdge [ edge . dest ] = edge ; queue . offer ( edge . dest ); } } } // If no augmenting path found, break if ( parent [ sink ] == - 1 ) break ; // Find minimum residual capacity along the path int bottleneck = Integer . MAX_VALUE ; for ( int v = sink ; v != source ; v = parent [ v ] ) { bottleneck = Math . min ( bottleneck , parentEdge [ v ] . remainingCapacity ()); } // Update flow along the path for ( int v = sink ; v != source ; v = parent [ v ] ) { parentEdge [ v ] . addFlow ( bottleneck ); } maxFlow += bottleneck ; } return maxFlow ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_13","text":"Implement residual graph carefully Use BFS for finding augmenting paths Track reverse edges Handle bottleneck calculations properly","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_13","text":"Ford-Fulkerson Algorithm Ford-Fulkerson Algorithm","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#2-prims-algorithm","text":"A greedy approach for finding minimum spanning tree, growing from a single vertex.","title":"2\ufe0f\u20e3 Prim's Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_15","text":"\u2705 Optimal solution \u2705 Local optimization \u2705 Vertex-based approach \ud83d\udd04 Time: O(E log V) \ud83d\udcbe Space: O(V)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_13","text":"Network design Cluster analysis Circuit design Cost minimization Network optimization public class PrimMST { private static class Edge { int dest , weight ; Edge ( int dest , int weight ) { this . dest = dest ; this . weight = weight ; } } private static class Vertex implements Comparable < Vertex > { int id , key ; Vertex ( int id , int key ) { this . id = id ; this . key = key ; } @Override public int compareTo ( Vertex other ) { return Integer . compare ( this . key , other . key ); } } public List < Edge > findMST ( List < List < Edge >> graph ) { int V = graph . size (); List < Edge > mst = new ArrayList <> (); // Priority queue for selecting minimum weight edge PriorityQueue < Vertex > pq = new PriorityQueue <> (); int [] key = new int [ V ] ; int [] parent = new int [ V ] ; boolean [] inMST = new boolean [ V ] ; // Initialize keys and parent Arrays . fill ( key , Integer . MAX_VALUE ); Arrays . fill ( parent , - 1 ); // Start with vertex 0 key [ 0 ] = 0 ; pq . offer ( new Vertex ( 0 , 0 )); while ( ! pq . isEmpty ()) { int u = pq . poll (). id ; // Skip if already processed if ( inMST [ u ] ) continue ; inMST [ u ] = true ; // Add edge to MST if not root if ( parent [ u ] != - 1 ) { mst . add ( new Edge ( u , key [ u ] )); } // Update keys of adjacent vertices for ( Edge edge : graph . get ( u )) { int v = edge . dest ; if ( ! inMST [ v ] && edge . weight < key [ v ] ) { key [ v ] = edge . weight ; parent [ v ] = u ; pq . offer ( new Vertex ( v , key [ v ] )); } } } return mst ; } }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_14","text":"Use priority queue for efficiency Maintain key values properly Handle disconnected components Consider dense vs sparse graphs","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_14","text":"Prim's Algorithm Prim's MST Algorithm","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison_4","text":"Feature Ford-Fulkerson Prim's Algorithm Time Complexity O(EF) O(E log V) Space Complexity O(V + E) O(V) Primary Use Max Flow Minimum Spanning Tree Data Structure Residual Graph Priority Queue Approach Iterative Improvement Greedy Growth Graph Type Directed Undirected Key Feature Augmenting Paths Local Optimization","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-best-practices_2","text":"","title":"\ud83d\udca1 Implementation Best Practices"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips_4","text":"Validate input graphs Handle edge cases Use efficient data structures Consider performance optimizations","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_5","text":"Incorrect flow updates Memory management issues Infinite loops Edge weight handling","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#substring-search-algorithms-guide","text":"","title":"\ud83d\udd0d Substring Search Algorithms Guide"},{"location":"1.Fundamentals/c.%20algorithms/#introduction_4","text":"Substring search algorithms are fundamental techniques for finding pattern matches within text. These algorithms are essential for: \ud83d\udcdd Text Processing : Finding words or patterns in documents \ud83d\udd0e Search Engines : Locating specific content \ud83e\uddec DNA Sequence Analysis : Finding genetic patterns \ud83d\udcda Plagiarism Detection : Identifying text matches \ud83d\udd04 Data Validation : Pattern matching in strings","title":"\ud83d\udcd8 Introduction"},{"location":"1.Fundamentals/c.%20algorithms/#basic-search-algorithms_1","text":"","title":"\ud83d\udd0d Basic Search Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#1-brute-force-search","text":"A straightforward approach that checks every possible position in the text.","title":"1\ufe0f\u20e3 Brute Force Search"},{"location":"1.Fundamentals/c.%20algorithms/#properties_16","text":"\u2705 Simple implementation \u2705 No preprocessing required \u2705 Works with any pattern \ud83d\udd04 Time: O(mn) \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_14","text":"Short patterns Short texts Simple implementations When preprocessing overhead isn't worth it When pattern varies frequently public static List < Integer > bruteForce ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); int n = text . length (); int m = pattern . length (); // Check each possible position in text for ( int i = 0 ; i <= n - m ; i ++ ) { boolean found = true ; // Check pattern match starting at position i for ( int j = 0 ; j < m ; j ++ ) { if ( comparator . compare ( pattern . charAt ( j ), text . charAt ( i + j )) != 0 ) { found = false ; break ; } } if ( found ) { matches . add ( i ); } } return matches ; }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_15","text":"Early termination on mismatch Handle edge cases properly Consider text/pattern lengths Validate inputs carefully","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#2-rabin-karp-algorithm","text":"Uses hashing to find exact pattern matches in text.","title":"2\ufe0f\u20e3 Rabin-Karp Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_17","text":"\u2705 Efficient for multiple patterns \u2705 Rolling hash function \u2705 Good average case \ud83d\udd04 Time: Average O(n+m), Worst O(mn) \ud83d\udcbe Space: O(1)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_15","text":"Multiple pattern matching Long texts Pattern finding in streams Plagiarism detection When preprocessing pattern is beneficial public static List < Integer > rabinKarp ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); int m = pattern . length (); int n = text . length (); if ( m > n ) return matches ; // Calculate pattern hash and first window hash int base = 113 ; // Prime base int patternHash = 0 ; int windowHash = 0 ; int highestPow = 1 ; // Calculate highest power of base needed for ( int i = 0 ; i < m - 1 ; i ++ ) { highestPow = highestPow * base ; } // Calculate initial hashes for ( int i = 0 ; i < m ; i ++ ) { patternHash = patternHash * base + pattern . charAt ( i ); windowHash = windowHash * base + text . charAt ( i ); } // Slide window and check matches for ( int i = 0 ; i <= n - m ; i ++ ) { if ( patternHash == windowHash ) { // Verify character by character boolean match = true ; for ( int j = 0 ; j < m ; j ++ ) { if ( comparator . compare ( pattern . charAt ( j ), text . charAt ( i + j )) != 0 ) { match = false ; break ; } } if ( match ) { matches . add ( i ); } } // Calculate hash for next window if ( i < n - m ) { windowHash = ( windowHash - text . charAt ( i ) * highestPow ) * base + text . charAt ( i + m ); } } return matches ; }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_16","text":"Choose appropriate hash function Handle hash collisions Use efficient rolling hash Consider modulo operations for large texts","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_15","text":"Rabin Karp Algorithm","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison_5","text":"Feature Brute Force Rabin-Karp Time Complexity (Worst) O(mn) O(mn) Time Complexity (Average) O(mn) O(n+m) Space Complexity O(1) O(1) Preprocessing No Yes Multiple Patterns Inefficient Efficient Implementation Simple Moderate Best Case O(n) O(n+m) Hash Function N/A Yes","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-best-practices_3","text":"","title":"\ud83d\udca1 Implementation Best Practices"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips_5","text":"Validate input parameters Handle edge cases Consider pattern/text lengths Use appropriate data structures","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_6","text":"Integer overflow in hash calculation Not handling collisions Inefficient hash updates Missing edge cases","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-substring-search-algorithms","text":"","title":"\ud83d\udd0d Advanced Substring Search Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#overview_3","text":"These advanced substring search algorithms use preprocessing for more efficient pattern matching. They are crucial for: \ud83d\ude80 High Performance Search : Fast pattern matching \ud83d\udcca Big Data Analysis : Processing large text efficiently \ud83d\udd04 Real-time Matching : Stream processing \ud83d\udcdd Text Editors : Efficient find/replace operations \ud83e\uddec Bioinformatics : DNA sequence matching","title":"\ud83d\udcd8 Overview"},{"location":"1.Fundamentals/c.%20algorithms/#advanced-algorithms","text":"","title":"\ud83d\udd0d Advanced Algorithms"},{"location":"1.Fundamentals/c.%20algorithms/#1-knuth-morris-pratt-kmp","text":"An efficient pattern matching algorithm that utilizes a failure table to avoid unnecessary comparisons.","title":"1\ufe0f\u20e3 Knuth-Morris-Pratt (KMP)"},{"location":"1.Fundamentals/c.%20algorithms/#properties_18","text":"\u2705 Linear time complexity \u2705 Preprocesses pattern \u2705 No backward movement in text \ud83d\udd04 Time: O(n + m) \ud83d\udcbe Space: O(m)","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_16","text":"Long patterns Repetitive patterns Streaming data Real-time matching When text cannot be buffered public static List < Integer > kmp ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); if ( pattern . length () > text . length ()) { return matches ; } // Build failure table int [] failureTable = buildFailureTable ( pattern , comparator ); int i = 0 ; // text index int j = 0 ; // pattern index while ( i <= text . length () - pattern . length ()) { while ( j < pattern . length () && comparator . compare ( text . charAt ( i + j ), pattern . charAt ( j )) == 0 ) { j ++ ; } if ( j == 0 ) { i ++ ; } else { if ( j == pattern . length ()) { matches . add ( i ); } int nextAlignment = failureTable [ j - 1 ] ; i = i + j - nextAlignment ; j = nextAlignment ; } } return matches ; } public static int [] buildFailureTable ( CharSequence pattern , CharacterComparator comparator ) { int [] failureTable = new int [ pattern . length () ] ; int i = 0 ; int j = 1 ; failureTable [ 0 ] = 0 ; while ( j < pattern . length ()) { if ( comparator . compare ( pattern . charAt ( i ), pattern . charAt ( j )) == 0 ) { failureTable [ j ] = i + 1 ; i ++ ; j ++ ; } else { if ( i == 0 ) { failureTable [ j ] = 0 ; j ++ ; } else { i = failureTable [ i - 1 ] ; } } } return failureTable ; }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_17","text":"Build failure table efficiently Handle pattern prefixes Avoid backing up in text Consider pattern preprocessing time","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_16","text":"Knuth-Morris-Pratt Algorithm","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#2-boyer-moore-algorithm","text":"A pattern matching algorithm that uses two heuristics: bad character and good suffix rules.","title":"2\ufe0f\u20e3 Boyer-Moore Algorithm"},{"location":"1.Fundamentals/c.%20algorithms/#properties_19","text":"\u2705 Sublinear time in practice \u2705 Two preprocessing tables \u2705 Right-to-left scanning \ud83d\udd04 Time: O(n/m) best, O(mn) worst \ud83d\udcbe Space: O(k) where k is alphabet size","title":"\ud83d\udcca Properties"},{"location":"1.Fundamentals/c.%20algorithms/#best-used-for_17","text":"Long patterns Large alphabets Natural language text When pattern is rare in text When preprocessing time is acceptable public static List < Integer > boyerMoore ( CharSequence pattern , CharSequence text , CharacterComparator comparator ) { if ( pattern == null || pattern . length () == 0 ) { throw new IllegalArgumentException ( \"Pattern cannot be null or empty\" ); } if ( text == null || comparator == null ) { throw new IllegalArgumentException ( \"Text and comparator cannot be null\" ); } List < Integer > matches = new ArrayList <> (); if ( pattern . length () > text . length ()) { return matches ; } // Build last occurrence table Map < Character , Integer > lastTable = buildLastTable ( pattern ); int i = 0 ; while ( i <= text . length () - pattern . length ()) { int j = pattern . length () - 1 ; // Match pattern from right to left while ( j >= 0 && comparator . compare ( pattern . charAt ( j ), text . charAt ( i + j )) == 0 ) { j -- ; } if ( j == - 1 ) { matches . add ( i ); i ++ ; } else { // Get last occurrence of mismatched character char mismatchChar = text . charAt ( i + j ); int lastOccurrence = lastTable . getOrDefault ( mismatchChar , - 1 ); // Calculate shift if ( lastOccurrence < j ) { i += j - lastOccurrence ; } else { i ++ ; } } } return matches ; } public static Map < Character , Integer > buildLastTable ( CharSequence pattern ) { Map < Character , Integer > lastTable = new HashMap <> (); // Record last occurrence of each character in pattern for ( int i = 0 ; i < pattern . length (); i ++ ) { lastTable . put ( pattern . charAt ( i ), i ); } return lastTable ; }","title":"\ud83d\udca1 Best Used For:"},{"location":"1.Fundamentals/c.%20algorithms/#key-tips_18","text":"Implement both heuristics correctly Handle character set efficiently Consider preprocessing overhead Use appropriate shift calculations","title":"\ud83d\udd11 Key Tips:"},{"location":"1.Fundamentals/c.%20algorithms/#references_17","text":"Boyer-Moore Algorithm","title":"References"},{"location":"1.Fundamentals/c.%20algorithms/#algorithm-comparison_6","text":"Feature KMP Boyer-Moore Time Complexity (Worst) O(n + m) O(mn) Time Complexity (Average) O(n + m) O(n/m) Space Complexity O(m) O(k) Pattern Scan Direction Left to Right Right to Left Preprocessing Failure Table Last Occurrence Table Best Case O(n) O(n/m) Text Scan Direction Forward Only Can Skip Characters Implementation Moderate Complex","title":"\ud83d\udcca Algorithm Comparison"},{"location":"1.Fundamentals/c.%20algorithms/#implementation-best-practices_4","text":"","title":"\ud83d\udca1 Implementation Best Practices"},{"location":"1.Fundamentals/c.%20algorithms/#general-tips_6","text":"Use efficient preprocessing Handle border cases Consider alphabet size Choose algorithm based on pattern characteristics","title":"\ud83c\udfaf General Tips"},{"location":"1.Fundamentals/c.%20algorithms/#common-pitfalls_7","text":"Incorrect preprocessing tables Inefficient character comparisons Wrong shift calculations Missing edge cases","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"1.Fundamentals/c.%20algorithms/#final-reference-to-algorithm-notes","text":"CS 1332 Data Structures and Algorithms","title":"Final Reference to Algorithm Notes"},{"location":"2.Interviews/b.%20technical%20interviews/","text":"\ud83d\ude80 The Ultimate Python Technical Interview Guide \u00b6 \ud83d\udcd8 Introduction \u00b6 Welcome to your comprehensive companion for mastering technical interviews! Whether you're aiming for FAANG companies or preparing for your first technical interview, this guide will help you tackle coding challenges with confidence. \ud83c\udfaf Why This Guide? \u00b6 \ud83d\udc0d Python-Focused : All solutions and examples in Python (the most popular interview language!) \ud83e\udde0 Pattern Recognition : Learn to spot and solve common problem patterns \u26a1 Optimization Skills : Master the art of writing efficient code \ud83c\udf93 Interview Strategy : Learn not just what to code, but how to approach problems \ud83d\udcaa Practical Examples : Real interview problems with detailed solutions \ud83c\udfa8 How This Guide is Different \u00b6 We believe learning should be fun! You'll find: \ud83c\udfae Interactive examples \ud83c\udfaf Pattern-based learning \ud83e\udde9 Visual explanations \ud83d\udca1 \"Aha!\" moment highlights \ud83d\udeab Common pitfall warnings \ud83d\uddfa\ufe0f Guide Structure \u00b6 1\ufe0f\u20e3 Foundation Building \u00b6 Big-O Notation and Complexity Analysis Python-specific optimizations Core data structures in Python Essential algorithms and their implementations 2\ufe0f\u20e3 Pattern Recognition \u00b6 Common interview patterns When to use which approach Pattern-specific optimizations Real interview problem mappings 3\ufe0f\u20e3 Interview Strategy \u00b6 Problem-solving framework Communication tips Code organization Testing approaches Good References \u00b6 Technical Interview Github Repo \ud83d\udcbb Before We Begin: Python Essentials \u00b6 \ud83d\udd27 Key Python Tools for Interviews \u00b6 # Common imports you'll need from collections import defaultdict , deque , Counter from heapq import heappush , heappop from typing import List , Dict , Set \ud83d\udee0\ufe0f Python-Specific Pro Tips \u00b6 # 1. List comprehension for cleaner code squares = [ x * x for x in range ( 10 )] # 2. Default dictionaries for counting counter = defaultdict ( int ) # 3. Built-in sort with custom key items . sort ( key = lambda x : x . value ) # 4. Multiple assignment x , y = y , x # Swap values \ud83c\udfaf How to Use This Guide \u00b6 \ud83d\udcda Learning Path \u00b6 Build the Foundation Master Python basics Understand complexity analysis Learn core data structures Pattern Recognition Study common patterns Practice similar problems Learn pattern variations Problem Solving Apply patterns to new problems Practice optimization Work on communication \u23f0 Time Management \u00b6 \ud83c\udf31 Beginner : 2-3 months of preparation \ud83c\udf3f Intermediate : 1-2 months of focused practice \ud83c\udf33 Advanced : 2-3 weeks of revision \ud83c\udfae Let's Get Started! \u00b6 \ud83c\udfaf Your First Steps \u00b6 Review Python fundamentals Start with easy problems Focus on problem-solving process Practice explaining your thought process \ud83d\udca1 Remember \u00b6 Understanding patterns > Memorizing solutions Practice regularly > Cramming Clear communication > Perfect code Learning from mistakes > Getting it right first time \ud83d\udea8 Common Interview Mistakes to Avoid \u00b6 Jumping into coding without planning Not clarifying requirements Ignoring edge cases Writing unclear/messy code Not testing your solution \ud83c\udf1f Success Tips \u00b6 Think aloud while solving Start with brute force, then optimize Use meaningful variable names Write clean, modular code Test with edge cases Ready to begin your journey to interview success? Let's dive into our first topic: Algorithmic Complexity and Big-O Notation! \ud83d\ude80 \ud83c\udfaf Algorithmic Complexity & Big-O Guide \u00b6 \ud83c\udfa8 Visual Complexity Chart \u00b6 Excellent O(1) \u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581 Good O(log n) \u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582 Fair O(n) \u2581\u2581\u2581\u2582\u2582\u2582\u2583\u2583\u2583\u2584\u2584\u2584\u2585\u2585\u2585\u2586\u2586\u2586 Bad O(n\u00b2) \u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Horrible O(2\u207f) \u2581\u2582\u2585\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 blog.algomaster.io \ud83c\udfae What is Algorithmic Complexity? \u00b6 Think of algorithmic complexity as your code's \"price tag\" in terms of: \u23f1\ufe0f Time (how long it takes to run) \ud83d\udcbe Space (how much memory it needs) \ud83c\udfaf Why Should You Care? \u00b6 # Example 1: O(n) - Linear Time def find_max_linear ( arr ): # \ud83d\ude0a Good for small lists return max ( arr ) # Example 2: O(n\u00b2) - Quadratic Time def find_max_nested ( arr ): # \ud83d\ude30 Terrible for large lists max_val = arr [ 0 ] for i in arr : for j in arr : # Unnecessary nested loop! if i > max_val : max_val = i return max_val \ud83d\ude80 Understanding Big-O Notation \u00b6 \ud83d\udcca Common Time Complexities (From Best to Worst) \u00b6 O(1) - Constant Time \ud83c\udf1f def get_first ( arr ): return arr [ 0 ] if arr else None Like finding a book when you know exactly where it is Examples: Hash table access, array index access O(log n) - Logarithmic Time \u2728 def binary_search ( arr , target ): left , right = 0 , len ( arr ) - 1 while left <= right : mid = ( left + right ) // 2 if arr [ mid ] == target : return mid if arr [ mid ] < target : left = mid + 1 else : right = mid - 1 return - 1 Like finding a word in a dictionary Examples: Binary search, balanced BST operations O(n) - Linear Time \ud83d\udc4d def linear_search ( arr , target ): return any ( x == target for x in arr ) Like reading every page in a book Examples: Array traversal, linear search O(n log n) - Log-Linear Time \ud83c\udd97 def merge_sort ( arr ): if len ( arr ) <= 1 : return arr mid = len ( arr ) // 2 return merge ( merge_sort ( arr [: mid ]), merge_sort ( arr [ mid :])) Like sorting a deck of cards efficiently Examples: Merge sort, quick sort (average case) O(n\u00b2) - Quadratic Time \ud83d\ude30 def bubble_sort ( arr ): for i in range ( len ( arr )): for j in range ( len ( arr ) - 1 ): if arr [ j ] > arr [ j + 1 ]: arr [ j ], arr [ j + 1 ] = arr [ j + 1 ], arr [ j ] Like comparing every page with every other page Examples: Nested loops, bubble sort O(2\u207f) - Exponential Time \ud83d\ude31 def fibonacci_recursive ( n ): if n <= 1 : return n return fibonacci_recursive ( n - 1 ) + fibonacci_recursive ( n - 2 ) Like trying every possible combination Examples: Recursive Fibonacci, power set \ud83c\udfae Common Space Complexities \u00b6 O(1) - Constant Space Fixed amount of extra space Example: Simple variables, fixed-size arrays O(n) - Linear Space Space grows linearly with input Example: Creating a new array of size n O(n\u00b2) - Quadratic Space Space grows quadratically Example: 2D array/matrix of size n\u00d7n \ud83c\udfaf Big-O Cheat Sheet for Common Data Structures \u00b6 Array Operations \u00b6 # Access: O(1) arr [ 5 ] # Direct access by index # Search: O(n) target in arr # Linear search # Insertion/Deletion at end: O(1) arr . append ( item ) # Add to end arr . pop () # Remove from end # Insertion/Deletion at middle: O(n) arr . insert ( 2 , item ) # Need to shift elements Dictionary/Hash Table Operations \u00b6 # Access/Insert/Delete: O(1) average dict_example = {} dict_example [ 'key' ] = 'value' # O(1) value = dict_example [ 'key' ] # O(1) del dict_example [ 'key' ] # O(1) \ud83c\udfae Pro Tips for Optimization \u00b6 Avoid Nested Loops When Possible # Bad: O(n\u00b2) for i in range ( n ): for j in range ( n ): # do something # Better: O(n) seen = set () for i in range ( n ): if i in seen : # do something Use Built-in Data Structures Wisely # Lists vs Sets for lookups numbers = [ 1 , 2 , 3 , 4 , 5 ] number_set = set ( numbers ) # Bad: O(n) 5 in numbers # Good: O(1) 5 in number_set Cache Results When Possible from functools import lru_cache @lru_cache ( maxsize = None ) def fibonacci ( n ): if n < 2 : return n return fibonacci ( n - 1 ) + fibonacci ( n - 2 ) \ud83c\udfaf Practice Problems \u00b6 Identify the Time Complexity def mystery_function ( n ): result = 0 for i in range ( n ): for j in range ( i , n ): result += 1 return result # What's the time complexity? # (Answer: O(n\u00b2)) Remember: The best algorithm is often a balance between: \u23f1\ufe0f Time complexity \ud83d\udcbe Space complexity \ud83c\udfaf Code readability \ud83d\udd27 Maintainability \ud83e\uddee Bit Manipulation & Sorting Algorithms \u00b6 Part 1: \ud83d\udd22 Bit Manipulation \u00b6 \ud83c\udfaf Why Bit Manipulation? \u00b6 \u26a1 More efficient than arithmetic operations \ud83d\ude80 Essential for optimization problems \ud83d\udcbb Crucial for low-level programming \ud83d\udcdd Common in technical interviews \ud83d\udee0\ufe0f Basic Operators \u00b6 # AND (&): 1 if both bits are 1 print ( 5 & 3 ) # 5(101) & 3(011) = 1(001) # OR (|): 1 if either bit is 1 print ( 5 | 3 ) # 5(101) | 3(011) = 7(111) # XOR (^): 1 if bits are different print ( 5 ^ 3 ) # 5(101) ^ 3(011) = 6(110) # NOT (~): Inverts all bits print ( ~ 5 ) # 5(101) -> -(110) # Left Shift (<<): Multiply by 2^n print ( 5 << 1 ) # 5(101) << 1 = 10(1010) # Right Shift (>>): Divide by 2^n print ( 5 >> 1 ) # 5(101) >> 1 = 2(010) \ud83c\udfae Common Bit Manipulation Tricks \u00b6 Check if Number is Even/Odd def is_even ( n : int ) -> bool : return not ( n & 1 ) # Last bit is 0 for even numbers Multiply/Divide by Powers of 2 def multiply_by_2 ( n : int ) -> int : return n << 1 # Left shift = multiply by 2 def divide_by_2 ( n : int ) -> int : return n >> 1 # Right shift = divide by 2 Set/Clear/Toggle Bits def set_bit ( n : int , pos : int ) -> int : return n | ( 1 << pos ) def clear_bit ( n : int , pos : int ) -> int : return n & ~ ( 1 << pos ) def toggle_bit ( n : int , pos : int ) -> int : return n ^ ( 1 << pos ) Check if Bit is Set def is_bit_set ( n : int , pos : int ) -> bool : return bool ( n & ( 1 << pos )) \ud83c\udfaf Interview Tips for Bit Manipulation \u00b6 Always visualize bits on paper Test with small numbers first Consider edge cases (negatives, zero) Explain your logic step by step Part 2: \ud83d\udd04 Sorting Algorithms \u00b6 \ud83d\udcca Comparison Overview \u00b6 sorting_algos = { 'Bubble Sort' : { 'Time' : 'O(n\u00b2)' , 'Space' : 'O(1)' , 'Stable' : True }, 'Selection Sort' : { 'Time' : 'O(n\u00b2)' , 'Space' : 'O(1)' , 'Stable' : False }, 'Insertion Sort' : { 'Time' : 'O(n\u00b2)' , 'Space' : 'O(1)' , 'Stable' : True }, 'Merge Sort' : { 'Time' : 'O(n log n)' , 'Space' : 'O(n)' , 'Stable' : True }, 'Quick Sort' : { 'Time' : 'O(n log n)' , 'Space' : 'O(log n)' , 'Stable' : False }, 'Heap Sort' : { 'Time' : 'O(n log n)' , 'Space' : 'O(1)' , 'Stable' : False } } \ud83c\udfaf Simple Sorting Algorithms \u00b6 Bubble Sort (The Beginner's Sort) def bubble_sort ( arr : list ) -> list : n = len ( arr ) for i in range ( n ): # Flag for optimization swapped = False # Last i elements are already sorted for j in range ( 0 , n - i - 1 ): if arr [ j ] > arr [ j + 1 ]: arr [ j ], arr [ j + 1 ] = arr [ j + 1 ], arr [ j ] swapped = True # If no swaps occurred, array is sorted if not swapped : break return arr # When to use: Small arrays or nearly sorted data # Pros: Simple to implement, in-place sorting # Cons: Very inefficient for large datasets Selection Sort (The Minimalist's Sort) def selection_sort ( arr : list ) -> list : n = len ( arr ) for i in range ( n ): min_idx = i for j in range ( i + 1 , n ): if arr [ j ] < arr [ min_idx ]: min_idx = j arr [ i ], arr [ min_idx ] = arr [ min_idx ], arr [ i ] return arr # When to use: Small arrays with expensive writes # Pros: Minimum number of swaps # Cons: Always makes O(n\u00b2) comparisons Insertion Sort (The Adaptive Sort) def insertion_sort ( arr : list ) -> list : for i in range ( 1 , len ( arr )): key = arr [ i ] j = i - 1 while j >= 0 and arr [ j ] > key : arr [ j + 1 ] = arr [ j ] j -= 1 arr [ j + 1 ] = key return arr # When to use: Small datasets or nearly sorted arrays # Pros: Adaptive, stable, and great for small data # Cons: Still O(n\u00b2) in worst case \ud83d\ude80 Advanced Sorting Algorithms \u00b6 Merge Sort (The Reliable Sort) def merge_sort ( arr : list ) -> list : if len ( arr ) <= 1 : return arr mid = len ( arr ) // 2 left = merge_sort ( arr [: mid ]) right = merge_sort ( arr [ mid :]) return merge ( left , right ) def merge ( left : list , right : list ) -> list : result = [] i = j = 0 while i < len ( left ) and j < len ( right ): if left [ i ] <= right [ j ]: result . append ( left [ i ]) i += 1 else : result . append ( right [ j ]) j += 1 result . extend ( left [ i :]) result . extend ( right [ j :]) return result # When to use: Large datasets where stability matters # Pros: Stable, predictable O(n log n) # Cons: Requires O(n) extra space Quick Sort (The Practical Sort) def quick_sort ( arr : list ) -> list : if len ( arr ) <= 1 : return arr pivot = arr [ len ( arr ) // 2 ] left = [ x for x in arr if x < pivot ] middle = [ x for x in arr if x == pivot ] right = [ x for x in arr if x > pivot ] return quick_sort ( left ) + middle + quick_sort ( right ) # When to use: General-purpose sorting # Pros: Usually fastest in practice # Cons: Unstable, bad worst-case O(n\u00b2) Heap Sort (The Memory-Efficient Sort) def heapify ( arr : list , n : int , i : int ): largest = i left = 2 * i + 1 right = 2 * i + 2 if left < n and arr [ left ] > arr [ largest ]: largest = left if right < n and arr [ right ] > arr [ largest ]: largest = right if largest != i : arr [ i ], arr [ largest ] = arr [ largest ], arr [ i ] heapify ( arr , n , largest ) def heap_sort ( arr : list ) -> list : n = len ( arr ) # Build max heap for i in range ( n // 2 - 1 , - 1 , - 1 ): heapify ( arr , n , i ) # Extract elements from heap for i in range ( n - 1 , 0 , - 1 ): arr [ 0 ], arr [ i ] = arr [ i ], arr [ 0 ] heapify ( arr , i , 0 ) return arr # When to use: When space is a premium # Pros: In-place, O(n log n) guaranteed # Cons: Unstable, poor cache performance \ud83c\udfa8 Special Purpose Sorting Algorithms \u00b6 Shell Sort (The Gap Sort) def shell_sort ( arr : list ) -> list : n = len ( arr ) gap = n // 2 while gap > 0 : for i in range ( gap , n ): temp = arr [ i ] j = i while j >= gap and arr [ j - gap ] > temp : arr [ j ] = arr [ j - gap ] j -= gap arr [ j ] = temp gap //= 2 return arr # When to use: Medium-sized arrays # Pros: Adaptive, handles partially sorted arrays well # Cons: Complex gap sequence selection Counting Sort (The Integer Sort) def counting_sort ( arr : list ) -> list : if not arr : return arr # Find range of array elements max_val = max ( arr ) min_val = min ( arr ) range_val = max_val - min_val + 1 # Create counting array and output array count = [ 0 ] * range_val output = [ 0 ] * len ( arr ) # Store count of each element for num in arr : count [ num - min_val ] += 1 # Modify count array to store actual positions for i in range ( 1 , len ( count )): count [ i ] += count [ i - 1 ] # Build output array for num in reversed ( arr ): output [ count [ num - min_val ] - 1 ] = num count [ num - min_val ] -= 1 return output # When to use: Integer arrays with known range # Pros: O(n) for known range integers # Cons: Requires extra space proportional to range Radix Sort (The Digit Sort) def counting_sort_for_radix ( arr : list , exp : int ) -> list : n = len ( arr ) output = [ 0 ] * n count = [ 0 ] * 10 # Store count of occurrences for i in range ( n ): index = arr [ i ] // exp count [ index % 10 ] += 1 # Change count[i] to contain actual position for i in range ( 1 , 10 ): count [ i ] += count [ i - 1 ] # Build output array i = n - 1 while i >= 0 : index = arr [ i ] // exp output [ count [ index % 10 ] - 1 ] = arr [ i ] count [ index % 10 ] -= 1 i -= 1 # Copy output array to arr for i in range ( n ): arr [ i ] = output [ i ] def radix_sort ( arr : list ) -> list : if not arr : return arr # Find maximum number to know number of digits max_val = max ( arr ) # Do counting sort for every digit exp = 1 while max_val // exp > 0 : counting_sort_for_radix ( arr , exp ) exp *= 10 return arr # When to use: Integer arrays with fixed number of digits # Pros: Linear time possible for fixed-length integers # Cons: Only works with integers, uses extra space Bucket Sort (The Distribution Sort) def bucket_sort ( arr : list , num_buckets : int = 10 ) -> list : if not arr : return arr # Find range of values max_val , min_val = max ( arr ), min ( arr ) # Create buckets range_val = ( max_val - min_val ) / num_buckets buckets = [[] for _ in range ( num_buckets )] # Put elements in buckets for num in arr : if num == max_val : bucket_idx = num_buckets - 1 else : bucket_idx = int (( num - min_val ) / range_val ) buckets [ bucket_idx ] . append ( num ) # Sort individual buckets for bucket in buckets : bucket . sort () # Using TimSort internally in Python # Concatenate all buckets into arr return [ num for bucket in buckets for num in bucket ] # When to use: Uniformly distributed data over a range # Pros: Linear time possible for uniform distribution # Cons: Requires uniform distribution for efficiency Tim Sort (Python's Built-in Sort) # Python's built-in sort uses TimSort def tim_sort_example ( arr : list ) -> list : return sorted ( arr ) # Uses TimSort internally # When to use: General purpose sorting # Pros: Excellent performance on real-world data # Cons: Complex implementation, requires extra space \ud83c\udfaf Best Practices for Each Algorithm \u00b6 Simple Sorts (O(n\u00b2)) \u00b6 Bubble Sort : Nearly sorted data, teaching purposes Selection Sort : Small arrays, minimizing swaps Insertion Sort : Small arrays, online sorting Efficient Sorts (O(n log n)) \u00b6 Merge Sort : Stable sorting needed, linked lists Quick Sort : General purpose, arrays Heap Sort : Memory constrained, guaranteed O(n log n) Special Purpose Sorts \u00b6 Shell Sort : Medium-sized arrays, partially sorted data Counting Sort : Small range integers Radix Sort : Fixed-length integers, like phone numbers Bucket Sort : Uniformly distributed floating-point numbers Tim Sort : When you need the best of both worlds (stable & efficient) \ud83c\udfae Choosing the Right Sort \u00b6 Consider Your Data Size of dataset Data type (integers, floating-point, strings) Data distribution Range of values Consider Your Constraints Memory limitations Stability requirements Whether data is streaming (online) Performance requirements General Guidelines Small dataset (n < 50): Insertion Sort Memory constrained: Heap Sort Stability required: Merge Sort General purpose: Quick Sort or Tim Sort Integer data: Counting Sort or Radix Sort Remember: In Python, use the built-in sort() or sorted() for best performance! They use TimSort, which is optimized for real-world data patterns. \ud83d\ude80 \ud83d\udd17 Linked Lists & Dummy Node Technique Guide \u00b6 \ud83d\udcd8 Understanding Linked Lists \u00b6 \ud83c\udfaf What is a Linked List? \u00b6 class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next \ud83d\udcca Types of Linked Lists \u00b6 Singly Linked List # 1 -> 2 -> 3 -> None head = ListNode ( 1 ) head . next = ListNode ( 2 ) head . next . next = ListNode ( 3 ) Doubly Linked List class DoublyListNode : def __init__ ( self , val = 0 , next = None , prev = None ): self . val = val self . next = next self . prev = prev Circular Linked List # 1 -> 2 -> 3 -> 1 (cycles back) head = ListNode ( 1 ) head . next = ListNode ( 2 ) head . next . next = ListNode ( 3 ) head . next . next . next = head # Creates cycle \ud83d\udcda Core Implementation Options \u00b6 1\ufe0f\u20e3 Using collections.deque \u00b6 from collections import deque # Creating linked lists llist = deque () # Empty list llist = deque ([ 1 , 2 , 3 ]) # From iterable llist = deque ( 'abc' ) # From string # Common Operations llist . append ( x ) # Add to right llist . appendleft ( x ) # Add to left llist . pop () # Remove from right llist . popleft () # Remove from left 2\ufe0f\u20e3 Custom Linked List Implementation \u00b6 class Node : def __init__ ( self , data ): self . data = data self . next = None def __repr__ ( self ): return str ( self . data ) class LinkedList : def __init__ ( self , nodes = None ): self . head = None if nodes : node = Node ( data = nodes . pop ( 0 )) self . head = node for elem in nodes : node . next = Node ( data = elem ) node = node . next def __repr__ ( self ): nodes = [] curr = self . head while curr : nodes . append ( str ( curr . data )) curr = curr . next return \" -> \" . join ( nodes + [ \"None\" ]) def __iter__ ( self ): node = self . head while node : yield node node = node . next \ud83c\udfaf Common Pattern Templates \u00b6 1\ufe0f\u20e3 Two-Pointer Technique Template \u00b6 def two_pointer_template ( head ): # Initialize pointers slow = fast = head # Move pointers while fast and fast . next : slow = slow . next # Move one step fast = fast . next . next # Move two steps # Optional: Detection logic here if slow == fast : return True # Or other logic return False 2\ufe0f\u20e3 Reverse List Template \u00b6 def reverse_template ( head ): prev = None current = head while current : # Store next next_node = current . next # Reverse pointer current . next = prev # Move prev and current prev = current current = next_node return prev # New head 3\ufe0f\u20e3 Merge Lists Template \u00b6 def merge_template ( l1 , l2 ): dummy = Node ( 0 ) current = dummy while l1 and l2 : if l1 . val <= l2 . val : current . next = l1 l1 = l1 . next else : current . next = l2 l2 = l2 . next current = current . next # Attach remaining nodes current . next = l1 or l2 return dummy . next \ud83d\udee0\ufe0f Essential Operations Templates \u00b6 1\ufe0f\u20e3 Node Insertion \u00b6 def insert_operations (): # Insert at beginning - O(1) def add_first ( self , node ): node . next = self . head self . head = node # Insert at end - O(n) def add_last ( self , node ): if not self . head : self . head = node return for current in self : pass current . next = node # Insert after node - O(n) def add_after ( self , target_data , new_node ): if not self . head : raise Exception ( \"List is empty\" ) for node in self : if node . data == target_data : new_node . next = node . next node . next = new_node return raise Exception ( \"Node not found\" ) 2\ufe0f\u20e3 Node Deletion \u00b6 def removal_template ( self , target ): if not self . head : raise Exception ( \"List is empty\" ) # Handle head removal if self . head . data == target : self . head = self . head . next return # Handle other removals current = self . head while current . next : if current . next . data == target : current . next = current . next . next return current = current . next raise Exception ( \"Node not found\" ) \ud83c\udfaf The Dummy Node Technique \u00b6 \ud83d\udd11 Why Use Dummy Nodes? \u00b6 Simplifies edge cases Avoids null pointer exceptions Makes code cleaner and more uniform Particularly useful for: List manipulation Merging lists Removing elements Complex operations \ud83d\udcdd Dummy Node Pattern Template \u00b6 def linked_list_operation ( head : ListNode ) -> ListNode : # Create dummy node dummy = ListNode ( 0 ) dummy . next = head # Work with dummy node current = dummy while current . next : # Perform operations current = current . next # Return modified list return dummy . next \ud83c\udfaf Advanced Techniques with Dummy Nodes \u00b6 Multiple Dummy Nodes def oddEvenList ( head : ListNode ) -> ListNode : if not head : return None # Two dummy nodes for odd and even lists odd_dummy = ListNode ( 0 ) even_dummy = ListNode ( 0 ) odd = odd_dummy even = even_dummy is_odd = True current = head while current : if is_odd : odd . next = current odd = odd . next else : even . next = current even = even . next is_odd = not is_odd current = current . next # Connect odd and even lists odd . next = even_dummy . next even . next = None return odd_dummy . next Dummy Node w/ Fast/Slower Pointers def hasCycle ( head : ListNode ) -> bool : dummy = ListNode ( 0 ) dummy . next = head slow = dummy fast = dummy while fast and fast . next : slow = slow . next fast = fast . next . next if slow == fast : return True return False \ud83c\udfaf Interview Tips \u00b6 When to Use Dummy Nodes List modification required Head might change Multiple pointer manipulation Merging or splitting lists Common Patterns # Pattern 1: Basic Dummy Node dummy = ListNode ( 0 ) dummy . next = head current = dummy # Pattern 2: Multiple Pointers dummy = ListNode ( 0 ) slow = fast = dummy # Pattern 3: Multiple Dummies dummy1 = ListNode ( 0 ) dummy2 = ListNode ( 0 ) Edge Cases to Consider Empty list Single node Two nodes Cycles in list Duplicate values \ud83c\udfae Practice Problems \u00b6 Reverse Linked List Detect Cycle Find Middle Node Remove Duplicates Merge K Sorted Lists Remember: Always handle edge cases first Consider using dummy nodes for cleaner code Test with small examples Draw the list operations on paper Keep track of all pointers carefully \ud83d\udd04 Stack & Queue Implementations in Python \u00b6 \ud83d\udcda Stack Implementations \u00b6 1\ufe0f\u20e3 Using List as Stack \u00b6 class ListStack : def __init__ ( self ): self . stack = [] def push ( self , item ): self . stack . append ( item ) def pop ( self ): if not self . is_empty (): return self . stack . pop () raise IndexError ( \"Stack is empty\" ) def peek ( self ): if not self . is_empty (): return self . stack [ - 1 ] raise IndexError ( \"Stack is empty\" ) def is_empty ( self ): return len ( self . stack ) == 0 def size ( self ): return len ( self . stack ) 2\ufe0f\u20e3 Using Collections.deque as Stack \u00b6 from collections import deque class DequeStack : def __init__ ( self ): self . stack = deque () def push ( self , item ): self . stack . append ( item ) def pop ( self ): if not self . is_empty (): return self . stack . pop () raise IndexError ( \"Stack is empty\" ) def peek ( self ): if not self . is_empty (): return self . stack [ - 1 ] raise IndexError ( \"Stack is empty\" ) def is_empty ( self ): return len ( self . stack ) == 0 def size ( self ): return len ( self . stack ) Common Stack Pattern Templates \u00b6 Basic Stack Operations Pattern def stack_pattern ( data ): stack = [] # or deque() for item in data : # Process current item while stack and some_condition ( stack [ - 1 ], item ): # Do something with stack.pop() pass stack . append ( item ) return result Monotonic Stack Pattern def monotonic_stack_pattern ( arr ): stack = [] # stores indices usually result = [ 0 ] * len ( arr ) # or any default value for i in range ( len ( arr )): # For increasing stack (next smaller) while stack and arr [ stack [ - 1 ]] > arr [ i ]: popped = stack . pop () result [ popped ] = i - popped # or any calculation stack . append ( i ) return result \ud83d\udcdd Queue Implementations \u00b6 1\ufe0f\u20e3 Using Collections.deque as Queue \u00b6 from collections import deque class DequeQueue : def __init__ ( self ): self . queue = deque () def enqueue ( self , item ): self . queue . append ( item ) def dequeue ( self ): if not self . is_empty (): return self . queue . popleft () raise IndexError ( \"Queue is empty\" ) def front ( self ): if not self . is_empty (): return self . queue [ 0 ] raise IndexError ( \"Queue is empty\" ) def rear ( self ): if not self . is_empty (): return self . queue [ - 1 ] raise IndexError ( \"Queue is empty\" ) def is_empty ( self ): return len ( self . queue ) == 0 def size ( self ): return len ( self . queue ) 2\ufe0f\u20e3 Queue Implementation \u00b6 from queue import Queue # Thread-safe queue usage queue = Queue () queue . put ( item ) # Enqueue item = queue . get () # Dequeue size = queue . qsize () # Size empty = queue . empty () \ud83c\udfaf Common Implementation Patterns \u00b6 Pattern 1: LIFO Stack Pattern \u00b6 def stack_pattern ( data ): stack = [] # or deque() for item in data : # Process current item while stack and condition ( stack [ - 1 ], item ): # Process stack.pop() pass stack . append ( item ) return result Pattern 2: FIFO Queue Pattern \u00b6 def queue_pattern ( start_node ): queue = deque ([ start_node ]) seen = { start_node } while queue : current = queue . popleft () # Process current node for neighbor in get_neighbors ( current ): if neighbor not in seen : seen . add ( neighbor ) queue . append ( neighbor ) \ud83d\udd11 Key Operations & Complexities \u00b6 Stack Operations \u00b6 operations = { 'push' : 'O(1)' , # Add to top 'pop' : 'O(1)' , # Remove from top 'peek' : 'O(1)' , # View top element 'isEmpty' : 'O(1)' , # Check if empty 'size' : 'O(1)' # Get number of elements } Queue Operations \u00b6 operations = { 'enqueue' : 'O(1)' , # Add to back 'dequeue' : 'O(1)' , # Remove from front 'front' : 'O(1)' , # View front element 'isEmpty' : 'O(1)' , # Check if empty 'size' : 'O(1)' # Get number of elements } \ud83d\udca1When to Use What \u00b6 Use Stack When: \u00b6 Need LIFO (Last In, First Out) behavior Tracking state changes (undo/redo) Parse expressions (parentheses matching) Function call management DFS implementation Use Queue When: \u00b6 Need FIFO (First In, First Out) behavior Order must be preserved BFS implementation Task scheduling Resource pooling \ud83c\udfaf Implementation Comparison \u00b6 Stack Implementation Comparison \u00b6 # List as Stack - Pros: Simple, built-in, good for small data - Cons: Potential memory reallocation for large data - Use when: Simple stack operations needed # Deque as Stack - Pros: Efficient memory usage, thread-safe - Cons: Slightly more complex than list - Use when: Large data or thread safety needed Queue Implementation Comparison \u00b6 # Deque as Queue - Pros: O(1) operations, efficient memory - Cons: Not fixed size - Use when: General queue operations needed # Queue - Pros: Memory efficient, fixed size - Cons: More complex implementation - Use when: Fixed size buffer needed \ud83c\udfae Practice Problem Tips \u00b6 Always clarify: Is there a size limit? What happens on empty pop/dequeue? Should operations be thread-safe? What type of elements to store? Consider: Time/Space complexity requirements Concurrency needs Error handling approach Edge cases Remember: Use collections.deque for efficient implementation Consider thread-safety needs before choosing implementation Watch for operation order dependence Handle edge cases explicitly \ud83d\uddc3\ufe0f Hash Tables in Python (Dictionaries) \u00b6 \ud83d\udcda Basic Implementation \u00b6 1\ufe0f\u20e3 Dictionary Creation \u00b6 # Method 1: Using curly braces hash_map = { 'key1' : 'value1' , 'key2' : 'value2' } # Method 2: Using dict() constructor hash_map = dict ( key1 = 'value1' , key2 = 'value2' ) # Method 3: From list of tuples hash_map = dict ([ ( 'key1' , 'value1' ), ( 'key2' , 'value2' ) ]) # Method 4: Empty dictionary hash_map = {} 2\ufe0f\u20e3 Basic Operations \u00b6 # Access Operations - O(1) average case hash_map [ 'key' ] = 'value' # Insert/Update value = hash_map [ 'key' ] # Access del hash_map [ 'key' ] # Delete # Safe Access value = hash_map . get ( 'key' , default_value ) # Returns default_value if key not found # Check Existence - O(1) if 'key' in hash_map : # Key exists pass \ud83c\udfaf Common Hash Table Patterns \u00b6 1\ufe0f\u20e3 Counting Pattern \u00b6 def counting_pattern ( items ): counter = {} # Count occurrences for item in items : counter [ item ] = counter . get ( item , 0 ) + 1 return counter # Alternative using defaultdict from collections import defaultdict def counting_with_defaultdict ( items ): counter = defaultdict ( int ) for item in items : counter [ item ] += 1 return counter 2\ufe0f\u20e3 Grouping Pattern \u00b6 def grouping_pattern ( items , key_func ): groups = {} for item in items : key = key_func ( item ) if key not in groups : groups [ key ] = [] groups [ key ] . append ( item ) return groups # Alternative using defaultdict def grouping_with_defaultdict ( items , key_func ): groups = defaultdict ( list ) for item in items : groups [ key_func ( item )] . append ( item ) return groups 3\ufe0f\u20e3 Caching/Memoization Pattern \u00b6 def memoization_pattern (): cache = {} def memoized_func ( arg ): if arg not in cache : cache [ arg ] = compute_value ( arg ) return cache [ arg ] return memoized_func # Alternative using @lru_cache from functools import lru_cache @lru_cache ( maxsize = None ) def cached_function ( arg ): return compute_value ( arg ) 4\ufe0f\u20e3 Two-Sum Pattern \u00b6 def two_sum_pattern ( nums , target ): seen = {} # value -> index for i , num in enumerate ( nums ): complement = target - num if complement in seen : return [ seen [ complement ], i ] seen [ num ] = i return [] \ud83c\udfae Advanced Techniques \u00b6 1\ufe0f\u20e3 Multi-Level Dictionary \u00b6 # Creation multi_level = { 'level1' : { 'level2' : { 'level3' : 'value' } } } # Safe Navigation def safe_get ( dictionary , * keys , default = None ): current = dictionary for key in keys : if not isinstance ( current , dict ): return default current = current . get ( key , default ) return current 2\ufe0f\u20e3 Dictionary Comprehension \u00b6 # Basic comprehension squares = { x : x * x for x in range ( 5 )} # Conditional comprehension even_squares = { x : x * x for x in range ( 5 ) if x % 2 == 0 } # Transforming dictionaries transformed = { k : v * 2 for k , v in original . items ()} 3\ufe0f\u20e3 Advanced Operations \u00b6 # Merging dictionaries dict3 = { ** dict1 , ** dict2 } # Python 3.5+ dict3 = dict1 | dict2 # Python 3.9+ # Get multiple values safely values = [ hash_map . get ( key ) for key in keys ] # Delete multiple keys for key in keys_to_delete : hash_map . pop ( key , None ) # Won't raise KeyError \ud83d\udcdd Common Interview Problem Patterns \u00b6 Frequency Counter Problems Character frequency in strings Word frequency in sentences Element frequency in arrays Two-Sum Type Problems Finding pairs with target sum Finding triplets Subarray with given sum Caching Problems Implementing LRU cache Memoization problems Function results caching String Problems Anagram detection First non-repeating character String permutations \ud83c\udfaf Practice Problems \u00b6 Frequency Based Find the first non-repeating character in a string Find if two strings are anagrams Most frequent element in an array Lookup Based Implement two sum Group anagrams together Find all pairs with given difference Caching Based Implement LRU cache Design a file system cache Implement memoization decorator Advanced Problems Design a time-based key-value store Implement a data structure that supports insert, delete, getRandom in O(1) Design a logger rate limiter \u26a0\ufe0f Common Pitfalls to Watch For \u00b6 Mutability Issues Using mutable objects as dictionary keys Modifying dictionary while iterating Performance Traps Repeatedly accessing the same key Not using .get() for default values Unnecessary key existence checks Memory Issues Unbounded growth in caching problems Not clearing references in long-running applications Edge Cases Empty dictionaries Non-existent keys None values vs missing keys Remember: Hash tables provide O(1) average case operations but require good hash functions and collision handling strategies. In Python, this is handled automatically by the dictionary implementation. \ud83c\udf33 Heaps for Technical Interviews \u00b6 \ud83d\udcda Core Concepts \u00b6 What is a Heap? \u00b6 \"\"\" A heap is a complete binary tree that satisfies the heap property: - Max Heap: Parent nodes are greater than or equal to children - Min Heap: Parent nodes are less than or equal to children - Python's heapq implements min heap \"\"\" # Key Properties: properties = { \"Complete Binary Tree\" : \"All levels filled except possibly last level\" , \"Heap Property\" : \"Parent-child relationship maintained throughout\" , \"Root\" : \"Smallest element (min heap) or largest element (max heap)\" , \"Implementation\" : \"Usually backed by an array/list\" , \"Height\" : \"O(log n) where n is number of nodes\" } Parent-Child Relationships in Array Implementation \u00b6 def get_relationships ( i : int ) -> dict : return { 'parent' : ( i - 1 ) // 2 , # Parent index 'left_child' : 2 * i + 1 , # Left child index 'right_child' : 2 * i + 2 , # Right child index } \ud83d\udd27 Basic Operations Using heapq \u00b6 1. Heap Creation \u00b6 import heapq # Method 1: Heapify existing list numbers = [ 3 , 1 , 4 , 1 , 5 , 9 , 2 , 6 , 5 , 3 , 5 ] heapq . heapify ( numbers ) # O(n) # Method 2: Create empty heap (just use list) heap = [] 2. Core Operations \u00b6 def heap_operations (): heap = [] # Push - O(log n) heapq . heappush ( heap , 5 ) # Pop - O(log n) smallest = heapq . heappop ( heap ) # Peek - O(1) if heap : smallest = heap [ 0 ] # Push and Pop combined - O(log n) smallest = heapq . heappushpop ( heap , 4 ) # Push then pop smallest = heapq . heapreplace ( heap , 4 ) # Pop then push 3. Helper Functions \u00b6 def heap_helpers ( items ): # Find n smallest elements - O(n log k) n_smallest = heapq . nsmallest ( 3 , items ) # Find n largest elements - O(n log k) n_largest = heapq . nlargest ( 3 , items ) # Merge sorted iterables - O(n log k) merged = heapq . merge ([ 1 , 3 , 5 ], [ 2 , 4 , 6 ]) \ud83c\udfaf Common Heap Patterns \u00b6 1. Priority Queue Implementation \u00b6 from dataclasses import dataclass , field from typing import Any @dataclass ( order = True ) class PrioritizedItem : priority : int item : Any = field ( compare = False ) class PriorityQueue : def __init__ ( self ): self . _queue = [] def push ( self , item , priority ): heapq . heappush ( self . _queue , PrioritizedItem ( priority , item )) def pop ( self ): return heapq . heappop ( self . _queue ) . item def peek ( self ): return self . _queue [ 0 ] . item if self . _queue else None 2. K-Way Merge Pattern \u00b6 def k_way_merge ( sorted_arrays ): \"\"\"Merge k sorted arrays using heap.\"\"\" merged = [] heap = [] # Initialize heap with first element from each array for i , arr in enumerate ( sorted_arrays ): if arr : heapq . heappush ( heap , ( arr [ 0 ], i , 0 )) while heap : val , array_index , elem_index = heapq . heappop ( heap ) merged . append ( val ) if elem_index + 1 < len ( sorted_arrays [ array_index ]): next_val = sorted_arrays [ array_index ][ elem_index + 1 ] heapq . heappush ( heap , ( next_val , array_index , elem_index + 1 )) return merged 3. Running Median Pattern \u00b6 class MedianFinder : def __init__ ( self ): self . small = [] # max heap (-ve numbers) self . large = [] # min heap def add_num ( self , num : int ) -> None : # Add to appropriate heap if len ( self . small ) == len ( self . large ): heapq . heappush ( self . large , - heapq . heappushpop ( self . small , - num )) else : heapq . heappush ( self . small , - heapq . heappushpop ( self . large , num )) def find_median ( self ) -> float : if len ( self . small ) == len ( self . large ): return ( - self . small [ 0 ] + self . large [ 0 ]) / 2.0 return float ( self . large [ 0 ]) \ud83c\udfaf Common Interview Problems \u00b6 Problem Types \u00b6 K-th Element Problems def find_kth_largest ( nums : List [ int ], k : int ) -> int : heap = [] for num in nums : heapq . heappush ( heap , num ) if len ( heap ) > k : heapq . heappop ( heap ) return heap [ 0 ] Merge Problems def merge_k_arrays ( arrays : List [ List [ int ]]) -> List [ int ]: return list ( heapq . merge ( * arrays )) Scheduling Problems def min_meeting_rooms ( intervals : List [ List [ int ]]) -> int : heap = [] # Track end times for start , end in sorted ( intervals ): if heap and heap [ 0 ] <= start : heapq . heapreplace ( heap , end ) else : heapq . heappush ( heap , end ) return len ( heap ) \u26a0\ufe0f Edge Cases to Consider \u00b6 def edge_cases_to_check (): \"\"\" 1. Empty heap operations 2. Single element heap 3. Duplicate elements 4. Negative numbers 5. Very large numbers 6. Equal priorities in priority queue \"\"\" pass \ud83c\udfaf Time Complexity Summary \u00b6 complexities = { \"heapify\" : \"O(n)\" , \"push\" : \"O(log n)\" , \"pop\" : \"O(log n)\" , \"peek\" : \"O(1)\" , \"heappushpop\" : \"O(log n)\" , \"nlargest/nsmallest\" : \"O(n log k)\" , # where k is the count requested \"merge k sorted lists\" : \"O(n log k)\" # where k is number of lists } \ud83d\udca1 Interview Tips \u00b6 Use heap when: Need to find k largest/smallest elements Need to continuously find min/max Need to merge sorted sequences Implementing priority queue Python Heap Notes: heapq implements min heap For max heap, negate values No decrease-key operation Can't access arbitrary elements Solution Strategy: Identify if problem needs min or max heap Consider if heap is overkill (sorted list might work) Check if priority queue would be clearer Think about space complexity tradeoffs Remember: Always verify time/space complexity Consider edge cases Explain heap property while coding Mention alternative approaches \ud83d\udd04 Recursion Guide for Technical Interviews \u00b6 \ud83d\udcda Core Concepts \u00b6 What is Recursion? \u00b6 \"\"\" Recursion is when a function calls itself either: 1. Directly: The function directly calls itself 2. Indirectly: Function A calls Function B which calls Function A Key Components: 1. Base Case (stopping condition) 2. Recursive Case (moving towards base case) \"\"\" Key Elements of Recursive Function \u00b6 def recursive_function ( input ): # 1. Base Case if input <= base_case : return base_value # 2. Recursive Case # - Must move towards base case # - Usually operates on smaller input return recursive_function ( smaller_input ) \ud83c\udfaf Common Recursion Patterns \u00b6 1. Linear Recursion Pattern \u00b6 def linear_recursion ( n : int ) -> int : # Base case if n <= 0 : return base_value # Single recursive call return recursive_step ( linear_recursion ( n - 1 )) # Example: Factorial def factorial ( n : int ) -> int : if n <= 1 : # Base case return 1 return n * factorial ( n - 1 ) # Recursive case 2. Binary Recursion Pattern \u00b6 def binary_recursion ( data ): # Base case if base_condition ( data ): return base_value # Two recursive calls left = binary_recursion ( left_portion ( data )) right = binary_recursion ( right_portion ( data )) return combine ( left , right ) # Example: Binary Tree Traversal def traverse ( root ): if not root : return traverse ( root . left ) traverse ( root . right ) 3. Tail Recursion Pattern \u00b6 def tail_recursion ( n , accumulator = initial_value ): # Base case if n <= 0 : return accumulator # Recursive call must be last operation return tail_recursion ( n - 1 , next_accumulator ) # Example: Tail Recursive Factorial def factorial_tail ( n : int , acc : int = 1 ) -> int : if n <= 1 : return acc return factorial_tail ( n - 1 , n * acc ) 4. Nested Recursion Pattern \u00b6 def nested_recursion ( n ): # Base case if n <= 0 : return base_value # Recursive call within recursive call return nested_recursion ( nested_recursion ( n - 1 )) \ud83d\udcdd Common Interview Problem Types \u00b6 1. Tree/Graph Problems \u00b6 def tree_traversal ( root ): # Base case if not root : return # Process current node process ( root ) # Recurse on children for child in root . children : tree_traversal ( child ) 2. String/Array Problems \u00b6 def is_palindrome ( s : str ) -> bool : # Base case: empty string or single char if len ( s ) <= 1 : return True # Check outermost chars and recurse on inner return s [ 0 ] == s [ - 1 ] and is_palindrome ( s [ 1 : - 1 ]) 3. Divide and Conquer Problems \u00b6 def quick_sort ( arr : list ) -> list : # Base case if len ( arr ) <= 1 : return arr pivot = arr [ len ( arr ) // 2 ] left = [ x for x in arr if x < pivot ] middle = [ x for x in arr if x == pivot ] right = [ x for x in arr if x > pivot ] # Recursive case return quick_sort ( left ) + middle + quick_sort ( right ) \u26a0\ufe0f Common Pitfalls & Solutions \u00b6 1. Stack Overflow \u00b6 from sys import setrecursionlimit def handle_deep_recursion ( n : int ): # Increase recursion limit if needed setrecursionlimit ( 10000 ) # Default is 1000 # Or better: Convert to iteration def iterative_version (): stack = [] while stack : # Process iteratively pass 2. Redundant Computations \u00b6 def fibonacci_with_memo ( n : int , memo : dict = None ) -> int : if memo is None : memo = {} # Check memo before computing if n in memo : return memo [ n ] # Base cases if n <= 1 : return n # Store result in memo memo [ n ] = fibonacci_with_memo ( n - 1 , memo ) + fibonacci_with_memo ( n - 2 , memo ) return memo [ n ] 3. Not Moving Towards Base Case \u00b6 def ensure_progress ( n : int ) -> int : # Bad: Might never reach base case if n != 0 : return ensure_progress ( n ) # Good: Always moves towards base case if n <= 0 : return 0 return ensure_progress ( n - 1 ) \ud83c\udfaf Time/Space Complexity Analysis \u00b6 Time Complexity Patterns \u00b6 complexities = { \"Linear Recursion\" : \"O(n) - Each call reduces n by 1\" , \"Binary Recursion\" : \"O(2^n) - Each call spawns 2 more calls\" , \"Divide & Conquer\" : \"O(n log n) - Divides problem in half each time\" , \"Tail Recursion\" : \"O(n) - Can be optimized by compiler\" , } Space Complexity Considerations \u00b6 space_usage = { \"Call Stack\" : \"Each recursive call adds a frame\" , \"Linear Recursion\" : \"O(n) stack space\" , \"Tail Recursion\" : \"O(1) with optimization\" , \"Tree Recursion\" : \"O(h) where h is tree height\" } \ud83d\udca1 Interview Tips \u00b6 Always start with: Base case identification How to move towards base case Whether recursion makes sense Consider converting to iteration if: Deep recursion possible Space complexity is crucial Performance is critical Optimize using: Memoization for overlapping subproblems Tail recursion when possible Helper functions for additional parameters Be prepared to explain: Why recursion is appropriate Space/time complexity How to handle edge cases Remember: Clarity over cleverness Consider both recursive and iterative solutions Watch for stack overflow in large inputs Test with small examples first \u267b\ufe0f Backtracking Guide \u00b6 \ud83d\udcda Core Properties \u00b6 1\ufe0f\u20e3 Property 1: No Repetition and Completion \u00b6 \"\"\" Backtracking is a systematic method that: 1. Avoids repetitions 2. Doesn't miss any possible solutions 3. Builds solutions incrementally 4. Returns to previous states (\"backtracks\") Ideal for: - Combinatorial problems (permutations, combinations) - Enumeration problems - Path finding in graphs \"\"\" 2\ufe0f\u20e3 Property 2: Search Pruning \u00b6 \"\"\" During solution building: 1. Evaluates partial solutions 2. Prunes branches that can't lead to valid solutions 3. Skips invalid configurations 4. Abandons paths worse than known solutions Ideal for: - Constraint satisfaction problems (CSP) - Optimization problems - Game-playing scenarios \"\"\" \ud83c\udfaf Implementation Patterns \u00b6 1. Two-Pass Pattern \u00b6 def backtrack_pattern ( input_data ): def dfs ( curr_state ): # Forward Pass: Build solution incrementally for choice in get_valid_choices ( curr_state ): # 1. Make choice apply_choice ( curr_state , choice ) # 2. Recurse dfs ( curr_state ) # Backward Pass: Reset state undo_choice ( curr_state , choice ) initial_state = create_initial_state () dfs ( initial_state ) Best Used When: \u00b6 State Modification Required # Example: N-Queens Problem def solve_n_queens ( n ): def dfs ( board , row ): # Forward: Place queen board [ row ][ col ] = 'Q' solve_further ( board , row + 1 ) # Backward: Remove queen board [ row ][ col ] = '.' Grid/Matrix Problems # Example: Maze Solving def solve_maze ( maze ): def dfs ( x , y ): # Forward: Mark path maze [ x ][ y ] = 'PATH' explore_neighbors ( x , y ) # Backward: Unmark if dead end maze [ x ][ y ] = 'EMPTY' Graph Problems with State Changes # Example: Graph Coloring def color_graph ( graph ): def dfs ( node , colors ): # Forward: Color node node . color = next_color color_neighbors ( node ) # Backward: Reset if invalid node . color = None Characteristics: \u00b6 Need to maintain and restore state Solutions built by modifying shared state Requires explicit cleanup Common in problems with global constraints 2. State Tracking Pattern \u00b6 def state_tracking_pattern (): used = set () # or list/array for tracking used elements curr = [] # current partial solution def dfs ( state ): if is_complete ( state ): record_solution ( curr [:]) return for choice in get_choices ( state ): if choice not in used : # Forward pass used . add ( choice ) curr . append ( choice ) dfs ( next_state ( state , choice )) # Backward pass used . remove ( choice ) curr . pop () Best Used When: \u00b6 Building Combinations/Permutations # Example: Generate Subsets def subsets ( nums ): result = [] curr = [] def dfs ( start ): result . append ( curr [:]) for i in range ( start , len ( nums )): curr . append ( nums [ i ]) dfs ( i + 1 ) curr . pop () Building Sequences # Example: Phone Number Letter Combinations def letter_combinations ( digits ): curr = [] def dfs ( index ): if len ( curr ) == len ( digits ): result . append ( '' . join ( curr )) return for letter in mapping [ digits [ index ]]: curr . append ( letter ) dfs ( index + 1 ) curr . pop () Path Finding Without State Modification # Example: All Paths from Source to Target def all_paths ( graph ): curr_path = [] def dfs ( node ): curr_path . append ( node ) dfs ( next_node ) curr_path . pop () Characteristics: \u00b6 Solutions built by tracking sequences No need for explicit state restoration Usually involves collecting multiple solutions Common in combinatorial problems \ud83c\udfaf Decision Making Guide \u00b6 Use Two-Pass Pattern When: \u00b6 Working with: Board games (Chess, N-Queens) Maze problems Grid-based problems Graph coloring State modification required Need to: Modify and restore shared state Handle complex constraints Work with matrix/grid structures Deal with global state Use State Tracking Pattern When: \u00b6 Working with: Combinations/Permutations String building problems Subset generation Path finding without modification Sequence generation Need to: Build multiple solutions Generate all possible arrangements Work with independent states Create combinations or selections \ud83c\udfae Hybrid Approach Examples \u00b6 Sometimes you might need to combine both patterns: def hybrid_backtracking (): curr_path = [] # State Tracking board = [[ 0 ] * N for _ in range ( N )] # Two-Pass State def dfs ( row , col ): # State Tracking: Build path curr_path . append (( row , col )) # Two-Pass: Modify board board [ row ][ col ] = 'VISITED' # Recurse explore_neighbors ( row , col ) # Two-Pass: Restore board board [ row ][ col ] = 'EMPTY' # State Tracking: Remove from path curr_path . pop () When to Use Hybrid: \u00b6 Complex game scenarios Path finding with state constraints Problems requiring both solution building and state modification Problems with both global and local constraints Remember: Consider state management needs Think about solution collection requirements Evaluate constraint checking needs Consider readability and maintainability \ud83c\udfae Common Problem Types \u00b6 1. Permutation Problems \u00b6 def permute ( nums : List [ int ]) -> List [ List [ int ]]: def backtrack ( curr : List [ int ], used : Set [ int ]): # Base case: complete permutation if len ( curr ) == len ( nums ): result . append ( curr [:]) return # Try each unused number for i in range ( len ( nums )): # Skip used numbers if i in used : continue # Forward pass used . add ( i ) curr . append ( nums [ i ]) backtrack ( curr , used ) # Backward pass used . remove ( i ) curr . pop () result = [] backtrack ([], set ()) return result 2. Unique Permutations (With Duplicates) \u00b6 def permuteUnique ( nums : List [ int ]) -> List [ List [ int ]]: def backtrack ( curr : List [ int ], counter : Dict [ int , int ]): if len ( curr ) == len ( nums ): result . append ( curr [:]) return # Use counter to handle duplicates for num in counter : if counter [ num ] > 0 : curr . append ( num ) counter [ num ] -= 1 backtrack ( curr , counter ) curr . pop () counter [ num ] += 1 result = [] counter = Counter ( nums ) backtrack ([], counter ) return result 3. Constraint Satisfaction Problems \u00b6 def solve_csp ( constraints ): def is_valid_state ( state ): return all ( constraint ( state ) for constraint in constraints ) def backtrack ( state ): if is_complete ( state ): return is_valid_state ( state ) for value in get_possible_values ( state ): if is_valid_partial ( state , value ): apply_value ( state , value ) if backtrack ( state ): return True undo_value ( state , value ) return False \ud83c\udfaf Time Complexity Analysis \u00b6 complexity_notes = { \"Permutations\" : { \"Time\" : \"O(n!)\" , \"Space\" : \"O(n) for recursion stack\" , \"Note\" : \"Visits each state exactly once\" }, \"Combinations\" : { \"Time\" : \"O(2^n)\" , \"Space\" : \"O(n) for recursion stack\" , \"Note\" : \"Each element has two choices\" }, \"CSP Problems\" : { \"Time\" : \"O(d^n) where d is domain size\" , \"Space\" : \"O(n) for recursion stack\" , \"Note\" : \"Pruning can significantly improve average case\" } } \ud83d\udca1 Optimization Techniques \u00b6 1. Early Pruning \u00b6 def optimized_backtrack ( state ): # Check constraints early if not is_valid_partial ( state ): return False if is_complete ( state ): return True for choice in sorted_choices ( state ): # Sort choices for better pruning if is_promising ( state , choice ): apply_choice ( state , choice ) if optimized_backtrack ( state ): return True undo_choice ( state , choice ) 2. State Duplication \u00b6 def backtrack_with_dedup ( nums : List [ int ]) -> List [ List [ int ]]: def backtrack ( start : int , curr : List [ int ]): result . append ( curr [:]) used = set () # Track used numbers at this level for i in range ( start , len ( nums )): if nums [ i ] in used : # Skip duplicates at same level continue used . add ( nums [ i ]) curr . append ( nums [ i ]) backtrack ( i + 1 , curr ) curr . pop () \ud83d\udca1 Interview Tips \u00b6 Implementation Strategy: Always use DFS for backtracking Identify state representation clearly Track partial solutions carefully Optimization Strategy: Look for early pruning opportunities Consider sorting input for better pruning Use sets/counters for duplicate handling Problem Solving Steps: Identify what makes a valid solution Determine how to build solutions incrementally Define clear base cases Plan state tracking strategy Testing Strategy: Start with small inputs Test with duplicates if relevant Verify all solutions are found Check for invalid inputs Remember: Backtracking = Choices + Consequences Think in terms of state and state changes Always handle cleanup in backward pass Consider space complexity of solution storage \ud83c\udf33 Binary Trees Guide \u00b6 \ud83d\udcda Core Implementation \u00b6 Basic Tree Node \u00b6 class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right Common Tree Building Patterns \u00b6 def build_tree_examples (): # Simple Tree root = TreeNode ( 1 ) root . left = TreeNode ( 2 ) root . right = TreeNode ( 3 ) # From List def from_list ( nums : List [ int ], index : int = 0 ) -> TreeNode : if index >= len ( nums ) or nums [ index ] is None : return None root = TreeNode ( nums [ index ]) root . left = from_list ( nums , 2 * index + 1 ) root . right = from_list ( nums , 2 * index + 2 ) return root \ud83c\udfaf Core Traversal Patterns \u00b6 1. DFS Patterns \u00b6 class DFSPatterns : def inorder ( self , root : TreeNode ) -> List [ int ]: # Left -> Root -> Right def dfs ( node ): if not node : return dfs ( node . left ) # Process left result . append ( node . val ) # Process root dfs ( node . right ) # Process right result = [] dfs ( root ) return result def preorder ( self , root : TreeNode ) -> List [ int ]: # Root -> Left -> Right def dfs ( node ): if not node : return result . append ( node . val ) # Process root dfs ( node . left ) # Process left dfs ( node . right ) # Process right result = [] dfs ( root ) return result def postorder ( self , root : TreeNode ) -> List [ int ]: # Left -> Right -> Root def dfs ( node ): if not node : return dfs ( node . left ) # Process left dfs ( node . right ) # Process right result . append ( node . val ) # Process root result = [] dfs ( root ) return result 2. BFS Pattern \u00b6 from collections import deque def level_order ( root : TreeNode ) -> List [ List [ int ]]: if not root : return [] result = [] queue = deque ([ root ]) while queue : level_size = len ( queue ) current_level = [] for _ in range ( level_size ): node = queue . popleft () current_level . append ( node . val ) if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) result . append ( current_level ) return result \ud83c\udfae Common Problem Patterns \u00b6 1. Path Problems Pattern \u00b6 def path_pattern ( root : TreeNode ): def dfs ( node , path , target ): if not node : return # Add current node to path path . append ( node . val ) # Check if leaf node if not node . left and not node . right : process_path ( path ) # Process complete path # Recurse on children dfs ( node . left , path , target ) dfs ( node . right , path , target ) # Backtrack path . pop () 2. Binary Search Tree Pattern \u00b6 def bst_pattern ( root : TreeNode ): def validate_bst ( node , min_val = float ( '-inf' ), max_val = float ( 'inf' )): if not node : return True # Check BST property if node . val <= min_val or node . val >= max_val : return False # Recurse with updated bounds return ( validate_bst ( node . left , min_val , node . val ) and validate_bst ( node . right , node . val , max_val )) 3. Lowest Common Ancestor \u00b6 def lca_pattern ( root : TreeNode , p : TreeNode , q : TreeNode ): def find_lca ( node ): if not node or node == p or node == q : return node # Search in left and right subtrees left = find_lca ( node . left ) right = find_lca ( node . right ) # If found in both subtrees, current node is LCA if left and right : return node # Return non-null node return left or right 4. View Problems Pattern \u00b6 def tree_view_pattern ( root : TreeNode ): def right_view ( root ): result = [] def dfs ( node , level ): if not node : return # First node of this level from right if len ( result ) == level : result . append ( node . val ) # Visit right first for right view dfs ( node . right , level + 1 ) dfs ( node . left , level + 1 ) dfs ( root , 0 ) return result \ud83c\udfaf Pattern Recognition Guide \u00b6 When to Use Each Pattern: \u00b6 Use DFS When: Need to process nodes in a specific order Working with paths from root to leaf Validating tree properties Computing tree properties recursively Use BFS When: Need level-by-level processing Finding shortest paths Working with tree width Level-based operations Use Path Patterns When: Need complete paths from root to leaf Summing paths Finding specific paths Path validation Use BST Patterns When: Searching for values Validating BST properties Range-based operations Maintaining sorted order \ud83d\udca1 Problem-Solving Strategy \u00b6 Identify Pattern Type: Is it path-based? Is it level-based? Does it involve BST properties? Is order important? Choose Traversal Method: patterns = { \"Need Path\" : \"DFS with path tracking\" , \"Level Operations\" : \"BFS with queue\" , \"Specific Order\" : \"Choose appropriate DFS order\" , \"BST Operations\" : \"Use BST properties\" } Consider Edge Cases edge_cases = [ \"Empty tree\" , \"Single node\" , \"All nodes same value\" , \"Unbalanced tree\" , \"Complete binary tree\" ] Time/Space Complexity complexities = { \"DFS\" : \"Time: O(n), Space: O(h)\" , \"BFS\" : \"Time: O(n), Space: O(w)\" , \"Path\" : \"Time: O(n), Space: O(h)\" , \"BST\" : \"Time: O(h), Space: O(1) typical\" } # where n = nodes, h = height, w = max width Remember: Start with traversal pattern identification Consider whether order matters Check if BST properties help Handle edge cases explicitly \ud83c\udf32 Tries (Prefix Trees) \u00b6 \ud83d\udcda Core Implementation \u00b6 Basic Trie Node \u00b6 class TrieNode : def __init__ ( self ): self . children = {} # or [None] * 26 for fixed alphabet self . is_end = False # Marks end of word Basic Trie Structure \u00b6 class Trie : def __init__ ( self ): self . root = TrieNode () def insert ( self , word : str ) -> None : node = self . root for char in word : if char not in node . children : node . children [ char ] = TrieNode () node = node . children [ char ] node . is_end = True def search ( self , word : str ) -> bool : node = self . root for char in word : if char not in node . children : return False node = node . children [ char ] return node . is_end def starts_with ( self , prefix : str ) -> bool : node = self . root for char in prefix : if char not in node . children : return False node = node . children [ char ] return True \ud83c\udfaf Common Patterns \u00b6 1. Word Dictionary Pattern \u00b6 class WordDictionary : def __init__ ( self ): self . root = TrieNode () def insert ( self , word : str ) -> None : node = self . root for char in word : if char not in node . children : node . children [ char ] = TrieNode () node = node . children [ char ] node . is_end = True def search_with_wildcard ( self , word : str ) -> bool : def dfs ( node , i ): if i == len ( word ): return node . is_end if word [ i ] == '.' : for child in node . children . values (): if child and dfs ( child , i + 1 ): return True return False if word [ i ] not in node . children : return False return dfs ( node . children [ word [ i ]], i + 1 ) return dfs ( self . root , 0 ) 2. Prefix Matching Pattern \u00b6 def prefix_matching_pattern (): class AutocompleteSystem : def __init__ ( self , words : List [ str ], times : List [ int ]): self . root = TrieNode () self . prefix = \"\" # Insert words with frequencies for word , count in zip ( words , times ): self . _insert ( word , count ) def _insert ( self , word : str , count : int ) -> None : node = self . root for char in word : if char not in node . children : node . children [ char ] = TrieNode () node = node . children [ char ] node . counts [ word ] = count def input ( self , c : str ) -> List [ str ]: if c == '#' : self . _insert ( self . prefix , 1 ) self . prefix = \"\" return [] self . prefix += c node = self . root # Find node for current prefix for char in self . prefix : if char not in node . children : return [] node = node . children [ char ] # Get top 3 suggestions return sorted ( node . counts . items (), key = lambda x : ( - x [ 1 ], x [ 0 ]))[: 3 ] 3. Word Square Pattern \u00b6 def word_square_pattern ( words : List [ str ]) -> List [ List [ str ]]: trie = Trie () n = len ( words [ 0 ]) # Build prefix map prefix_map = defaultdict ( list ) for i , word in enumerate ( words ): for j in range ( len ( word ) + 1 ): prefix_map [ word [: j ]] . append ( i ) def get_words_with_prefix ( prefix ): return [ words [ i ] for i in prefix_map [ prefix ]] def backtrack ( square ): if len ( square ) == n : result . append ( square [:]) return # Get prefix for next word pos = len ( square ) prefix = '' . join ( word [ pos ] for word in square ) # Try all words with this prefix for word in get_words_with_prefix ( prefix ): square . append ( word ) backtrack ( square ) square . pop () result = [] backtrack ([]) return result \ud83c\udfaf Time/Space Complexity \u00b6 complexities = { \"Insert\" : { \"Time\" : \"O(m) where m is word length\" , \"Space\" : \"O(m)\" }, \"Search\" : { \"Time\" : \"O(m)\" , \"Space\" : \"O(1)\" }, \"StartsWith\" : { \"Time\" : \"O(m)\" , \"Space\" : \"O(1)\" }, \"Space Usage\" : \"O(ALPHABET_SIZE * m * n) for n words\" } \ud83d\udd11 Key Advantages/Disadvantages \u00b6 Advantages: \u00b6 advantages = [ \"Fast prefix lookups O(m)\" , \"Space-efficient for common prefixes\" , \"No need for hash function\" , \"No collisions to handle\" , \"Natural for autocomplete/spellcheck\" ] Disadvantages \u00b6 disadvantages = [ \"Memory intensive (many null pointers)\" , \"Slower than hash table for exact lookups\" , \"Complex to implement/maintain\" , \"Not cache-friendly due to pointer chasing\" ] \ud83d\udca1 When to Use Tries \u00b6 use_cases = { \"Autocomplete\" : \"Search suggestions\" , \"Spell Checker\" : \"Word validation\" , \"IP Routing\" : \"Prefix matching\" , \"Word Games\" : \"Word validation/search\" , \"Contact List\" : \"Type-ahead search\" } \u26a0\ufe0f Common Pitfalls \u00b6 Memory Management def avoid_memory_issues (): \"\"\" - Consider using array instead of map for fixed alphabet - Clean up unused nodes - Use compressed tries for long strings \"\"\" pass Implementation Choices def implementation_tips (): \"\"\" - Choose appropriate children structure (array vs map based on alphabet size) - Decide on case sensitivity handling - Plan wildcard character handling \"\"\" pass \ud83c\udfaf Practice Problem Types \u00b6 Basic Operations Implement insert/search/startsWith Handle wildcards Case-sensitive operations Word Problems Word search Word squares Word break Replace words Prefix Problems Autocomplete Longest common prefix Unique prefixes Remember: Consider memory-space tradeoffs Handle edge cases (empty strings, special chars) Think about prefix sharing opportunities Consider case sensitivity requirements \ud83d\udd0d Binary Search Guide \u00b6 \ud83d\udcda Core Template \u00b6 Most Generalized Binary Search Template \u00b6 def binary_search ( array ) -> int : def condition ( value ) -> bool : # Customize condition here pass left , right = min ( search_space ), max ( search_space ) while left < right : mid = left + ( right - left ) // 2 if condition ( mid ): right = mid else : left = mid + 1 return left # Key Points: # 1. Initialize boundaries to include ALL possible answers # 2. Condition function defines search criteria # 3. Returns minimum k where condition(k) is True \ud83c\udfaf Three Key Components \u00b6 1. Boundary Initialization \u00b6 def initialize_boundaries (): \"\"\" Rules for setting left and right: 1. Must include all possible answers 2. Common patterns: - [0, len(array)] # For index search - [min(array), max(array)] # For value search - [1, max_possible] # For minimum/maximum problems \"\"\" # Example bounds for different scenarios bounds = { \"Index Search\" : ( 0 , len ( array )), \"Value Search\" : ( min ( array ), max ( array )), \"Minimum Search\" : ( 1 , max_value ), \"Maximum Search\" : ( min_value , sum ( array )) } 2. Condition Function Design \u00b6 def design_condition (): \"\"\" Patterns for condition functions: 1. Direct Comparison: array[mid] >= target 2. Feasibility Check: can_achieve(mid) 3. Counting: count_less_equal(mid) >= k 4. Validation: is_valid_solution(mid) \"\"\" # Example condition patterns conditions = { \"Finding Target\" : lambda mid : array [ mid ] >= target , \"Feasibility\" : lambda mid : can_do_task_with_value ( mid ), \"Counting\" : lambda mid : count_elements_less_than ( mid ) >= k , \"Validation\" : lambda mid : validates_constraint ( mid ) } 3. Return Value Selection \u00b6 def choose_return (): \"\"\" Return value patterns: 1. left: Minimum value satisfying condition 2. left - 1: Maximum value not satisfying condition 3. right: Alternative minimum value 4. Special handling for not found cases \"\"\" return_patterns = { \"Minimum Satisfying\" : \"return left\" , \"Maximum Not Satisfying\" : \"return left - 1\" , \"Not Found\" : \"return -1 if not found\" } \ud83c\udfae Common Problem Patterns \u00b6 1. Classical Binary Search \u00b6 def classical_search ( nums : List [ int ], target : int ) -> int : left , right = 0 , len ( nums ) while left < right : mid = left + ( right - left ) // 2 if nums [ mid ] >= target : right = mid else : left = mid + 1 return left if left < len ( nums ) and nums [ left ] == target else - 1 2. Minimum Value Search \u00b6 def find_minimum ( nums : List [ int ]) -> int : def feasible ( value ) -> bool : # Define feasibility condition total = 0 for num in nums : if condition ( num , value ): total += 1 return total >= required left , right = min_possible , max_possible while left < right : mid = left + ( right - left ) // 2 if feasible ( mid ): right = mid else : left = mid + 1 return left 3. Maximum Value Search \u00b6 def find_maximum ( nums : List [ int ]) -> int : def feasible ( value ) -> bool : # Define feasibility condition return can_achieve_with_value ( value ) left , right = min_possible , max_possible while left < right : mid = left + ( right - left + 1 ) // 2 # Note: Different mid calculation if feasible ( mid ): left = mid else : right = mid - 1 return left \ud83c\udfaf Pattern Recognition Guide \u00b6 When to Use Binary Search: \u00b6 binary_search_indicators = { \"Sorted Array\" : \"Direct binary search possible\" , \"Monotonic Condition\" : \"Can use binary search on answer space\" , \"Min/Max Optimization\" : \"Likely binary search on result\" , \"Feasibility Check\" : \"Can binary search with validation\" , \"Counting Problems\" : \"Binary search possible if monotonic\" } Problem Type Recognition \u00b6 def identify_pattern ( problem ): patterns = { \"Find Exact Value\" : \"Classical binary search\" , \"Find Minimum Satisfying\" : \"Minimum value pattern\" , \"Find Maximum Possible\" : \"Maximum value pattern\" , \"Optimization with Constraint\" : \"Feasibility pattern\" , \"Counting with Condition\" : \"Counting pattern\" } \u26a0\ufe0f Common Pitfalls \u00b6 Boundary Issues def avoid_boundary_issues (): \"\"\" Common pitfalls: 1. Off-by-one errors in boundaries 2. Not including all possible answers 3. Infinite loops due to improper mid calculation 4. Not handling edge cases \"\"\" pass Condition Design def condition_pitfalls (): \"\"\" Watch out for: 1. Non-monotonic conditions 2. Incorrect comparison operators 3. Missing edge cases in condition 4. Overcomplicated condition logic \"\"\" pass \ud83d\udca1 Implementation Tips \u00b6 Always use left + (right - left) // 2 to avoid overflow Consider whether to include end points Test with small examples first Verify monotonicity of condition Handle edge cases explicitly Remember: Think in terms of answer space vs index space Verify condition function monotonicity Consider boundary cases carefully Test with small inputs first \ud83e\ude99 Greedy Algorithms \u00b6 \ud83d\udcda Core Properties \u00b6 What is a Greedy Algorithm? \u00b6 A greedy algorithm makes the locally optimal choice at each step, hoping to find a global optimum. While simple and intuitive, they don't always yield the optimal solution but often provide efficient solutions for optimization problems. Key Properties \u00b6 properties = { \"Local Optimal Choice\" : \"Best choice at current step\" , \"Hope\" : \"Local optimum leads to global optimum\" , \"No Backtracking\" : \"Decisions are final\" , \"Simple Implementation\" : \"Usually straightforward code\" } \ud83c\udfaf When to Use Greedy Algorithms \u00b6 Criteria for Greedy Approach \u00b6 def is_greedy_applicable ( problem ): criteria = { \"Greedy Choice Property\" : \"\"\"Local optimal choices lead to global optimal solution\"\"\" , \"Optimal Substructure\" : \"\"\"Optimal solution contains optimal solutions to subproblems\"\"\" , \"No Future Impact\" : \"Current choice doesn't affect future choices\" , \"Simple Constraints\" : \"Problem has straightforward constraints\" } return all ( criteria . values ()) \ud83c\udfae Common Greedy Patterns \u00b6 1. Activity Selection Pattern \u00b6 def activity_selection ( start : List [ int ], finish : List [ int ]) -> List [ int ]: # Sort activities by finish time activities = sorted ( zip ( start , finish ), key = lambda x : x [ 1 ]) selected = [ activities [ 0 ]] last_finish = activities [ 0 ][ 1 ] for start_time , finish_time in activities [ 1 :]: if start_time >= last_finish : selected . append (( start_time , finish_time )) last_finish = finish_time return selected 2. Fractional Knapsack Problem \u00b6 def fractional_knapsack ( values : List [ int ], weights : List [ int ], capacity : int ) -> float : # Calculate value/weight ratio items = sorted ( zip ( values , weights ), key = lambda x : x [ 0 ] / x [ 1 ], reverse = True ) total_value = 0 for value , weight in items : if capacity >= weight : # Take whole item capacity -= weight total_value += value else : # Take fraction of item total_value += value * ( capacity / weight ) break return total_value 3. Meeting Rooms Pattern \u00b6 def min_meeting_rooms ( intervals : List [ List [ int ]]) -> int : if not intervals : return 0 # Separate start and end times starts = sorted ([ i [ 0 ] for i in intervals ]) ends = sorted ([ i [ 1 ] for i in intervals ]) rooms = 0 max_rooms = 0 s = e = 0 while s < len ( intervals ): if starts [ s ] < ends [ e ]: rooms += 1 s += 1 else : rooms -= 1 e += 1 max_rooms = max ( max_rooms , rooms ) return max_rooms 4. Coin Change (Greedy Pattern) \u00b6 def coin_change_greedy ( amount : int , coins : List [ int ]) -> int : coins . sort ( reverse = True ) # Sort coins in descending order count = 0 for coin in coins : while amount >= coin : amount -= coin count += 1 return count if amount == 0 else - 1 \ud83d\udd04 Universal Greedy Patterns \u00b6 1. Sorting-First Pattern \u00b6 def sorting_first_pattern ( items , key_function = None ): \"\"\" Universal pattern for problems requiring initial sorting. Common in: Activity selection, Job scheduling, Meeting rooms \"\"\" # 1. Sort based on key metric sorted_items = sorted ( items , key = key_function ) if key_function else sorted ( items ) result = [] current = sorted_items [ 0 ] # Track current selection # 2. Process items in sorted order for item in sorted_items [ 1 :]: if satisfies_constraint ( current , item ): # 3. Make greedy choice result . append ( current ) current = item result . append ( current ) # Don't forget last item return result # Example Usage: Activity Selection def activity_selection ( activities ): return sorting_first_pattern ( activities , key_function = lambda x : x [ 1 ] # Sort by finish time ) # Example Usage: Meeting Rooms def meeting_rooms ( meetings ): return sorting_first_pattern ( meetings , key_function = lambda x : x [ 0 ] # Sort by start time ) 2. Fraction Rate/Pattern \u00b6 def fraction_pattern ( items , constraint , get_value , get_weight ): \"\"\" Universal pattern for fractional optimization problems. Common in: Knapsack, Task scheduling with efficiency \"\"\" # 1. Calculate rates and sort rates = [( get_value ( item ) / get_weight ( item ), item ) for item in items ] rates . sort ( reverse = True ) result = [] total_value = 0 remaining = constraint # 2. Process items by rate for rate , item in rates : weight = get_weight ( item ) if remaining >= weight : # Take whole item result . append (( item , 1.0 )) total_value += get_value ( item ) remaining -= weight else : # Take fraction fraction = remaining / weight result . append (( item , fraction )) total_value += get_value ( item ) * fraction break return result , total_value # Example Usage: Fractional Knapsack def fractional_knapsack ( items , capacity ): return fraction_pattern ( items , capacity , get_value = lambda x : x . value , get_weight = lambda x : x . weight ) 3. Running Window Pattern \u00b6 def running_window_pattern ( items , constraint ): \"\"\" Universal pattern for running window problems. Common in: Meeting rooms, Task scheduling, Resource allocation \"\"\" # 1. Separate start and end events events = [] for start , end in items : events . append (( start , 1 )) # 1 for start events . append (( end , - 1 )) # -1 for end # 2. Sort events events . sort () current = 0 max_needed = 0 # 3. Process events in order for time , change in events : current += change max_needed = max ( max_needed , current ) if max_needed > constraint : return False return True # Example Usage: Meeting Rooms def can_schedule_meetings ( meetings , available_rooms ): return running_window_pattern ( meetings , available_rooms ) 4. Local Exchange Pattern \u00b6 def local_exchange_pattern ( items ): \"\"\" Universal pattern for local optimization problems. Common in: Job scheduling, Task optimization \"\"\" result = list ( items ) # Create mutable copy made_change = True while made_change : made_change = False for i in range ( len ( result ) - 1 ): # Compare adjacent items if better_exchange ( result [ i ], result [ i + 1 ]): result [ i ], result [ i + 1 ] = result [ i + 1 ], result [ i ] made_change = True return result # Example Usage: Job Sequencing def job_sequencing ( jobs ): def better_exchange ( job1 , job2 ): return ( job1 . profit / job1 . deadline < job2 . profit / job2 . deadline ) return local_exchange_pattern ( jobs ) 5. Priority Queue Pattern \u00b6 from heapq import heappush , heappop def priority_queue_pattern ( items , k ): \"\"\" Universal pattern for k-selection problems. Common in: K closest points, Top K frequent elements \"\"\" heap = [] for item in items : # Maintain heap of size k if len ( heap ) < k : heappush ( heap , item ) else : if better_than_top ( item , heap [ 0 ]): heappop ( heap ) heappush ( heap , item ) return sorted ( heap ) # Return sorted result # Example Usage: K Closest Points def k_closest_points ( points , k ): return priority_queue_pattern ( points , k = k ) Pattern Selection Guide \u00b6 pattern_guide = { \"Sorting-First\" : { \"Use When\" : [ \"Items need to be processed in specific order\" , \"Selection based on sorted property\" , \"No overlapping allowed\" ], \"Examples\" : [ \"Activity selection\" , \"Meeting rooms\" , \"Task scheduling\" ] }, \"Fraction/Rate\" : { \"Use When\" : [ \"Divisible items\" , \"Optimization based on rates\" , \"Knapsack-like problems\" ], \"Examples\" : [ \"Fractional knapsack\" , \"Resource allocation\" , \"Time management\" ] }, \"Running Window\" : { \"Use When\" : [ \"Time/Space intervals\" , \"Resource constraints\" , \"Overlapping intervals\" ], \"Examples\" : [ \"Meeting rooms\" , \"CPU scheduling\" , \"Resource booking\" ] }, \"Local Exchange\" : { \"Use When\" : [ \"Local optimization possible\" , \"Pairwise comparisons sufficient\" , \"Order matters\" ], \"Examples\" : [ \"Job sequencing\" , \"Task ordering\" , \"Optimization problems\" ] }, \"Priority Queue\" : { \"Use When\" : [ \"K-selection problems\" , \"Running minimum/maximum\" , \"Stream processing\" ], \"Examples\" : [ \"K closest points\" , \"Top K elements\" , \"Running median\" ] } } \ud83c\udfaf Problem-Solving Framework \u00b6 1. Verify Greedy Approach \u00b6 def verify_greedy_approach (): checks = { \"Local Choice\" : \"Can we make locally optimal choice?\" , \"Subproblem\" : \"Does it lead to simpler subproblem?\" , \"Optimality\" : \"Do local choices lead to global optimum?\" , \"Constraints\" : \"Are constraints simple and local?\" } 2. Design Steps \u00b6 Sort if Needed Often first step is sorting by key metric Examples: finish time, value/weight ratio Define Greedy Choice What makes a choice locally optimal? How to select next element? Implement Selection Process Process elements in sorted order Apply greedy choice at each step Track Progress/Result Maintain running solution Update constraints \u26a0\ufe0f Common Pitfalls \u00b6 1. Verification Issues \u00b6 pitfalls = { \"Optimality\" : \"Not verifying if greedy leads to optimal\" , \"Constraints\" : \"Missing important constraints\" , \"Sorting\" : \"Wrong sorting criteria\" , \"Edge Cases\" : \"Not handling edge cases\" } 2. Implementation Issues \u00b6 implementation_issues = { \"Initialization\" : \"Incorrect initial values\" , \"Updates\" : \"Wrong progress tracking\" , \"Termination\" : \"Incorrect stopping condition\" , \"Optimization\" : \"Missing optimization opportunities\" } \ud83d\udcdd Common Interview Problems \u00b6 1. Scheduling Problems \u00b6 Activity Selection Meeting Rooms Task Scheduling 2. Optimization Problems \u00b6 Fractional Knapsack Minimum Coins Huffman Coding 3. Connection Problems \u00b6 Minimum Spanning Tree Job Sequencing Shortest Path (Dijkstra's) \ud83d\udca1 Interview Tips \u00b6 Approach Start with greedy hypothesis Prove/disprove with examples Consider sorting first Track progress clearly Verification Use small examples Find counter-examples Explain why greedy works Implementation Keep code clean and simple Handle edge cases Consider optimization Test with various inputs \ud83c\udfaf Time Complexity Analysis \u00b6 complexities = { \"Sorting Based\" : \"O(n log n) typical\" , \"Linear Scan\" : \"O(n) without sorting\" , \"Priority Queue\" : \"O(n log k) for k elements\" , \"Space\" : \"Usually O(1) or O(n)\" } Remember: Greedy algorithms are simple but not always optimal Verify greedy choice property Consider sorting as first step Handle edge cases carefully \ud83c\udfaf Dynamic Programming - From Fundamentals to Mastery \u00b6 \ud83d\udcda Introduction to Dynamic Programming \u00b6 What is Dynamic Programming? \u00b6 Dynamic Programming (DP) is both a mathematical optimization method and a programming method that: Breaks down complex problems into simpler subproblems Stores solutions to these subproblems to avoid recalculating them Uses stored solutions to build up to the final solution Think of it as \"careful brute force\" - instead of recalculating values we've seen before, we save them for later use. When to Use Dynamic Programming \u00b6 criteria_for_dp = { \"1. Optimal Substructure\" : \"\"\" Can the problem be broken down into smaller problems? Example: Fibonacci numbers - F(n) depends on F(n-1) and F(n-2) \"\"\" , \"2. Overlapping Subproblems\" : \"\"\" Do we calculate the same things repeatedly? Example: In Fibonacci, F(5) and F(4) both need F(3) \"\"\" , \"3. No Greedy Choice\" : \"\"\" Does making the locally optimal choice not always lead to global optimal? Example: Coin change problem with coins [1, 15, 25] \"\"\" } \ud83c\udfaf Core Concepts Explained \u00b6 1. Subproblems and Optimal Substructure \u00b6 def understand_subproblems (): \"\"\" Example: Finding F(4) in Fibonacci sequence F(4) = F(3) + F(2) # Main problem F(3) = F(2) + F(1) # Subproblem F(2) = F(1) + F(0) # Smaller subproblem Properties: 1. Each subproblem is smaller version of main problem 2. Solution to main problem depends on subproblems 3. Base cases stop the recursion \"\"\" pass 2. Overlapping Subproblems \u00b6 def show_overlapping_example ( n : int ): \"\"\" Without DP (lots of repeated calculations): F(5) \u251c\u2500\u2500 F(4) \u2502 \u251c\u2500\u2500 F(3) \u2502 \u2502 \u251c\u2500\u2500 F(2) # Calculated multiple times \u2502 \u2502 \u2514\u2500\u2500 F(1) \u2502 \u2514\u2500\u2500 F(2) # Calculated again \u2514\u2500\u2500 F(3) \u251c\u2500\u2500 F(2) # Calculated yet again \u2514\u2500\u2500 F(1) With DP (calculate once, reuse result): memo = { 0: 0, 1: 1, 2: F(2), # Calculate once, reuse many times 3: F(3), ... } \"\"\" pass \ud83c\udfae Two Main Approaches to DP \u00b6 1. Top-Down (Memoization) \u00b6 def explain_memoization (): \"\"\" Top-Down Process: 1. Start with original problem (top) 2. Break into subproblems recursively 3. Store results in memo table 4. Return memoized results if subproblem seen before Advantages: - More intuitive (follows natural thinking) - Only solves needed subproblems - Easier to debug Disadvantages: - Recursion overhead - Stack space usage \"\"\" # Example implementation def fib_memo ( n : int , memo : dict = None ) -> int : if memo is None : memo = {} # Base cases if n <= 1 : return n # Check memo before computing if n in memo : return memo [ n ] # Store result in memo memo [ n ] = fib_memo ( n - 1 , memo ) + fib_memo ( n - 2 , memo ) return memo [ n ] 2. Bottom-Up (Tabulation) \u00b6 def explain_tabulation (): \"\"\" Bottom-Up Process: 1. Start with base cases (bottom) 2. Build larger solutions from smaller ones 3. Store results in table 4. Use table to build final solution Advantages: - More space efficient - No recursion overhead - Better cache performance Disadvantages: - May solve unnecessary subproblems - Sometimes less intuitive \"\"\" # Example implementation def fib_table ( n : int ) -> int : if n <= 1 : return n # Initialize table with base cases dp = [ 0 ] * ( n + 1 ) dp [ 1 ] = 1 # Build up the solution for i in range ( 2 , n + 1 ): dp [ i ] = dp [ i - 1 ] + dp [ i - 2 ] return dp [ n ] \ud83c\udfaf Problem-Solving Framework \u00b6 Step 1: Identify DP Characteristics \u00b6 def identify_dp_potential ( problem ): \"\"\" Ask these questions: 1. Can I break this into smaller similar subproblems? 2. Does solving subproblems help solve the original problem? 3. Am I calculating same things repeatedly? 4. Can I store and reuse these calculations? \"\"\" checklist = { \"Optimal Substructure\" : False , \"Overlapping Subproblems\" : False , \"Need for Optimization\" : False } return all ( checklist . values ()) Step 2: Define the Subproblem \u00b6 def define_subproblem (): \"\"\" 1. State Definition: - What variables define a subproblem? - What information needed to solve it? 2. State Transition: - How do I move from one state to another? - What choices do I have at each state? Example (Knapsack): - State: dp[i][w] = max value using items[0..i] with weight limit w - Transition: Choose whether to include item i or not \"\"\" pass Step 3: Write the Recurrence Relation \u00b6 def create_recurrence (): \"\"\" 1. Base Cases: - Smallest possible subproblem - Starting point for computation 2. Recurrence Formula: - How larger problems relate to smaller ones - Mathematical relationship between states Example (Knapsack): dp[i][w] = max( dp[i-1][w], # Don't take item dp[i-1][w-weight[i]] + val[i] # Take item ) \"\"\" pass Step 4: Implement Solution \u00b6 def implement_solution (): \"\"\" Choose Implementation Style: 1. Top-Down if: - Natural recursive solution - Not all subproblems needed - Need to debug/understand easily 2. Bottom-Up if: - Need to optimize space - All subproblems needed - Want to avoid recursion \"\"\" pass \ud83c\udfaf Common DP Patterns \u00b6 1. Linear Sequence \u00b6 Used when each state depends on previous states. def linear_dp_example (): # Example: House Robber Problem def rob ( nums : List [ int ]) -> int : if not nums : return 0 if len ( nums ) == 1 : return nums [ 0 ] dp = [ 0 ] * len ( nums ) dp [ 0 ] = nums [ 0 ] dp [ 1 ] = max ( nums [ 0 ], nums [ 1 ]) for i in range ( 2 , len ( nums )): dp [ i ] = max ( dp [ i - 1 ], dp [ i - 2 ] + nums [ i ]) return dp [ - 1 ] 2. Matrix Chain \u00b6 Used for optimization problems involving sequences. def matrix_chain_example (): # Example: Matrix Chain Multiplication def matrix_mult_cost ( dimensions : List [ int ]) -> int : n = len ( dimensions ) - 1 dp = [[ 0 ] * n for _ in range ( n )] for length in range ( 2 , n + 1 ): for i in range ( n - length + 1 ): j = i + length - 1 dp [ i ][ j ] = float ( 'inf' ) for k in range ( i , j ): cost = ( dp [ i ][ k ] + dp [ k + 1 ][ j ] + dimensions [ i ] * dimensions [ k + 1 ] * dimensions [ j + 1 ]) dp [ i ][ j ] = min ( dp [ i ][ j ], cost ) return dp [ 0 ][ n - 1 ] 3. Interval Problems \u00b6 Used when dealing with ranges or intervals. def interval_dp_example (): # Example: Palindrome Partitioning def min_cuts ( s : str ) -> int : n = len ( s ) # is_palindrome[i][j] tells if s[i:j+1] is palindrome is_palindrome = [[ False ] * n for _ in range ( n )] # Single letters are palindromes for i in range ( n ): is_palindrome [ i ][ i ] = True # Check for palindromes of length 2 and more for length in range ( 2 , n + 1 ): for start in range ( n - length + 1 ): end = start + length - 1 if length == 2 : is_palindrome [ start ][ end ] = ( s [ start ] == s [ end ]) else : is_palindrome [ start ][ end ] = ( s [ start ] == s [ end ] and is_palindrome [ start + 1 ][ end - 1 ] ) # dp[i] = minimum cuts needed for s[0:i+1] dp = [ 0 ] * n for i in range ( n ): if is_palindrome [ 0 ][ i ]: dp [ i ] = 0 else : dp [ i ] = i for j in range ( i ): if is_palindrome [ j + 1 ][ i ]: dp [ i ] = min ( dp [ i ], dp [ j ] + 1 ) return dp [ n - 1 ] \ud83d\udca1 Advanced Optimization Techniques \u00b6 1. Space Optimization \u00b6 def space_optimization_example (): \"\"\" Common Techniques: 1. Rolling Array - Keep only last k states - Use mod operator for indexing 2. State Compression - Use bits to represent states - Reduce dimension of dp table Example: Fibonacci with O(1) space \"\"\" def fib_optimized ( n : int ) -> int : if n <= 1 : return n a , b = 0 , 1 for _ in range ( 2 , n + 1 ): a , b = b , a + b return b 2. State Reduction \u00b6 def state_reduction_example (): \"\"\" Techniques: 1. Eliminate Redundant States - Identify states that can be derived - Combine overlapping states 2. Change State Representation - More efficient encoding - Different perspective on problem Example: Reducing 2D DP to 1D \"\"\" # Original 2D Knapsack def knapsack_2d ( weights : List [ int ], values : List [ int ], capacity : int ) -> int : n = len ( weights ) dp = [[ 0 ] * ( capacity + 1 ) for _ in range ( n + 1 )] for i in range ( 1 , n + 1 ): for w in range ( capacity + 1 ): if weights [ i - 1 ] <= w : dp [ i ][ w ] = max ( values [ i - 1 ] + dp [ i - 1 ][ w - weights [ i - 1 ]], dp [ i - 1 ][ w ]) else : dp [ i ][ w ] = dp [ i - 1 ][ w ] return dp [ n ][ capacity ] # Optimized 1D Knapsack def knapsack_1d ( weights : List [ int ], values : List [ int ], capacity : int ) -> int : dp = [ 0 ] * ( capacity + 1 ) for i in range ( len ( weights )): for w in range ( capacity , weights [ i ] - 1 , - 1 ): dp [ w ] = max ( dp [ w ], dp [ w - weights [ i ]] + values [ i ]) return dp [ capacity ] Remember: Always start with a clear understanding of subproblems Draw out the recurrence relation Consider both top-down and bottom-up approaches Look for optimization opportunities Test with small cases first Reference \u00b6 Dynamic Programming \ud83d\udcca Graphs & Graph Theory \u00b6 \ud83d\udcda Core Concepts \u00b6 What is a Graph? \u00b6 A graph is a data structure consisting of: Vertices (Nodes) : Points in the graph Edges : Connections between vertices Optional Properties : Weights, directions, labels Types of Graphs: graph_types = { \"Undirected\" : \"Edges have no direction (Facebook friendships)\" , \"Directed\" : \"Edges have direction (Twitter follows)\" , \"Weighted\" : \"Edges have weights (Road distances)\" , \"Connected\" : \"Path exists between any two vertices\" , \"Cyclic\" : \"Contains at least one cycle\" , \"Acyclic\" : \"Contains no cycles (trees are acyclic)\" } \ud83c\udfaf Graph Representations \u00b6 1. Adjacency List (Most Common in Interviews) \u00b6 class Graph : def __init__ ( self ): self . graph = {} def add_vertex ( self , vertex ): if vertex not in self . graph : self . graph [ vertex ] = set () def add_edge ( self , v1 , v2 ): if v1 not in self . graph : self . add_vertex ( v1 ) if v2 not in self . graph : self . add_vertex ( v2 ) self . graph [ v1 ] . add ( v2 ) self . graph [ v2 ] . add ( v1 ) # Remove for directed graph 2. Adjacency Matrix \u00b6 class GraphMatrix : def __init__ ( self , vertices ): self . V = vertices self . graph = [[ 0 ] * vertices for _ in range ( vertices )] def add_edge ( self , v1 , v2 , weight = 1 ): self . graph [ v1 ][ v2 ] = weight self . graph [ v2 ][ v1 ] = weight # Remove for directed graph \ud83c\udfae Essential Graph Operations \u00b6 1. Graph Traversal \u00b6 BFS (Breadth-First Search) \u00b6 from collections import deque def bfs ( graph , start ): \"\"\" Time: O(V + E) Space: O(V) Use when: - Finding shortest paths - Level-by-level traversal - Finding nodes at distance k \"\"\" visited = set ([ start ]) queue = deque ([ start ]) while queue : vertex = queue . popleft () for neighbor in graph [ vertex ]: if neighbor not in visited : visited . add ( neighbor ) queue . append ( neighbor ) return visited DFS (Depth-First Search) \u00b6 def dfs ( graph , start , visited = None ): \"\"\" Time: O(V + E) Space: O(V) Use when: - Finding paths/cycles - Exhaustively exploring paths - Topological sorting \"\"\" if visited is None : visited = set () visited . add ( start ) for neighbor in graph [ start ]: if neighbor not in visited : dfs ( graph , neighbor , visited ) return visited # Iterative DFS (often preferred in interviews) def dfs_iterative ( graph , start ): visited = set () stack = [ start ] while stack : node = stack . pop () if node not in visited : visited . add ( node ) stack . extend ( neighbor for neighbor in graph [ node ] if neighbor not in visited ) return visited 2. Path Finding \u00b6 Find Path Between Two Vertices \u00b6 def find_path ( graph , start , end , path = None ): if path is None : path = [] path = path + [ start ] if start == end : return path for neighbor in graph [ start ]: if neighbor not in path : new_path = find_path ( graph , neighbor , end , path ) if new_path : return new_path return None Find All Paths \u00b6 def find_all_paths ( graph , start , end , path = None ): if path is None : path = [] path = path + [ start ] if start == end : return [ path ] paths = [] for neighbor in graph [ start ]: if neighbor not in path : new_paths = find_all_paths ( graph , neighbor , end , path ) paths . extend ( new_paths ) return paths \ud83c\udfaf Common Graph Algorithms for Interviews \u00b6 1. Detect Cycle \u00b6 def has_cycle ( graph ): visited = set () rec_stack = set () def dfs_cycle ( vertex ): visited . add ( vertex ) rec_stack . add ( vertex ) for neighbor in graph [ vertex ]: if neighbor not in visited : if dfs_cycle ( neighbor ): return True elif neighbor in rec_stack : return True rec_stack . remove ( vertex ) return False for vertex in graph : if vertex not in visited : if dfs_cycle ( vertex ): return True return False 2. Topological Sort \u00b6 def topological_sort ( graph ): \"\"\" For directed acyclic graphs (DAGs) Time: O(V + E) Space: O(V) Use when: - Scheduling with dependencies - Build systems - Course prerequisites \"\"\" def dfs ( node ): if node in visited : return visited . add ( node ) for neighbor in graph [ node ]: dfs ( neighbor ) result . append ( node ) visited = set () result = [] for node in graph : dfs ( node ) return result [:: - 1 ] # Reverse for correct order # Alternative: Kahn's Algorithm (BFS-based) def topological_sort_kahn ( graph ): in_degree = { node : 0 for node in graph } for node in graph : for neighbor in graph [ node ]: in_degree [ neighbor ] += 1 queue = deque ([ node for node , degree in in_degree . items () if degree == 0 ]) result = [] while queue : node = queue . popleft () result . append ( node ) for neighbor in graph [ node ]: in_degree [ neighbor ] -= 1 if in_degree [ neighbor ] == 0 : queue . append ( neighbor ) return result if len ( result ) == len ( graph ) else [] # Check for cycles 3. Connected Components \u00b6 def find_connected_components ( graph ): def dfs_component ( vertex , component ): visited . add ( vertex ) component . append ( vertex ) for neighbor in graph [ vertex ]: if neighbor not in visited : dfs_component ( neighbor , component ) visited = set () components = [] for vertex in graph : if vertex not in visited : current_component = [] dfs_component ( vertex , current_component ) components . append ( current_component ) return components 4. Shortest Path Algorithms \u00b6 Dijkstra's Algorithm \u00b6 import heapq def dijkstra ( graph , start ): \"\"\" For weighted graphs with non-negative edges Time: O((V + E) log V) Space: O(V) Use when: - Finding shortest paths - Network routing - GPS navigation \"\"\" distances = { vertex : float ( 'infinity' ) for vertex in graph } distances [ start ] = 0 pq = [( 0 , start )] while pq : current_distance , current = heapq . heappop ( pq ) if current_distance > distances [ current ]: continue for neighbor , weight in graph [ current ] . items (): distance = current_distance + weight if distance < distances [ neighbor ]: distances [ neighbor ] = distance heapq . heappush ( pq , ( distance , neighbor )) return distances 5. Union Find (Disjoint Set) \u00b6 class UnionFind : \"\"\" Time: O(\u03b1(n)) per operation (practically O(1)) Space: O(n) Use when: - Finding connected components - Cycle detection - Minimum spanning trees \"\"\" def __init__ ( self , size ): self . parent = list ( range ( size )) self . rank = [ 0 ] * size def find ( self , x ): if self . parent [ x ] != x : self . parent [ x ] = self . find ( self . parent [ x ]) # Path compression return self . parent [ x ] def union ( self , x , y ): px , py = self . find ( x ), self . find ( y ) if px == py : return False # Union by rank if self . rank [ px ] < self . rank [ py ]: self . parent [ px ] = py elif self . rank [ px ] > self . rank [ py ]: self . parent [ py ] = px else : self . parent [ py ] = px self . rank [ px ] += 1 return True \ud83d\udcdd Interview Problem Patterns \u00b6 1. Graph Traversal Problems \u00b6 Visiting all nodes/edges Finding connected components Level-order traversal traversal_tips = { \"BFS\" : \"Use when:- Finding shortest path- Level by level traversal- Minimum steps\" , \"DFS\" : \"Use when:- Exploring paths- Finding cycles- Topological sorting\" , \"Edge Cases\" : \"- Empty graph- Single node- Disconnected components\" } 2. Path Finding Problems \u00b6 Shortest path All possible paths Path with constraints def shortest_path ( graph , start , end ): queue = deque ([( start , [ start ])]) visited = { start } while queue : vertex , path = queue . popleft () if vertex == end : return path for neighbor in graph [ vertex ]: if neighbor not in visited : visited . add ( neighbor ) queue . append (( neighbor , path + [ neighbor ])) return None \ud83d\udca1 Interview Tips \u00b6 Representation Choice choosing_representation = { \"Adjacency List\" : \"- Sparse graphs- Memory efficient- Quick neighbor lookup\" , \"Adjacency Matrix\" : \"- Dense graphs- Quick edge weight lookup- Simple implementation\" } Algorithm Selection algorithm_selection = { \"BFS\" : \"Shortest path in unweighted graph\" , \"DFS\" : \"Path finding, cycle detection\" , \"Dijkstra\" : \"Shortest path in weighted graph\" , \"Union Find\" : \"Connected components, cycle detection in undirected graph\" } selection_guide = { \"Shortest Path (Unweighted)\" : \"Use BFS\" , \"Shortest Path (Weighted, Non-negative)\" : \"Use Dijkstra\" , \"Shortest Path (Weighted, Can be negative)\" : \"Use Bellman-Ford\" , \"Cycle Detection\" : \"Use DFS with recursion stack\" , \"Component Finding\" : \"Use Union Find or DFS\" , \"Dependency Ordering\" : \"Use Topological Sort\" , \"Two-Coloring Problems\" : \"Use Bipartite Check\" } Edge Cases to Consider edge_cases = [ \"Empty graph\" , \"Single node\" , \"Disconnected components\" , \"Cycles\" , \"Self-loops\" , \"Bidirectional edges\" , \"No path exists\" ] Optimization Tips : Use adjacency list for sparse graphs Use adjacency matrix for dense graphs Consider using iterative DFS instead of recursive for large graphs Use Union Find for dynamic connectivity problems Cache results in graph traversal when possible Remember: Always clarify the graph properties (directed/undirected, weighted/unweighted) Consider time/space complexity tradeoffs Draw examples when solving Test with small cases first Consider using helper functions for complex logic \ud83c\udf33 Minimum Spanning Trees (MST) \u00b6 \ud83d\udcda Core Concepts \u00b6 What is a Minimum Spanning Tree? \u00b6 \"\"\" A Minimum Spanning Tree (MST) is a subset of edges in a connected, undirected, weighted graph that: 1. Connects all vertices 2. Contains no cycles 3. Has minimum total edge weight among all possible spanning trees Properties: - Contains exactly V-1 edges (where V is number of vertices) - May not be unique (graph can have multiple MSTs) - Always unique if all edge weights are different \"\"\" \ud83c\udfaf Key Algorithms \u00b6 1. Kruskal's Algorithm \u00b6 class UnionFind : def __init__ ( self , size ): self . parent = list ( range ( size )) self . rank = [ 0 ] * size def find ( self , x ): if self . parent [ x ] != x : self . parent [ x ] = self . find ( self . parent [ x ]) # Path compression return self . parent [ x ] def union ( self , x , y ): px , py = self . find ( x ), self . find ( y ) if px == py : return False # Union by rank if self . rank [ px ] < self . rank [ py ]: self . parent [ px ] = py elif self . rank [ px ] > self . rank [ py ]: self . parent [ py ] = px else : self . parent [ py ] = px self . rank [ px ] += 1 return True def kruskal_mst ( graph , V ): \"\"\" Time: O(E log E) where E is number of edges Space: O(V) where V is number of vertices Use when: - Graph is sparse (E << V\u00b2) - Graph might not be connected - Edge weights are primary consideration \"\"\" edges = [] # (weight, u, v) for u in range ( V ): for v , w in graph [ u ]: edges . append (( w , u , v )) edges . sort () # Sort by weight uf = UnionFind ( V ) mst = [] mst_weight = 0 for weight , u , v in edges : if uf . union ( u , v ): # If no cycle is created mst . append (( u , v )) mst_weight += weight if len ( mst ) == V - 1 : break return mst , mst_weight 2. Prim's Algorithm \u00b6 from heapq import heappush , heappop def prim_mst ( graph , V ): \"\"\" Time: O(E log V) with min-heap Space: O(V) Use when: - Graph is dense (E \u2248 V\u00b2) - Graph is guaranteed to be connected - Starting vertex is known/important \"\"\" visited = [ False ] * V min_heap = [( 0 , 0 , - 1 )] # (weight, vertex, parent) mst = [] mst_weight = 0 while min_heap : weight , vertex , parent = heappop ( min_heap ) if visited [ vertex ]: continue visited [ vertex ] = True if parent != - 1 : mst . append (( parent , vertex )) mst_weight += weight for next_vertex , edge_weight in graph [ vertex ]: if not visited [ next_vertex ]: heappush ( min_heap , ( edge_weight , next_vertex , vertex )) return mst , mst_weight \ud83c\udfae Algorithm Selection Guide \u00b6 When to Use Each Algorithm \u00b6 def choose_mst_algorithm ( graph_properties ): selection_guide = { \"Kruskal\" : { \"Best for\" : [ \"Sparse graphs (E << V\u00b2)\" , \"When graph might be disconnected\" , \"When edge weights are the focus\" ], \"Advantages\" : [ \"Works with disconnected graphs\" , \"Tends to be simpler to implement\" , \"Good for sparse graphs\" ] }, \"Prim\" : { \"Best for\" : [ \"Dense graphs (E \u2248 V\u00b2)\" , \"When starting vertex matters\" , \"When graph is connected\" ], \"Advantages\" : [ \"Better for dense graphs\" , \"Can find partial MSTs\" , \"More efficient with priority queue\" ] } } \ud83d\udcdd Common Interview Problems \u00b6 1. Connecting Cities with Minimum Cost \u00b6 def min_cost_connect_cities ( connections , N ): \"\"\" Given a list of connections [city1, city2, cost], find minimum cost to connect all cities \"\"\" def find ( x ): if parent [ x ] != x : parent [ x ] = find ( parent [ x ]) return parent [ x ] def union ( x , y ): px , py = find ( x ), find ( y ) if px == py : return False parent [ px ] = py return True parent = list ( range ( N + 1 )) connections . sort ( key = lambda x : x [ 2 ]) # Sort by cost total_cost = 0 edges_used = 0 for city1 , city2 , cost in connections : if union ( city1 , city2 ): total_cost += cost edges_used += 1 return total_cost if edges_used == N - 1 else - 1 2. Network Optimization \u00b6 def optimize_network ( nodes , connections ): \"\"\" Optimize network connections while maintaining minimum latency between all nodes \"\"\" def mst_with_constraints ( edges ): uf = UnionFind ( len ( nodes )) mst = [] total_latency = 0 for u , v , latency in sorted ( edges , key = lambda x : ( x [ 2 ], x [ 0 ])): if uf . union ( u , v ): mst . append (( u , v )) total_latency += latency return mst , total_latency if len ( mst ) == len ( nodes ) - 1 else float ( 'inf' ) \ud83d\udca1 Interview Tips \u00b6 1. Problem Recognition \u00b6 mst_indicators = { \"Minimum cost/distance/weight\" : \"Total weight needs to be minimized\" , \"Connect all points\" : \"Need spanning tree property\" , \"No cycles allowed\" : \"Tree structure required\" , \"Optimize network\" : \"Network optimization problems\" , \"Reduce redundancy\" : \"Remove unnecessary edges\" } 2. Implementation Strategy \u00b6 implementation_tips = { \"1. Graph Representation\" : [ \"Adjacency list for sparse graphs\" , \"Adjacency matrix for dense graphs\" , \"Edge list for Kruskal's\" ], \"2. Edge Cases\" : [ \"Empty graph\" , \"Single node\" , \"Disconnected components\" , \"Equal edge weights\" ], \"3. Optimization\" : [ \"Use Union-Find for cycle detection\" , \"Priority queue for Prim's\" , \"Sort edges once for Kruskal's\" ] } 3. Common Mistakes to Avoid \u00b6 common_mistakes = { \"Algorithm Selection\" : \"Not considering graph density\" , \"Cycle Detection\" : \"Forgetting to check for cycles\" , \"Edge Processing\" : \"Not handling duplicate edges\" , \"Disconnected Graphs\" : \"Assuming graph is connected\" , \"Edge Weights\" : \"Not handling negative weights\" } Remember: Always verify if graph is connected when using Prim's Consider edge cases (empty graph, single node) Watch for negative edge weights Check if all vertices are included in final MST Consider trade-offs between algorithms based on graph properties Technical Interview Patterns \u00b6 Common Technical Interview Patterns","title":"\ud83d\ude80 The Ultimate Python Technical Interview Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#the-ultimate-python-technical-interview-guide","text":"","title":"\ud83d\ude80 The Ultimate Python Technical Interview Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#introduction","text":"Welcome to your comprehensive companion for mastering technical interviews! Whether you're aiming for FAANG companies or preparing for your first technical interview, this guide will help you tackle coding challenges with confidence.","title":"\ud83d\udcd8 Introduction"},{"location":"2.Interviews/b.%20technical%20interviews/#why-this-guide","text":"\ud83d\udc0d Python-Focused : All solutions and examples in Python (the most popular interview language!) \ud83e\udde0 Pattern Recognition : Learn to spot and solve common problem patterns \u26a1 Optimization Skills : Master the art of writing efficient code \ud83c\udf93 Interview Strategy : Learn not just what to code, but how to approach problems \ud83d\udcaa Practical Examples : Real interview problems with detailed solutions","title":"\ud83c\udfaf Why This Guide?"},{"location":"2.Interviews/b.%20technical%20interviews/#how-this-guide-is-different","text":"We believe learning should be fun! You'll find: \ud83c\udfae Interactive examples \ud83c\udfaf Pattern-based learning \ud83e\udde9 Visual explanations \ud83d\udca1 \"Aha!\" moment highlights \ud83d\udeab Common pitfall warnings","title":"\ud83c\udfa8 How This Guide is Different"},{"location":"2.Interviews/b.%20technical%20interviews/#guide-structure","text":"","title":"\ud83d\uddfa\ufe0f Guide Structure"},{"location":"2.Interviews/b.%20technical%20interviews/#1-foundation-building","text":"Big-O Notation and Complexity Analysis Python-specific optimizations Core data structures in Python Essential algorithms and their implementations","title":"1\ufe0f\u20e3 Foundation Building"},{"location":"2.Interviews/b.%20technical%20interviews/#2-pattern-recognition","text":"Common interview patterns When to use which approach Pattern-specific optimizations Real interview problem mappings","title":"2\ufe0f\u20e3 Pattern Recognition"},{"location":"2.Interviews/b.%20technical%20interviews/#3-interview-strategy","text":"Problem-solving framework Communication tips Code organization Testing approaches","title":"3\ufe0f\u20e3 Interview Strategy"},{"location":"2.Interviews/b.%20technical%20interviews/#good-references","text":"Technical Interview Github Repo","title":"Good References"},{"location":"2.Interviews/b.%20technical%20interviews/#before-we-begin-python-essentials","text":"","title":"\ud83d\udcbb Before We Begin: Python Essentials"},{"location":"2.Interviews/b.%20technical%20interviews/#key-python-tools-for-interviews","text":"# Common imports you'll need from collections import defaultdict , deque , Counter from heapq import heappush , heappop from typing import List , Dict , Set","title":"\ud83d\udd27 Key Python Tools for Interviews"},{"location":"2.Interviews/b.%20technical%20interviews/#python-specific-pro-tips","text":"# 1. List comprehension for cleaner code squares = [ x * x for x in range ( 10 )] # 2. Default dictionaries for counting counter = defaultdict ( int ) # 3. Built-in sort with custom key items . sort ( key = lambda x : x . value ) # 4. Multiple assignment x , y = y , x # Swap values","title":"\ud83d\udee0\ufe0f Python-Specific Pro Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#how-to-use-this-guide","text":"","title":"\ud83c\udfaf How to Use This Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#learning-path","text":"Build the Foundation Master Python basics Understand complexity analysis Learn core data structures Pattern Recognition Study common patterns Practice similar problems Learn pattern variations Problem Solving Apply patterns to new problems Practice optimization Work on communication","title":"\ud83d\udcda Learning Path"},{"location":"2.Interviews/b.%20technical%20interviews/#time-management","text":"\ud83c\udf31 Beginner : 2-3 months of preparation \ud83c\udf3f Intermediate : 1-2 months of focused practice \ud83c\udf33 Advanced : 2-3 weeks of revision","title":"\u23f0 Time Management"},{"location":"2.Interviews/b.%20technical%20interviews/#lets-get-started","text":"","title":"\ud83c\udfae Let's Get Started!"},{"location":"2.Interviews/b.%20technical%20interviews/#your-first-steps","text":"Review Python fundamentals Start with easy problems Focus on problem-solving process Practice explaining your thought process","title":"\ud83c\udfaf Your First Steps"},{"location":"2.Interviews/b.%20technical%20interviews/#remember","text":"Understanding patterns > Memorizing solutions Practice regularly > Cramming Clear communication > Perfect code Learning from mistakes > Getting it right first time","title":"\ud83d\udca1 Remember"},{"location":"2.Interviews/b.%20technical%20interviews/#common-interview-mistakes-to-avoid","text":"Jumping into coding without planning Not clarifying requirements Ignoring edge cases Writing unclear/messy code Not testing your solution","title":"\ud83d\udea8 Common Interview Mistakes to Avoid"},{"location":"2.Interviews/b.%20technical%20interviews/#success-tips","text":"Think aloud while solving Start with brute force, then optimize Use meaningful variable names Write clean, modular code Test with edge cases Ready to begin your journey to interview success? Let's dive into our first topic: Algorithmic Complexity and Big-O Notation! \ud83d\ude80","title":"\ud83c\udf1f Success Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#algorithmic-complexity-big-o-guide","text":"","title":"\ud83c\udfaf Algorithmic Complexity &amp; Big-O Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#visual-complexity-chart","text":"Excellent O(1) \u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581 Good O(log n) \u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582 Fair O(n) \u2581\u2581\u2581\u2582\u2582\u2582\u2583\u2583\u2583\u2584\u2584\u2584\u2585\u2585\u2585\u2586\u2586\u2586 Bad O(n\u00b2) \u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Horrible O(2\u207f) \u2581\u2582\u2585\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 blog.algomaster.io","title":"\ud83c\udfa8 Visual Complexity Chart"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-algorithmic-complexity","text":"Think of algorithmic complexity as your code's \"price tag\" in terms of: \u23f1\ufe0f Time (how long it takes to run) \ud83d\udcbe Space (how much memory it needs)","title":"\ud83c\udfae What is Algorithmic Complexity?"},{"location":"2.Interviews/b.%20technical%20interviews/#why-should-you-care","text":"# Example 1: O(n) - Linear Time def find_max_linear ( arr ): # \ud83d\ude0a Good for small lists return max ( arr ) # Example 2: O(n\u00b2) - Quadratic Time def find_max_nested ( arr ): # \ud83d\ude30 Terrible for large lists max_val = arr [ 0 ] for i in arr : for j in arr : # Unnecessary nested loop! if i > max_val : max_val = i return max_val","title":"\ud83c\udfaf Why Should You Care?"},{"location":"2.Interviews/b.%20technical%20interviews/#understanding-big-o-notation","text":"","title":"\ud83d\ude80 Understanding Big-O Notation"},{"location":"2.Interviews/b.%20technical%20interviews/#common-time-complexities-from-best-to-worst","text":"O(1) - Constant Time \ud83c\udf1f def get_first ( arr ): return arr [ 0 ] if arr else None Like finding a book when you know exactly where it is Examples: Hash table access, array index access O(log n) - Logarithmic Time \u2728 def binary_search ( arr , target ): left , right = 0 , len ( arr ) - 1 while left <= right : mid = ( left + right ) // 2 if arr [ mid ] == target : return mid if arr [ mid ] < target : left = mid + 1 else : right = mid - 1 return - 1 Like finding a word in a dictionary Examples: Binary search, balanced BST operations O(n) - Linear Time \ud83d\udc4d def linear_search ( arr , target ): return any ( x == target for x in arr ) Like reading every page in a book Examples: Array traversal, linear search O(n log n) - Log-Linear Time \ud83c\udd97 def merge_sort ( arr ): if len ( arr ) <= 1 : return arr mid = len ( arr ) // 2 return merge ( merge_sort ( arr [: mid ]), merge_sort ( arr [ mid :])) Like sorting a deck of cards efficiently Examples: Merge sort, quick sort (average case) O(n\u00b2) - Quadratic Time \ud83d\ude30 def bubble_sort ( arr ): for i in range ( len ( arr )): for j in range ( len ( arr ) - 1 ): if arr [ j ] > arr [ j + 1 ]: arr [ j ], arr [ j + 1 ] = arr [ j + 1 ], arr [ j ] Like comparing every page with every other page Examples: Nested loops, bubble sort O(2\u207f) - Exponential Time \ud83d\ude31 def fibonacci_recursive ( n ): if n <= 1 : return n return fibonacci_recursive ( n - 1 ) + fibonacci_recursive ( n - 2 ) Like trying every possible combination Examples: Recursive Fibonacci, power set","title":"\ud83d\udcca Common Time Complexities (From Best to Worst)"},{"location":"2.Interviews/b.%20technical%20interviews/#common-space-complexities","text":"O(1) - Constant Space Fixed amount of extra space Example: Simple variables, fixed-size arrays O(n) - Linear Space Space grows linearly with input Example: Creating a new array of size n O(n\u00b2) - Quadratic Space Space grows quadratically Example: 2D array/matrix of size n\u00d7n","title":"\ud83c\udfae Common Space Complexities"},{"location":"2.Interviews/b.%20technical%20interviews/#big-o-cheat-sheet-for-common-data-structures","text":"","title":"\ud83c\udfaf Big-O Cheat Sheet for Common Data Structures"},{"location":"2.Interviews/b.%20technical%20interviews/#array-operations","text":"# Access: O(1) arr [ 5 ] # Direct access by index # Search: O(n) target in arr # Linear search # Insertion/Deletion at end: O(1) arr . append ( item ) # Add to end arr . pop () # Remove from end # Insertion/Deletion at middle: O(n) arr . insert ( 2 , item ) # Need to shift elements","title":"Array Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#dictionaryhash-table-operations","text":"# Access/Insert/Delete: O(1) average dict_example = {} dict_example [ 'key' ] = 'value' # O(1) value = dict_example [ 'key' ] # O(1) del dict_example [ 'key' ] # O(1)","title":"Dictionary/Hash Table Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#pro-tips-for-optimization","text":"Avoid Nested Loops When Possible # Bad: O(n\u00b2) for i in range ( n ): for j in range ( n ): # do something # Better: O(n) seen = set () for i in range ( n ): if i in seen : # do something Use Built-in Data Structures Wisely # Lists vs Sets for lookups numbers = [ 1 , 2 , 3 , 4 , 5 ] number_set = set ( numbers ) # Bad: O(n) 5 in numbers # Good: O(1) 5 in number_set Cache Results When Possible from functools import lru_cache @lru_cache ( maxsize = None ) def fibonacci ( n ): if n < 2 : return n return fibonacci ( n - 1 ) + fibonacci ( n - 2 )","title":"\ud83c\udfae Pro Tips for Optimization"},{"location":"2.Interviews/b.%20technical%20interviews/#practice-problems","text":"Identify the Time Complexity def mystery_function ( n ): result = 0 for i in range ( n ): for j in range ( i , n ): result += 1 return result # What's the time complexity? # (Answer: O(n\u00b2)) Remember: The best algorithm is often a balance between: \u23f1\ufe0f Time complexity \ud83d\udcbe Space complexity \ud83c\udfaf Code readability \ud83d\udd27 Maintainability","title":"\ud83c\udfaf Practice Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#bit-manipulation-sorting-algorithms","text":"","title":"\ud83e\uddee Bit Manipulation &amp; Sorting Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#part-1-bit-manipulation","text":"","title":"Part 1: \ud83d\udd22 Bit Manipulation"},{"location":"2.Interviews/b.%20technical%20interviews/#why-bit-manipulation","text":"\u26a1 More efficient than arithmetic operations \ud83d\ude80 Essential for optimization problems \ud83d\udcbb Crucial for low-level programming \ud83d\udcdd Common in technical interviews","title":"\ud83c\udfaf Why Bit Manipulation?"},{"location":"2.Interviews/b.%20technical%20interviews/#basic-operators","text":"# AND (&): 1 if both bits are 1 print ( 5 & 3 ) # 5(101) & 3(011) = 1(001) # OR (|): 1 if either bit is 1 print ( 5 | 3 ) # 5(101) | 3(011) = 7(111) # XOR (^): 1 if bits are different print ( 5 ^ 3 ) # 5(101) ^ 3(011) = 6(110) # NOT (~): Inverts all bits print ( ~ 5 ) # 5(101) -> -(110) # Left Shift (<<): Multiply by 2^n print ( 5 << 1 ) # 5(101) << 1 = 10(1010) # Right Shift (>>): Divide by 2^n print ( 5 >> 1 ) # 5(101) >> 1 = 2(010)","title":"\ud83d\udee0\ufe0f Basic Operators"},{"location":"2.Interviews/b.%20technical%20interviews/#common-bit-manipulation-tricks","text":"Check if Number is Even/Odd def is_even ( n : int ) -> bool : return not ( n & 1 ) # Last bit is 0 for even numbers Multiply/Divide by Powers of 2 def multiply_by_2 ( n : int ) -> int : return n << 1 # Left shift = multiply by 2 def divide_by_2 ( n : int ) -> int : return n >> 1 # Right shift = divide by 2 Set/Clear/Toggle Bits def set_bit ( n : int , pos : int ) -> int : return n | ( 1 << pos ) def clear_bit ( n : int , pos : int ) -> int : return n & ~ ( 1 << pos ) def toggle_bit ( n : int , pos : int ) -> int : return n ^ ( 1 << pos ) Check if Bit is Set def is_bit_set ( n : int , pos : int ) -> bool : return bool ( n & ( 1 << pos ))","title":"\ud83c\udfae Common Bit Manipulation Tricks"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips-for-bit-manipulation","text":"Always visualize bits on paper Test with small numbers first Consider edge cases (negatives, zero) Explain your logic step by step","title":"\ud83c\udfaf Interview Tips for Bit Manipulation"},{"location":"2.Interviews/b.%20technical%20interviews/#part-2-sorting-algorithms","text":"","title":"Part 2: \ud83d\udd04 Sorting Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#comparison-overview","text":"sorting_algos = { 'Bubble Sort' : { 'Time' : 'O(n\u00b2)' , 'Space' : 'O(1)' , 'Stable' : True }, 'Selection Sort' : { 'Time' : 'O(n\u00b2)' , 'Space' : 'O(1)' , 'Stable' : False }, 'Insertion Sort' : { 'Time' : 'O(n\u00b2)' , 'Space' : 'O(1)' , 'Stable' : True }, 'Merge Sort' : { 'Time' : 'O(n log n)' , 'Space' : 'O(n)' , 'Stable' : True }, 'Quick Sort' : { 'Time' : 'O(n log n)' , 'Space' : 'O(log n)' , 'Stable' : False }, 'Heap Sort' : { 'Time' : 'O(n log n)' , 'Space' : 'O(1)' , 'Stable' : False } }","title":"\ud83d\udcca Comparison Overview"},{"location":"2.Interviews/b.%20technical%20interviews/#simple-sorting-algorithms","text":"Bubble Sort (The Beginner's Sort) def bubble_sort ( arr : list ) -> list : n = len ( arr ) for i in range ( n ): # Flag for optimization swapped = False # Last i elements are already sorted for j in range ( 0 , n - i - 1 ): if arr [ j ] > arr [ j + 1 ]: arr [ j ], arr [ j + 1 ] = arr [ j + 1 ], arr [ j ] swapped = True # If no swaps occurred, array is sorted if not swapped : break return arr # When to use: Small arrays or nearly sorted data # Pros: Simple to implement, in-place sorting # Cons: Very inefficient for large datasets Selection Sort (The Minimalist's Sort) def selection_sort ( arr : list ) -> list : n = len ( arr ) for i in range ( n ): min_idx = i for j in range ( i + 1 , n ): if arr [ j ] < arr [ min_idx ]: min_idx = j arr [ i ], arr [ min_idx ] = arr [ min_idx ], arr [ i ] return arr # When to use: Small arrays with expensive writes # Pros: Minimum number of swaps # Cons: Always makes O(n\u00b2) comparisons Insertion Sort (The Adaptive Sort) def insertion_sort ( arr : list ) -> list : for i in range ( 1 , len ( arr )): key = arr [ i ] j = i - 1 while j >= 0 and arr [ j ] > key : arr [ j + 1 ] = arr [ j ] j -= 1 arr [ j + 1 ] = key return arr # When to use: Small datasets or nearly sorted arrays # Pros: Adaptive, stable, and great for small data # Cons: Still O(n\u00b2) in worst case","title":"\ud83c\udfaf Simple Sorting Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#advanced-sorting-algorithms","text":"Merge Sort (The Reliable Sort) def merge_sort ( arr : list ) -> list : if len ( arr ) <= 1 : return arr mid = len ( arr ) // 2 left = merge_sort ( arr [: mid ]) right = merge_sort ( arr [ mid :]) return merge ( left , right ) def merge ( left : list , right : list ) -> list : result = [] i = j = 0 while i < len ( left ) and j < len ( right ): if left [ i ] <= right [ j ]: result . append ( left [ i ]) i += 1 else : result . append ( right [ j ]) j += 1 result . extend ( left [ i :]) result . extend ( right [ j :]) return result # When to use: Large datasets where stability matters # Pros: Stable, predictable O(n log n) # Cons: Requires O(n) extra space Quick Sort (The Practical Sort) def quick_sort ( arr : list ) -> list : if len ( arr ) <= 1 : return arr pivot = arr [ len ( arr ) // 2 ] left = [ x for x in arr if x < pivot ] middle = [ x for x in arr if x == pivot ] right = [ x for x in arr if x > pivot ] return quick_sort ( left ) + middle + quick_sort ( right ) # When to use: General-purpose sorting # Pros: Usually fastest in practice # Cons: Unstable, bad worst-case O(n\u00b2) Heap Sort (The Memory-Efficient Sort) def heapify ( arr : list , n : int , i : int ): largest = i left = 2 * i + 1 right = 2 * i + 2 if left < n and arr [ left ] > arr [ largest ]: largest = left if right < n and arr [ right ] > arr [ largest ]: largest = right if largest != i : arr [ i ], arr [ largest ] = arr [ largest ], arr [ i ] heapify ( arr , n , largest ) def heap_sort ( arr : list ) -> list : n = len ( arr ) # Build max heap for i in range ( n // 2 - 1 , - 1 , - 1 ): heapify ( arr , n , i ) # Extract elements from heap for i in range ( n - 1 , 0 , - 1 ): arr [ 0 ], arr [ i ] = arr [ i ], arr [ 0 ] heapify ( arr , i , 0 ) return arr # When to use: When space is a premium # Pros: In-place, O(n log n) guaranteed # Cons: Unstable, poor cache performance","title":"\ud83d\ude80 Advanced Sorting Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#special-purpose-sorting-algorithms","text":"Shell Sort (The Gap Sort) def shell_sort ( arr : list ) -> list : n = len ( arr ) gap = n // 2 while gap > 0 : for i in range ( gap , n ): temp = arr [ i ] j = i while j >= gap and arr [ j - gap ] > temp : arr [ j ] = arr [ j - gap ] j -= gap arr [ j ] = temp gap //= 2 return arr # When to use: Medium-sized arrays # Pros: Adaptive, handles partially sorted arrays well # Cons: Complex gap sequence selection Counting Sort (The Integer Sort) def counting_sort ( arr : list ) -> list : if not arr : return arr # Find range of array elements max_val = max ( arr ) min_val = min ( arr ) range_val = max_val - min_val + 1 # Create counting array and output array count = [ 0 ] * range_val output = [ 0 ] * len ( arr ) # Store count of each element for num in arr : count [ num - min_val ] += 1 # Modify count array to store actual positions for i in range ( 1 , len ( count )): count [ i ] += count [ i - 1 ] # Build output array for num in reversed ( arr ): output [ count [ num - min_val ] - 1 ] = num count [ num - min_val ] -= 1 return output # When to use: Integer arrays with known range # Pros: O(n) for known range integers # Cons: Requires extra space proportional to range Radix Sort (The Digit Sort) def counting_sort_for_radix ( arr : list , exp : int ) -> list : n = len ( arr ) output = [ 0 ] * n count = [ 0 ] * 10 # Store count of occurrences for i in range ( n ): index = arr [ i ] // exp count [ index % 10 ] += 1 # Change count[i] to contain actual position for i in range ( 1 , 10 ): count [ i ] += count [ i - 1 ] # Build output array i = n - 1 while i >= 0 : index = arr [ i ] // exp output [ count [ index % 10 ] - 1 ] = arr [ i ] count [ index % 10 ] -= 1 i -= 1 # Copy output array to arr for i in range ( n ): arr [ i ] = output [ i ] def radix_sort ( arr : list ) -> list : if not arr : return arr # Find maximum number to know number of digits max_val = max ( arr ) # Do counting sort for every digit exp = 1 while max_val // exp > 0 : counting_sort_for_radix ( arr , exp ) exp *= 10 return arr # When to use: Integer arrays with fixed number of digits # Pros: Linear time possible for fixed-length integers # Cons: Only works with integers, uses extra space Bucket Sort (The Distribution Sort) def bucket_sort ( arr : list , num_buckets : int = 10 ) -> list : if not arr : return arr # Find range of values max_val , min_val = max ( arr ), min ( arr ) # Create buckets range_val = ( max_val - min_val ) / num_buckets buckets = [[] for _ in range ( num_buckets )] # Put elements in buckets for num in arr : if num == max_val : bucket_idx = num_buckets - 1 else : bucket_idx = int (( num - min_val ) / range_val ) buckets [ bucket_idx ] . append ( num ) # Sort individual buckets for bucket in buckets : bucket . sort () # Using TimSort internally in Python # Concatenate all buckets into arr return [ num for bucket in buckets for num in bucket ] # When to use: Uniformly distributed data over a range # Pros: Linear time possible for uniform distribution # Cons: Requires uniform distribution for efficiency Tim Sort (Python's Built-in Sort) # Python's built-in sort uses TimSort def tim_sort_example ( arr : list ) -> list : return sorted ( arr ) # Uses TimSort internally # When to use: General purpose sorting # Pros: Excellent performance on real-world data # Cons: Complex implementation, requires extra space","title":"\ud83c\udfa8 Special Purpose Sorting Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#best-practices-for-each-algorithm","text":"","title":"\ud83c\udfaf Best Practices for Each Algorithm"},{"location":"2.Interviews/b.%20technical%20interviews/#simple-sorts-on2","text":"Bubble Sort : Nearly sorted data, teaching purposes Selection Sort : Small arrays, minimizing swaps Insertion Sort : Small arrays, online sorting","title":"Simple Sorts (O(n\u00b2))"},{"location":"2.Interviews/b.%20technical%20interviews/#efficient-sorts-on-log-n","text":"Merge Sort : Stable sorting needed, linked lists Quick Sort : General purpose, arrays Heap Sort : Memory constrained, guaranteed O(n log n)","title":"Efficient Sorts (O(n log n))"},{"location":"2.Interviews/b.%20technical%20interviews/#special-purpose-sorts","text":"Shell Sort : Medium-sized arrays, partially sorted data Counting Sort : Small range integers Radix Sort : Fixed-length integers, like phone numbers Bucket Sort : Uniformly distributed floating-point numbers Tim Sort : When you need the best of both worlds (stable & efficient)","title":"Special Purpose Sorts"},{"location":"2.Interviews/b.%20technical%20interviews/#choosing-the-right-sort","text":"Consider Your Data Size of dataset Data type (integers, floating-point, strings) Data distribution Range of values Consider Your Constraints Memory limitations Stability requirements Whether data is streaming (online) Performance requirements General Guidelines Small dataset (n < 50): Insertion Sort Memory constrained: Heap Sort Stability required: Merge Sort General purpose: Quick Sort or Tim Sort Integer data: Counting Sort or Radix Sort Remember: In Python, use the built-in sort() or sorted() for best performance! They use TimSort, which is optimized for real-world data patterns. \ud83d\ude80","title":"\ud83c\udfae Choosing the Right Sort"},{"location":"2.Interviews/b.%20technical%20interviews/#linked-lists-dummy-node-technique-guide","text":"","title":"\ud83d\udd17 Linked Lists &amp; Dummy Node Technique Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#understanding-linked-lists","text":"","title":"\ud83d\udcd8 Understanding Linked Lists"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-a-linked-list","text":"class ListNode : def __init__ ( self , val = 0 , next = None ): self . val = val self . next = next","title":"\ud83c\udfaf What is a Linked List?"},{"location":"2.Interviews/b.%20technical%20interviews/#types-of-linked-lists","text":"Singly Linked List # 1 -> 2 -> 3 -> None head = ListNode ( 1 ) head . next = ListNode ( 2 ) head . next . next = ListNode ( 3 ) Doubly Linked List class DoublyListNode : def __init__ ( self , val = 0 , next = None , prev = None ): self . val = val self . next = next self . prev = prev Circular Linked List # 1 -> 2 -> 3 -> 1 (cycles back) head = ListNode ( 1 ) head . next = ListNode ( 2 ) head . next . next = ListNode ( 3 ) head . next . next . next = head # Creates cycle","title":"\ud83d\udcca Types of Linked Lists"},{"location":"2.Interviews/b.%20technical%20interviews/#core-implementation-options","text":"","title":"\ud83d\udcda Core Implementation Options"},{"location":"2.Interviews/b.%20technical%20interviews/#1-using-collectionsdeque","text":"from collections import deque # Creating linked lists llist = deque () # Empty list llist = deque ([ 1 , 2 , 3 ]) # From iterable llist = deque ( 'abc' ) # From string # Common Operations llist . append ( x ) # Add to right llist . appendleft ( x ) # Add to left llist . pop () # Remove from right llist . popleft () # Remove from left","title":"1\ufe0f\u20e3 Using collections.deque"},{"location":"2.Interviews/b.%20technical%20interviews/#2-custom-linked-list-implementation","text":"class Node : def __init__ ( self , data ): self . data = data self . next = None def __repr__ ( self ): return str ( self . data ) class LinkedList : def __init__ ( self , nodes = None ): self . head = None if nodes : node = Node ( data = nodes . pop ( 0 )) self . head = node for elem in nodes : node . next = Node ( data = elem ) node = node . next def __repr__ ( self ): nodes = [] curr = self . head while curr : nodes . append ( str ( curr . data )) curr = curr . next return \" -> \" . join ( nodes + [ \"None\" ]) def __iter__ ( self ): node = self . head while node : yield node node = node . next","title":"2\ufe0f\u20e3 Custom Linked List Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#common-pattern-templates","text":"","title":"\ud83c\udfaf Common Pattern Templates"},{"location":"2.Interviews/b.%20technical%20interviews/#1-two-pointer-technique-template","text":"def two_pointer_template ( head ): # Initialize pointers slow = fast = head # Move pointers while fast and fast . next : slow = slow . next # Move one step fast = fast . next . next # Move two steps # Optional: Detection logic here if slow == fast : return True # Or other logic return False","title":"1\ufe0f\u20e3 Two-Pointer Technique Template"},{"location":"2.Interviews/b.%20technical%20interviews/#2-reverse-list-template","text":"def reverse_template ( head ): prev = None current = head while current : # Store next next_node = current . next # Reverse pointer current . next = prev # Move prev and current prev = current current = next_node return prev # New head","title":"2\ufe0f\u20e3 Reverse List Template"},{"location":"2.Interviews/b.%20technical%20interviews/#3-merge-lists-template","text":"def merge_template ( l1 , l2 ): dummy = Node ( 0 ) current = dummy while l1 and l2 : if l1 . val <= l2 . val : current . next = l1 l1 = l1 . next else : current . next = l2 l2 = l2 . next current = current . next # Attach remaining nodes current . next = l1 or l2 return dummy . next","title":"3\ufe0f\u20e3 Merge Lists Template"},{"location":"2.Interviews/b.%20technical%20interviews/#essential-operations-templates","text":"","title":"\ud83d\udee0\ufe0f Essential Operations Templates"},{"location":"2.Interviews/b.%20technical%20interviews/#1-node-insertion","text":"def insert_operations (): # Insert at beginning - O(1) def add_first ( self , node ): node . next = self . head self . head = node # Insert at end - O(n) def add_last ( self , node ): if not self . head : self . head = node return for current in self : pass current . next = node # Insert after node - O(n) def add_after ( self , target_data , new_node ): if not self . head : raise Exception ( \"List is empty\" ) for node in self : if node . data == target_data : new_node . next = node . next node . next = new_node return raise Exception ( \"Node not found\" )","title":"1\ufe0f\u20e3 Node Insertion"},{"location":"2.Interviews/b.%20technical%20interviews/#2-node-deletion","text":"def removal_template ( self , target ): if not self . head : raise Exception ( \"List is empty\" ) # Handle head removal if self . head . data == target : self . head = self . head . next return # Handle other removals current = self . head while current . next : if current . next . data == target : current . next = current . next . next return current = current . next raise Exception ( \"Node not found\" )","title":"2\ufe0f\u20e3 Node Deletion"},{"location":"2.Interviews/b.%20technical%20interviews/#the-dummy-node-technique","text":"","title":"\ud83c\udfaf The Dummy Node Technique"},{"location":"2.Interviews/b.%20technical%20interviews/#why-use-dummy-nodes","text":"Simplifies edge cases Avoids null pointer exceptions Makes code cleaner and more uniform Particularly useful for: List manipulation Merging lists Removing elements Complex operations","title":"\ud83d\udd11 Why Use Dummy Nodes?"},{"location":"2.Interviews/b.%20technical%20interviews/#dummy-node-pattern-template","text":"def linked_list_operation ( head : ListNode ) -> ListNode : # Create dummy node dummy = ListNode ( 0 ) dummy . next = head # Work with dummy node current = dummy while current . next : # Perform operations current = current . next # Return modified list return dummy . next","title":"\ud83d\udcdd Dummy Node Pattern Template"},{"location":"2.Interviews/b.%20technical%20interviews/#advanced-techniques-with-dummy-nodes","text":"Multiple Dummy Nodes def oddEvenList ( head : ListNode ) -> ListNode : if not head : return None # Two dummy nodes for odd and even lists odd_dummy = ListNode ( 0 ) even_dummy = ListNode ( 0 ) odd = odd_dummy even = even_dummy is_odd = True current = head while current : if is_odd : odd . next = current odd = odd . next else : even . next = current even = even . next is_odd = not is_odd current = current . next # Connect odd and even lists odd . next = even_dummy . next even . next = None return odd_dummy . next Dummy Node w/ Fast/Slower Pointers def hasCycle ( head : ListNode ) -> bool : dummy = ListNode ( 0 ) dummy . next = head slow = dummy fast = dummy while fast and fast . next : slow = slow . next fast = fast . next . next if slow == fast : return True return False","title":"\ud83c\udfaf Advanced Techniques with Dummy Nodes"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips","text":"When to Use Dummy Nodes List modification required Head might change Multiple pointer manipulation Merging or splitting lists Common Patterns # Pattern 1: Basic Dummy Node dummy = ListNode ( 0 ) dummy . next = head current = dummy # Pattern 2: Multiple Pointers dummy = ListNode ( 0 ) slow = fast = dummy # Pattern 3: Multiple Dummies dummy1 = ListNode ( 0 ) dummy2 = ListNode ( 0 ) Edge Cases to Consider Empty list Single node Two nodes Cycles in list Duplicate values","title":"\ud83c\udfaf Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#practice-problems_1","text":"Reverse Linked List Detect Cycle Find Middle Node Remove Duplicates Merge K Sorted Lists Remember: Always handle edge cases first Consider using dummy nodes for cleaner code Test with small examples Draw the list operations on paper Keep track of all pointers carefully","title":"\ud83c\udfae Practice Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#stack-queue-implementations-in-python","text":"","title":"\ud83d\udd04 Stack &amp; Queue Implementations in Python"},{"location":"2.Interviews/b.%20technical%20interviews/#stack-implementations","text":"","title":"\ud83d\udcda Stack Implementations"},{"location":"2.Interviews/b.%20technical%20interviews/#1-using-list-as-stack","text":"class ListStack : def __init__ ( self ): self . stack = [] def push ( self , item ): self . stack . append ( item ) def pop ( self ): if not self . is_empty (): return self . stack . pop () raise IndexError ( \"Stack is empty\" ) def peek ( self ): if not self . is_empty (): return self . stack [ - 1 ] raise IndexError ( \"Stack is empty\" ) def is_empty ( self ): return len ( self . stack ) == 0 def size ( self ): return len ( self . stack )","title":"1\ufe0f\u20e3 Using List as Stack"},{"location":"2.Interviews/b.%20technical%20interviews/#2-using-collectionsdeque-as-stack","text":"from collections import deque class DequeStack : def __init__ ( self ): self . stack = deque () def push ( self , item ): self . stack . append ( item ) def pop ( self ): if not self . is_empty (): return self . stack . pop () raise IndexError ( \"Stack is empty\" ) def peek ( self ): if not self . is_empty (): return self . stack [ - 1 ] raise IndexError ( \"Stack is empty\" ) def is_empty ( self ): return len ( self . stack ) == 0 def size ( self ): return len ( self . stack )","title":"2\ufe0f\u20e3 Using Collections.deque as Stack"},{"location":"2.Interviews/b.%20technical%20interviews/#common-stack-pattern-templates","text":"Basic Stack Operations Pattern def stack_pattern ( data ): stack = [] # or deque() for item in data : # Process current item while stack and some_condition ( stack [ - 1 ], item ): # Do something with stack.pop() pass stack . append ( item ) return result Monotonic Stack Pattern def monotonic_stack_pattern ( arr ): stack = [] # stores indices usually result = [ 0 ] * len ( arr ) # or any default value for i in range ( len ( arr )): # For increasing stack (next smaller) while stack and arr [ stack [ - 1 ]] > arr [ i ]: popped = stack . pop () result [ popped ] = i - popped # or any calculation stack . append ( i ) return result","title":"Common Stack Pattern Templates"},{"location":"2.Interviews/b.%20technical%20interviews/#queue-implementations","text":"","title":"\ud83d\udcdd Queue Implementations"},{"location":"2.Interviews/b.%20technical%20interviews/#1-using-collectionsdeque-as-queue","text":"from collections import deque class DequeQueue : def __init__ ( self ): self . queue = deque () def enqueue ( self , item ): self . queue . append ( item ) def dequeue ( self ): if not self . is_empty (): return self . queue . popleft () raise IndexError ( \"Queue is empty\" ) def front ( self ): if not self . is_empty (): return self . queue [ 0 ] raise IndexError ( \"Queue is empty\" ) def rear ( self ): if not self . is_empty (): return self . queue [ - 1 ] raise IndexError ( \"Queue is empty\" ) def is_empty ( self ): return len ( self . queue ) == 0 def size ( self ): return len ( self . queue )","title":"1\ufe0f\u20e3 Using Collections.deque as Queue"},{"location":"2.Interviews/b.%20technical%20interviews/#2-queue-implementation","text":"from queue import Queue # Thread-safe queue usage queue = Queue () queue . put ( item ) # Enqueue item = queue . get () # Dequeue size = queue . qsize () # Size empty = queue . empty ()","title":"2\ufe0f\u20e3 Queue Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#common-implementation-patterns","text":"","title":"\ud83c\udfaf Common Implementation Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#pattern-1-lifo-stack-pattern","text":"def stack_pattern ( data ): stack = [] # or deque() for item in data : # Process current item while stack and condition ( stack [ - 1 ], item ): # Process stack.pop() pass stack . append ( item ) return result","title":"Pattern 1: LIFO Stack Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#pattern-2-fifo-queue-pattern","text":"def queue_pattern ( start_node ): queue = deque ([ start_node ]) seen = { start_node } while queue : current = queue . popleft () # Process current node for neighbor in get_neighbors ( current ): if neighbor not in seen : seen . add ( neighbor ) queue . append ( neighbor )","title":"Pattern 2: FIFO Queue Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#key-operations-complexities","text":"","title":"\ud83d\udd11 Key Operations &amp; Complexities"},{"location":"2.Interviews/b.%20technical%20interviews/#stack-operations","text":"operations = { 'push' : 'O(1)' , # Add to top 'pop' : 'O(1)' , # Remove from top 'peek' : 'O(1)' , # View top element 'isEmpty' : 'O(1)' , # Check if empty 'size' : 'O(1)' # Get number of elements }","title":"Stack Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#queue-operations","text":"operations = { 'enqueue' : 'O(1)' , # Add to back 'dequeue' : 'O(1)' , # Remove from front 'front' : 'O(1)' , # View front element 'isEmpty' : 'O(1)' , # Check if empty 'size' : 'O(1)' # Get number of elements }","title":"Queue Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-what","text":"","title":"\ud83d\udca1When to Use What"},{"location":"2.Interviews/b.%20technical%20interviews/#use-stack-when","text":"Need LIFO (Last In, First Out) behavior Tracking state changes (undo/redo) Parse expressions (parentheses matching) Function call management DFS implementation","title":"Use Stack When:"},{"location":"2.Interviews/b.%20technical%20interviews/#use-queue-when","text":"Need FIFO (First In, First Out) behavior Order must be preserved BFS implementation Task scheduling Resource pooling","title":"Use Queue When:"},{"location":"2.Interviews/b.%20technical%20interviews/#implementation-comparison","text":"","title":"\ud83c\udfaf Implementation Comparison"},{"location":"2.Interviews/b.%20technical%20interviews/#stack-implementation-comparison","text":"# List as Stack - Pros: Simple, built-in, good for small data - Cons: Potential memory reallocation for large data - Use when: Simple stack operations needed # Deque as Stack - Pros: Efficient memory usage, thread-safe - Cons: Slightly more complex than list - Use when: Large data or thread safety needed","title":"Stack Implementation Comparison"},{"location":"2.Interviews/b.%20technical%20interviews/#queue-implementation-comparison","text":"# Deque as Queue - Pros: O(1) operations, efficient memory - Cons: Not fixed size - Use when: General queue operations needed # Queue - Pros: Memory efficient, fixed size - Cons: More complex implementation - Use when: Fixed size buffer needed","title":"Queue Implementation Comparison"},{"location":"2.Interviews/b.%20technical%20interviews/#practice-problem-tips","text":"Always clarify: Is there a size limit? What happens on empty pop/dequeue? Should operations be thread-safe? What type of elements to store? Consider: Time/Space complexity requirements Concurrency needs Error handling approach Edge cases Remember: Use collections.deque for efficient implementation Consider thread-safety needs before choosing implementation Watch for operation order dependence Handle edge cases explicitly","title":"\ud83c\udfae Practice Problem Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#hash-tables-in-python-dictionaries","text":"","title":"\ud83d\uddc3\ufe0f Hash Tables in Python (Dictionaries)"},{"location":"2.Interviews/b.%20technical%20interviews/#basic-implementation","text":"","title":"\ud83d\udcda Basic Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#1-dictionary-creation","text":"# Method 1: Using curly braces hash_map = { 'key1' : 'value1' , 'key2' : 'value2' } # Method 2: Using dict() constructor hash_map = dict ( key1 = 'value1' , key2 = 'value2' ) # Method 3: From list of tuples hash_map = dict ([ ( 'key1' , 'value1' ), ( 'key2' , 'value2' ) ]) # Method 4: Empty dictionary hash_map = {}","title":"1\ufe0f\u20e3 Dictionary Creation"},{"location":"2.Interviews/b.%20technical%20interviews/#2-basic-operations","text":"# Access Operations - O(1) average case hash_map [ 'key' ] = 'value' # Insert/Update value = hash_map [ 'key' ] # Access del hash_map [ 'key' ] # Delete # Safe Access value = hash_map . get ( 'key' , default_value ) # Returns default_value if key not found # Check Existence - O(1) if 'key' in hash_map : # Key exists pass","title":"2\ufe0f\u20e3 Basic Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#common-hash-table-patterns","text":"","title":"\ud83c\udfaf Common Hash Table Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-counting-pattern","text":"def counting_pattern ( items ): counter = {} # Count occurrences for item in items : counter [ item ] = counter . get ( item , 0 ) + 1 return counter # Alternative using defaultdict from collections import defaultdict def counting_with_defaultdict ( items ): counter = defaultdict ( int ) for item in items : counter [ item ] += 1 return counter","title":"1\ufe0f\u20e3 Counting Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#2-grouping-pattern","text":"def grouping_pattern ( items , key_func ): groups = {} for item in items : key = key_func ( item ) if key not in groups : groups [ key ] = [] groups [ key ] . append ( item ) return groups # Alternative using defaultdict def grouping_with_defaultdict ( items , key_func ): groups = defaultdict ( list ) for item in items : groups [ key_func ( item )] . append ( item ) return groups","title":"2\ufe0f\u20e3 Grouping Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#3-cachingmemoization-pattern","text":"def memoization_pattern (): cache = {} def memoized_func ( arg ): if arg not in cache : cache [ arg ] = compute_value ( arg ) return cache [ arg ] return memoized_func # Alternative using @lru_cache from functools import lru_cache @lru_cache ( maxsize = None ) def cached_function ( arg ): return compute_value ( arg )","title":"3\ufe0f\u20e3 Caching/Memoization Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#4-two-sum-pattern","text":"def two_sum_pattern ( nums , target ): seen = {} # value -> index for i , num in enumerate ( nums ): complement = target - num if complement in seen : return [ seen [ complement ], i ] seen [ num ] = i return []","title":"4\ufe0f\u20e3 Two-Sum Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#advanced-techniques","text":"","title":"\ud83c\udfae Advanced Techniques"},{"location":"2.Interviews/b.%20technical%20interviews/#1-multi-level-dictionary","text":"# Creation multi_level = { 'level1' : { 'level2' : { 'level3' : 'value' } } } # Safe Navigation def safe_get ( dictionary , * keys , default = None ): current = dictionary for key in keys : if not isinstance ( current , dict ): return default current = current . get ( key , default ) return current","title":"1\ufe0f\u20e3 Multi-Level Dictionary"},{"location":"2.Interviews/b.%20technical%20interviews/#2-dictionary-comprehension","text":"# Basic comprehension squares = { x : x * x for x in range ( 5 )} # Conditional comprehension even_squares = { x : x * x for x in range ( 5 ) if x % 2 == 0 } # Transforming dictionaries transformed = { k : v * 2 for k , v in original . items ()}","title":"2\ufe0f\u20e3 Dictionary Comprehension"},{"location":"2.Interviews/b.%20technical%20interviews/#3-advanced-operations","text":"# Merging dictionaries dict3 = { ** dict1 , ** dict2 } # Python 3.5+ dict3 = dict1 | dict2 # Python 3.9+ # Get multiple values safely values = [ hash_map . get ( key ) for key in keys ] # Delete multiple keys for key in keys_to_delete : hash_map . pop ( key , None ) # Won't raise KeyError","title":"3\ufe0f\u20e3 Advanced Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#common-interview-problem-patterns","text":"Frequency Counter Problems Character frequency in strings Word frequency in sentences Element frequency in arrays Two-Sum Type Problems Finding pairs with target sum Finding triplets Subarray with given sum Caching Problems Implementing LRU cache Memoization problems Function results caching String Problems Anagram detection First non-repeating character String permutations","title":"\ud83d\udcdd Common Interview Problem Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#practice-problems_2","text":"Frequency Based Find the first non-repeating character in a string Find if two strings are anagrams Most frequent element in an array Lookup Based Implement two sum Group anagrams together Find all pairs with given difference Caching Based Implement LRU cache Design a file system cache Implement memoization decorator Advanced Problems Design a time-based key-value store Implement a data structure that supports insert, delete, getRandom in O(1) Design a logger rate limiter","title":"\ud83c\udfaf Practice Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#common-pitfalls-to-watch-for","text":"Mutability Issues Using mutable objects as dictionary keys Modifying dictionary while iterating Performance Traps Repeatedly accessing the same key Not using .get() for default values Unnecessary key existence checks Memory Issues Unbounded growth in caching problems Not clearing references in long-running applications Edge Cases Empty dictionaries Non-existent keys None values vs missing keys Remember: Hash tables provide O(1) average case operations but require good hash functions and collision handling strategies. In Python, this is handled automatically by the dictionary implementation.","title":"\u26a0\ufe0f Common Pitfalls to Watch For"},{"location":"2.Interviews/b.%20technical%20interviews/#heaps-for-technical-interviews","text":"","title":"\ud83c\udf33 Heaps for Technical Interviews"},{"location":"2.Interviews/b.%20technical%20interviews/#core-concepts","text":"","title":"\ud83d\udcda Core Concepts"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-a-heap","text":"\"\"\" A heap is a complete binary tree that satisfies the heap property: - Max Heap: Parent nodes are greater than or equal to children - Min Heap: Parent nodes are less than or equal to children - Python's heapq implements min heap \"\"\" # Key Properties: properties = { \"Complete Binary Tree\" : \"All levels filled except possibly last level\" , \"Heap Property\" : \"Parent-child relationship maintained throughout\" , \"Root\" : \"Smallest element (min heap) or largest element (max heap)\" , \"Implementation\" : \"Usually backed by an array/list\" , \"Height\" : \"O(log n) where n is number of nodes\" }","title":"What is a Heap?"},{"location":"2.Interviews/b.%20technical%20interviews/#parent-child-relationships-in-array-implementation","text":"def get_relationships ( i : int ) -> dict : return { 'parent' : ( i - 1 ) // 2 , # Parent index 'left_child' : 2 * i + 1 , # Left child index 'right_child' : 2 * i + 2 , # Right child index }","title":"Parent-Child Relationships in Array Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#basic-operations-using-heapq","text":"","title":"\ud83d\udd27 Basic Operations Using heapq"},{"location":"2.Interviews/b.%20technical%20interviews/#1-heap-creation","text":"import heapq # Method 1: Heapify existing list numbers = [ 3 , 1 , 4 , 1 , 5 , 9 , 2 , 6 , 5 , 3 , 5 ] heapq . heapify ( numbers ) # O(n) # Method 2: Create empty heap (just use list) heap = []","title":"1. Heap Creation"},{"location":"2.Interviews/b.%20technical%20interviews/#2-core-operations","text":"def heap_operations (): heap = [] # Push - O(log n) heapq . heappush ( heap , 5 ) # Pop - O(log n) smallest = heapq . heappop ( heap ) # Peek - O(1) if heap : smallest = heap [ 0 ] # Push and Pop combined - O(log n) smallest = heapq . heappushpop ( heap , 4 ) # Push then pop smallest = heapq . heapreplace ( heap , 4 ) # Pop then push","title":"2. Core Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#3-helper-functions","text":"def heap_helpers ( items ): # Find n smallest elements - O(n log k) n_smallest = heapq . nsmallest ( 3 , items ) # Find n largest elements - O(n log k) n_largest = heapq . nlargest ( 3 , items ) # Merge sorted iterables - O(n log k) merged = heapq . merge ([ 1 , 3 , 5 ], [ 2 , 4 , 6 ])","title":"3. Helper Functions"},{"location":"2.Interviews/b.%20technical%20interviews/#common-heap-patterns","text":"","title":"\ud83c\udfaf Common Heap Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-priority-queue-implementation","text":"from dataclasses import dataclass , field from typing import Any @dataclass ( order = True ) class PrioritizedItem : priority : int item : Any = field ( compare = False ) class PriorityQueue : def __init__ ( self ): self . _queue = [] def push ( self , item , priority ): heapq . heappush ( self . _queue , PrioritizedItem ( priority , item )) def pop ( self ): return heapq . heappop ( self . _queue ) . item def peek ( self ): return self . _queue [ 0 ] . item if self . _queue else None","title":"1. Priority Queue Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#2-k-way-merge-pattern","text":"def k_way_merge ( sorted_arrays ): \"\"\"Merge k sorted arrays using heap.\"\"\" merged = [] heap = [] # Initialize heap with first element from each array for i , arr in enumerate ( sorted_arrays ): if arr : heapq . heappush ( heap , ( arr [ 0 ], i , 0 )) while heap : val , array_index , elem_index = heapq . heappop ( heap ) merged . append ( val ) if elem_index + 1 < len ( sorted_arrays [ array_index ]): next_val = sorted_arrays [ array_index ][ elem_index + 1 ] heapq . heappush ( heap , ( next_val , array_index , elem_index + 1 )) return merged","title":"2. K-Way Merge Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#3-running-median-pattern","text":"class MedianFinder : def __init__ ( self ): self . small = [] # max heap (-ve numbers) self . large = [] # min heap def add_num ( self , num : int ) -> None : # Add to appropriate heap if len ( self . small ) == len ( self . large ): heapq . heappush ( self . large , - heapq . heappushpop ( self . small , - num )) else : heapq . heappush ( self . small , - heapq . heappushpop ( self . large , num )) def find_median ( self ) -> float : if len ( self . small ) == len ( self . large ): return ( - self . small [ 0 ] + self . large [ 0 ]) / 2.0 return float ( self . large [ 0 ])","title":"3. Running Median Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#common-interview-problems","text":"","title":"\ud83c\udfaf Common Interview Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#problem-types","text":"K-th Element Problems def find_kth_largest ( nums : List [ int ], k : int ) -> int : heap = [] for num in nums : heapq . heappush ( heap , num ) if len ( heap ) > k : heapq . heappop ( heap ) return heap [ 0 ] Merge Problems def merge_k_arrays ( arrays : List [ List [ int ]]) -> List [ int ]: return list ( heapq . merge ( * arrays )) Scheduling Problems def min_meeting_rooms ( intervals : List [ List [ int ]]) -> int : heap = [] # Track end times for start , end in sorted ( intervals ): if heap and heap [ 0 ] <= start : heapq . heapreplace ( heap , end ) else : heapq . heappush ( heap , end ) return len ( heap )","title":"Problem Types"},{"location":"2.Interviews/b.%20technical%20interviews/#edge-cases-to-consider","text":"def edge_cases_to_check (): \"\"\" 1. Empty heap operations 2. Single element heap 3. Duplicate elements 4. Negative numbers 5. Very large numbers 6. Equal priorities in priority queue \"\"\" pass","title":"\u26a0\ufe0f Edge Cases to Consider"},{"location":"2.Interviews/b.%20technical%20interviews/#time-complexity-summary","text":"complexities = { \"heapify\" : \"O(n)\" , \"push\" : \"O(log n)\" , \"pop\" : \"O(log n)\" , \"peek\" : \"O(1)\" , \"heappushpop\" : \"O(log n)\" , \"nlargest/nsmallest\" : \"O(n log k)\" , # where k is the count requested \"merge k sorted lists\" : \"O(n log k)\" # where k is number of lists }","title":"\ud83c\udfaf Time Complexity Summary"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips_1","text":"Use heap when: Need to find k largest/smallest elements Need to continuously find min/max Need to merge sorted sequences Implementing priority queue Python Heap Notes: heapq implements min heap For max heap, negate values No decrease-key operation Can't access arbitrary elements Solution Strategy: Identify if problem needs min or max heap Consider if heap is overkill (sorted list might work) Check if priority queue would be clearer Think about space complexity tradeoffs Remember: Always verify time/space complexity Consider edge cases Explain heap property while coding Mention alternative approaches","title":"\ud83d\udca1 Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#recursion-guide-for-technical-interviews","text":"","title":"\ud83d\udd04 Recursion Guide for Technical Interviews"},{"location":"2.Interviews/b.%20technical%20interviews/#core-concepts_1","text":"","title":"\ud83d\udcda Core Concepts"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-recursion","text":"\"\"\" Recursion is when a function calls itself either: 1. Directly: The function directly calls itself 2. Indirectly: Function A calls Function B which calls Function A Key Components: 1. Base Case (stopping condition) 2. Recursive Case (moving towards base case) \"\"\"","title":"What is Recursion?"},{"location":"2.Interviews/b.%20technical%20interviews/#key-elements-of-recursive-function","text":"def recursive_function ( input ): # 1. Base Case if input <= base_case : return base_value # 2. Recursive Case # - Must move towards base case # - Usually operates on smaller input return recursive_function ( smaller_input )","title":"Key Elements of Recursive Function"},{"location":"2.Interviews/b.%20technical%20interviews/#common-recursion-patterns","text":"","title":"\ud83c\udfaf Common Recursion Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-linear-recursion-pattern","text":"def linear_recursion ( n : int ) -> int : # Base case if n <= 0 : return base_value # Single recursive call return recursive_step ( linear_recursion ( n - 1 )) # Example: Factorial def factorial ( n : int ) -> int : if n <= 1 : # Base case return 1 return n * factorial ( n - 1 ) # Recursive case","title":"1. Linear Recursion Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#2-binary-recursion-pattern","text":"def binary_recursion ( data ): # Base case if base_condition ( data ): return base_value # Two recursive calls left = binary_recursion ( left_portion ( data )) right = binary_recursion ( right_portion ( data )) return combine ( left , right ) # Example: Binary Tree Traversal def traverse ( root ): if not root : return traverse ( root . left ) traverse ( root . right )","title":"2. Binary Recursion Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#3-tail-recursion-pattern","text":"def tail_recursion ( n , accumulator = initial_value ): # Base case if n <= 0 : return accumulator # Recursive call must be last operation return tail_recursion ( n - 1 , next_accumulator ) # Example: Tail Recursive Factorial def factorial_tail ( n : int , acc : int = 1 ) -> int : if n <= 1 : return acc return factorial_tail ( n - 1 , n * acc )","title":"3. Tail Recursion Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#4-nested-recursion-pattern","text":"def nested_recursion ( n ): # Base case if n <= 0 : return base_value # Recursive call within recursive call return nested_recursion ( nested_recursion ( n - 1 ))","title":"4. Nested Recursion Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#common-interview-problem-types","text":"","title":"\ud83d\udcdd Common Interview Problem Types"},{"location":"2.Interviews/b.%20technical%20interviews/#1-treegraph-problems","text":"def tree_traversal ( root ): # Base case if not root : return # Process current node process ( root ) # Recurse on children for child in root . children : tree_traversal ( child )","title":"1. Tree/Graph Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#2-stringarray-problems","text":"def is_palindrome ( s : str ) -> bool : # Base case: empty string or single char if len ( s ) <= 1 : return True # Check outermost chars and recurse on inner return s [ 0 ] == s [ - 1 ] and is_palindrome ( s [ 1 : - 1 ])","title":"2. String/Array Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#3-divide-and-conquer-problems","text":"def quick_sort ( arr : list ) -> list : # Base case if len ( arr ) <= 1 : return arr pivot = arr [ len ( arr ) // 2 ] left = [ x for x in arr if x < pivot ] middle = [ x for x in arr if x == pivot ] right = [ x for x in arr if x > pivot ] # Recursive case return quick_sort ( left ) + middle + quick_sort ( right )","title":"3. Divide and Conquer Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#common-pitfalls-solutions","text":"","title":"\u26a0\ufe0f Common Pitfalls &amp; Solutions"},{"location":"2.Interviews/b.%20technical%20interviews/#1-stack-overflow","text":"from sys import setrecursionlimit def handle_deep_recursion ( n : int ): # Increase recursion limit if needed setrecursionlimit ( 10000 ) # Default is 1000 # Or better: Convert to iteration def iterative_version (): stack = [] while stack : # Process iteratively pass","title":"1. Stack Overflow"},{"location":"2.Interviews/b.%20technical%20interviews/#2-redundant-computations","text":"def fibonacci_with_memo ( n : int , memo : dict = None ) -> int : if memo is None : memo = {} # Check memo before computing if n in memo : return memo [ n ] # Base cases if n <= 1 : return n # Store result in memo memo [ n ] = fibonacci_with_memo ( n - 1 , memo ) + fibonacci_with_memo ( n - 2 , memo ) return memo [ n ]","title":"2. Redundant Computations"},{"location":"2.Interviews/b.%20technical%20interviews/#3-not-moving-towards-base-case","text":"def ensure_progress ( n : int ) -> int : # Bad: Might never reach base case if n != 0 : return ensure_progress ( n ) # Good: Always moves towards base case if n <= 0 : return 0 return ensure_progress ( n - 1 )","title":"3. Not Moving Towards Base Case"},{"location":"2.Interviews/b.%20technical%20interviews/#timespace-complexity-analysis","text":"","title":"\ud83c\udfaf Time/Space Complexity Analysis"},{"location":"2.Interviews/b.%20technical%20interviews/#time-complexity-patterns","text":"complexities = { \"Linear Recursion\" : \"O(n) - Each call reduces n by 1\" , \"Binary Recursion\" : \"O(2^n) - Each call spawns 2 more calls\" , \"Divide & Conquer\" : \"O(n log n) - Divides problem in half each time\" , \"Tail Recursion\" : \"O(n) - Can be optimized by compiler\" , }","title":"Time Complexity Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#space-complexity-considerations","text":"space_usage = { \"Call Stack\" : \"Each recursive call adds a frame\" , \"Linear Recursion\" : \"O(n) stack space\" , \"Tail Recursion\" : \"O(1) with optimization\" , \"Tree Recursion\" : \"O(h) where h is tree height\" }","title":"Space Complexity Considerations"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips_2","text":"Always start with: Base case identification How to move towards base case Whether recursion makes sense Consider converting to iteration if: Deep recursion possible Space complexity is crucial Performance is critical Optimize using: Memoization for overlapping subproblems Tail recursion when possible Helper functions for additional parameters Be prepared to explain: Why recursion is appropriate Space/time complexity How to handle edge cases Remember: Clarity over cleverness Consider both recursive and iterative solutions Watch for stack overflow in large inputs Test with small examples first","title":"\ud83d\udca1 Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#backtracking-guide","text":"","title":"\u267b\ufe0f Backtracking Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#core-properties","text":"","title":"\ud83d\udcda Core Properties"},{"location":"2.Interviews/b.%20technical%20interviews/#1-property-1-no-repetition-and-completion","text":"\"\"\" Backtracking is a systematic method that: 1. Avoids repetitions 2. Doesn't miss any possible solutions 3. Builds solutions incrementally 4. Returns to previous states (\"backtracks\") Ideal for: - Combinatorial problems (permutations, combinations) - Enumeration problems - Path finding in graphs \"\"\"","title":"1\ufe0f\u20e3 Property 1: No Repetition and Completion"},{"location":"2.Interviews/b.%20technical%20interviews/#2-property-2-search-pruning","text":"\"\"\" During solution building: 1. Evaluates partial solutions 2. Prunes branches that can't lead to valid solutions 3. Skips invalid configurations 4. Abandons paths worse than known solutions Ideal for: - Constraint satisfaction problems (CSP) - Optimization problems - Game-playing scenarios \"\"\"","title":"2\ufe0f\u20e3 Property 2: Search Pruning"},{"location":"2.Interviews/b.%20technical%20interviews/#implementation-patterns","text":"","title":"\ud83c\udfaf Implementation Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-two-pass-pattern","text":"def backtrack_pattern ( input_data ): def dfs ( curr_state ): # Forward Pass: Build solution incrementally for choice in get_valid_choices ( curr_state ): # 1. Make choice apply_choice ( curr_state , choice ) # 2. Recurse dfs ( curr_state ) # Backward Pass: Reset state undo_choice ( curr_state , choice ) initial_state = create_initial_state () dfs ( initial_state )","title":"1. Two-Pass Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#best-used-when","text":"State Modification Required # Example: N-Queens Problem def solve_n_queens ( n ): def dfs ( board , row ): # Forward: Place queen board [ row ][ col ] = 'Q' solve_further ( board , row + 1 ) # Backward: Remove queen board [ row ][ col ] = '.' Grid/Matrix Problems # Example: Maze Solving def solve_maze ( maze ): def dfs ( x , y ): # Forward: Mark path maze [ x ][ y ] = 'PATH' explore_neighbors ( x , y ) # Backward: Unmark if dead end maze [ x ][ y ] = 'EMPTY' Graph Problems with State Changes # Example: Graph Coloring def color_graph ( graph ): def dfs ( node , colors ): # Forward: Color node node . color = next_color color_neighbors ( node ) # Backward: Reset if invalid node . color = None","title":"Best Used When:"},{"location":"2.Interviews/b.%20technical%20interviews/#characteristics","text":"Need to maintain and restore state Solutions built by modifying shared state Requires explicit cleanup Common in problems with global constraints","title":"Characteristics:"},{"location":"2.Interviews/b.%20technical%20interviews/#2-state-tracking-pattern","text":"def state_tracking_pattern (): used = set () # or list/array for tracking used elements curr = [] # current partial solution def dfs ( state ): if is_complete ( state ): record_solution ( curr [:]) return for choice in get_choices ( state ): if choice not in used : # Forward pass used . add ( choice ) curr . append ( choice ) dfs ( next_state ( state , choice )) # Backward pass used . remove ( choice ) curr . pop ()","title":"2. State Tracking Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#best-used-when_1","text":"Building Combinations/Permutations # Example: Generate Subsets def subsets ( nums ): result = [] curr = [] def dfs ( start ): result . append ( curr [:]) for i in range ( start , len ( nums )): curr . append ( nums [ i ]) dfs ( i + 1 ) curr . pop () Building Sequences # Example: Phone Number Letter Combinations def letter_combinations ( digits ): curr = [] def dfs ( index ): if len ( curr ) == len ( digits ): result . append ( '' . join ( curr )) return for letter in mapping [ digits [ index ]]: curr . append ( letter ) dfs ( index + 1 ) curr . pop () Path Finding Without State Modification # Example: All Paths from Source to Target def all_paths ( graph ): curr_path = [] def dfs ( node ): curr_path . append ( node ) dfs ( next_node ) curr_path . pop ()","title":"Best Used When:"},{"location":"2.Interviews/b.%20technical%20interviews/#characteristics_1","text":"Solutions built by tracking sequences No need for explicit state restoration Usually involves collecting multiple solutions Common in combinatorial problems","title":"Characteristics:"},{"location":"2.Interviews/b.%20technical%20interviews/#decision-making-guide","text":"","title":"\ud83c\udfaf Decision Making Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#use-two-pass-pattern-when","text":"Working with: Board games (Chess, N-Queens) Maze problems Grid-based problems Graph coloring State modification required Need to: Modify and restore shared state Handle complex constraints Work with matrix/grid structures Deal with global state","title":"Use Two-Pass Pattern When:"},{"location":"2.Interviews/b.%20technical%20interviews/#use-state-tracking-pattern-when","text":"Working with: Combinations/Permutations String building problems Subset generation Path finding without modification Sequence generation Need to: Build multiple solutions Generate all possible arrangements Work with independent states Create combinations or selections","title":"Use State Tracking Pattern When:"},{"location":"2.Interviews/b.%20technical%20interviews/#hybrid-approach-examples","text":"Sometimes you might need to combine both patterns: def hybrid_backtracking (): curr_path = [] # State Tracking board = [[ 0 ] * N for _ in range ( N )] # Two-Pass State def dfs ( row , col ): # State Tracking: Build path curr_path . append (( row , col )) # Two-Pass: Modify board board [ row ][ col ] = 'VISITED' # Recurse explore_neighbors ( row , col ) # Two-Pass: Restore board board [ row ][ col ] = 'EMPTY' # State Tracking: Remove from path curr_path . pop ()","title":"\ud83c\udfae Hybrid Approach Examples"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-hybrid","text":"Complex game scenarios Path finding with state constraints Problems requiring both solution building and state modification Problems with both global and local constraints Remember: Consider state management needs Think about solution collection requirements Evaluate constraint checking needs Consider readability and maintainability","title":"When to Use Hybrid:"},{"location":"2.Interviews/b.%20technical%20interviews/#common-problem-types","text":"","title":"\ud83c\udfae Common Problem Types"},{"location":"2.Interviews/b.%20technical%20interviews/#1-permutation-problems","text":"def permute ( nums : List [ int ]) -> List [ List [ int ]]: def backtrack ( curr : List [ int ], used : Set [ int ]): # Base case: complete permutation if len ( curr ) == len ( nums ): result . append ( curr [:]) return # Try each unused number for i in range ( len ( nums )): # Skip used numbers if i in used : continue # Forward pass used . add ( i ) curr . append ( nums [ i ]) backtrack ( curr , used ) # Backward pass used . remove ( i ) curr . pop () result = [] backtrack ([], set ()) return result","title":"1. Permutation Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#2-unique-permutations-with-duplicates","text":"def permuteUnique ( nums : List [ int ]) -> List [ List [ int ]]: def backtrack ( curr : List [ int ], counter : Dict [ int , int ]): if len ( curr ) == len ( nums ): result . append ( curr [:]) return # Use counter to handle duplicates for num in counter : if counter [ num ] > 0 : curr . append ( num ) counter [ num ] -= 1 backtrack ( curr , counter ) curr . pop () counter [ num ] += 1 result = [] counter = Counter ( nums ) backtrack ([], counter ) return result","title":"2. Unique Permutations (With Duplicates)"},{"location":"2.Interviews/b.%20technical%20interviews/#3-constraint-satisfaction-problems","text":"def solve_csp ( constraints ): def is_valid_state ( state ): return all ( constraint ( state ) for constraint in constraints ) def backtrack ( state ): if is_complete ( state ): return is_valid_state ( state ) for value in get_possible_values ( state ): if is_valid_partial ( state , value ): apply_value ( state , value ) if backtrack ( state ): return True undo_value ( state , value ) return False","title":"3. Constraint Satisfaction Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#time-complexity-analysis","text":"complexity_notes = { \"Permutations\" : { \"Time\" : \"O(n!)\" , \"Space\" : \"O(n) for recursion stack\" , \"Note\" : \"Visits each state exactly once\" }, \"Combinations\" : { \"Time\" : \"O(2^n)\" , \"Space\" : \"O(n) for recursion stack\" , \"Note\" : \"Each element has two choices\" }, \"CSP Problems\" : { \"Time\" : \"O(d^n) where d is domain size\" , \"Space\" : \"O(n) for recursion stack\" , \"Note\" : \"Pruning can significantly improve average case\" } }","title":"\ud83c\udfaf Time Complexity Analysis"},{"location":"2.Interviews/b.%20technical%20interviews/#optimization-techniques","text":"","title":"\ud83d\udca1 Optimization Techniques"},{"location":"2.Interviews/b.%20technical%20interviews/#1-early-pruning","text":"def optimized_backtrack ( state ): # Check constraints early if not is_valid_partial ( state ): return False if is_complete ( state ): return True for choice in sorted_choices ( state ): # Sort choices for better pruning if is_promising ( state , choice ): apply_choice ( state , choice ) if optimized_backtrack ( state ): return True undo_choice ( state , choice )","title":"1. Early Pruning"},{"location":"2.Interviews/b.%20technical%20interviews/#2-state-duplication","text":"def backtrack_with_dedup ( nums : List [ int ]) -> List [ List [ int ]]: def backtrack ( start : int , curr : List [ int ]): result . append ( curr [:]) used = set () # Track used numbers at this level for i in range ( start , len ( nums )): if nums [ i ] in used : # Skip duplicates at same level continue used . add ( nums [ i ]) curr . append ( nums [ i ]) backtrack ( i + 1 , curr ) curr . pop ()","title":"2. State Duplication"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips_3","text":"Implementation Strategy: Always use DFS for backtracking Identify state representation clearly Track partial solutions carefully Optimization Strategy: Look for early pruning opportunities Consider sorting input for better pruning Use sets/counters for duplicate handling Problem Solving Steps: Identify what makes a valid solution Determine how to build solutions incrementally Define clear base cases Plan state tracking strategy Testing Strategy: Start with small inputs Test with duplicates if relevant Verify all solutions are found Check for invalid inputs Remember: Backtracking = Choices + Consequences Think in terms of state and state changes Always handle cleanup in backward pass Consider space complexity of solution storage","title":"\ud83d\udca1 Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#binary-trees-guide","text":"","title":"\ud83c\udf33 Binary Trees Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#core-implementation","text":"","title":"\ud83d\udcda Core Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#basic-tree-node","text":"class TreeNode : def __init__ ( self , val = 0 , left = None , right = None ): self . val = val self . left = left self . right = right","title":"Basic Tree Node"},{"location":"2.Interviews/b.%20technical%20interviews/#common-tree-building-patterns","text":"def build_tree_examples (): # Simple Tree root = TreeNode ( 1 ) root . left = TreeNode ( 2 ) root . right = TreeNode ( 3 ) # From List def from_list ( nums : List [ int ], index : int = 0 ) -> TreeNode : if index >= len ( nums ) or nums [ index ] is None : return None root = TreeNode ( nums [ index ]) root . left = from_list ( nums , 2 * index + 1 ) root . right = from_list ( nums , 2 * index + 2 ) return root","title":"Common Tree Building Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#core-traversal-patterns","text":"","title":"\ud83c\udfaf Core Traversal Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-dfs-patterns","text":"class DFSPatterns : def inorder ( self , root : TreeNode ) -> List [ int ]: # Left -> Root -> Right def dfs ( node ): if not node : return dfs ( node . left ) # Process left result . append ( node . val ) # Process root dfs ( node . right ) # Process right result = [] dfs ( root ) return result def preorder ( self , root : TreeNode ) -> List [ int ]: # Root -> Left -> Right def dfs ( node ): if not node : return result . append ( node . val ) # Process root dfs ( node . left ) # Process left dfs ( node . right ) # Process right result = [] dfs ( root ) return result def postorder ( self , root : TreeNode ) -> List [ int ]: # Left -> Right -> Root def dfs ( node ): if not node : return dfs ( node . left ) # Process left dfs ( node . right ) # Process right result . append ( node . val ) # Process root result = [] dfs ( root ) return result","title":"1. DFS Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#2-bfs-pattern","text":"from collections import deque def level_order ( root : TreeNode ) -> List [ List [ int ]]: if not root : return [] result = [] queue = deque ([ root ]) while queue : level_size = len ( queue ) current_level = [] for _ in range ( level_size ): node = queue . popleft () current_level . append ( node . val ) if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) result . append ( current_level ) return result","title":"2. BFS Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#common-problem-patterns","text":"","title":"\ud83c\udfae Common Problem Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-path-problems-pattern","text":"def path_pattern ( root : TreeNode ): def dfs ( node , path , target ): if not node : return # Add current node to path path . append ( node . val ) # Check if leaf node if not node . left and not node . right : process_path ( path ) # Process complete path # Recurse on children dfs ( node . left , path , target ) dfs ( node . right , path , target ) # Backtrack path . pop ()","title":"1. Path Problems Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#2-binary-search-tree-pattern","text":"def bst_pattern ( root : TreeNode ): def validate_bst ( node , min_val = float ( '-inf' ), max_val = float ( 'inf' )): if not node : return True # Check BST property if node . val <= min_val or node . val >= max_val : return False # Recurse with updated bounds return ( validate_bst ( node . left , min_val , node . val ) and validate_bst ( node . right , node . val , max_val ))","title":"2. Binary Search Tree Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#3-lowest-common-ancestor","text":"def lca_pattern ( root : TreeNode , p : TreeNode , q : TreeNode ): def find_lca ( node ): if not node or node == p or node == q : return node # Search in left and right subtrees left = find_lca ( node . left ) right = find_lca ( node . right ) # If found in both subtrees, current node is LCA if left and right : return node # Return non-null node return left or right","title":"3. Lowest Common Ancestor"},{"location":"2.Interviews/b.%20technical%20interviews/#4-view-problems-pattern","text":"def tree_view_pattern ( root : TreeNode ): def right_view ( root ): result = [] def dfs ( node , level ): if not node : return # First node of this level from right if len ( result ) == level : result . append ( node . val ) # Visit right first for right view dfs ( node . right , level + 1 ) dfs ( node . left , level + 1 ) dfs ( root , 0 ) return result","title":"4. View Problems Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#pattern-recognition-guide","text":"","title":"\ud83c\udfaf Pattern Recognition Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-each-pattern","text":"Use DFS When: Need to process nodes in a specific order Working with paths from root to leaf Validating tree properties Computing tree properties recursively Use BFS When: Need level-by-level processing Finding shortest paths Working with tree width Level-based operations Use Path Patterns When: Need complete paths from root to leaf Summing paths Finding specific paths Path validation Use BST Patterns When: Searching for values Validating BST properties Range-based operations Maintaining sorted order","title":"When to Use Each Pattern:"},{"location":"2.Interviews/b.%20technical%20interviews/#problem-solving-strategy","text":"Identify Pattern Type: Is it path-based? Is it level-based? Does it involve BST properties? Is order important? Choose Traversal Method: patterns = { \"Need Path\" : \"DFS with path tracking\" , \"Level Operations\" : \"BFS with queue\" , \"Specific Order\" : \"Choose appropriate DFS order\" , \"BST Operations\" : \"Use BST properties\" } Consider Edge Cases edge_cases = [ \"Empty tree\" , \"Single node\" , \"All nodes same value\" , \"Unbalanced tree\" , \"Complete binary tree\" ] Time/Space Complexity complexities = { \"DFS\" : \"Time: O(n), Space: O(h)\" , \"BFS\" : \"Time: O(n), Space: O(w)\" , \"Path\" : \"Time: O(n), Space: O(h)\" , \"BST\" : \"Time: O(h), Space: O(1) typical\" } # where n = nodes, h = height, w = max width Remember: Start with traversal pattern identification Consider whether order matters Check if BST properties help Handle edge cases explicitly","title":"\ud83d\udca1 Problem-Solving Strategy"},{"location":"2.Interviews/b.%20technical%20interviews/#tries-prefix-trees","text":"","title":"\ud83c\udf32 Tries (Prefix Trees)"},{"location":"2.Interviews/b.%20technical%20interviews/#core-implementation_1","text":"","title":"\ud83d\udcda Core Implementation"},{"location":"2.Interviews/b.%20technical%20interviews/#basic-trie-node","text":"class TrieNode : def __init__ ( self ): self . children = {} # or [None] * 26 for fixed alphabet self . is_end = False # Marks end of word","title":"Basic Trie Node"},{"location":"2.Interviews/b.%20technical%20interviews/#basic-trie-structure","text":"class Trie : def __init__ ( self ): self . root = TrieNode () def insert ( self , word : str ) -> None : node = self . root for char in word : if char not in node . children : node . children [ char ] = TrieNode () node = node . children [ char ] node . is_end = True def search ( self , word : str ) -> bool : node = self . root for char in word : if char not in node . children : return False node = node . children [ char ] return node . is_end def starts_with ( self , prefix : str ) -> bool : node = self . root for char in prefix : if char not in node . children : return False node = node . children [ char ] return True","title":"Basic Trie Structure"},{"location":"2.Interviews/b.%20technical%20interviews/#common-patterns","text":"","title":"\ud83c\udfaf Common Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-word-dictionary-pattern","text":"class WordDictionary : def __init__ ( self ): self . root = TrieNode () def insert ( self , word : str ) -> None : node = self . root for char in word : if char not in node . children : node . children [ char ] = TrieNode () node = node . children [ char ] node . is_end = True def search_with_wildcard ( self , word : str ) -> bool : def dfs ( node , i ): if i == len ( word ): return node . is_end if word [ i ] == '.' : for child in node . children . values (): if child and dfs ( child , i + 1 ): return True return False if word [ i ] not in node . children : return False return dfs ( node . children [ word [ i ]], i + 1 ) return dfs ( self . root , 0 )","title":"1. Word Dictionary Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#2-prefix-matching-pattern","text":"def prefix_matching_pattern (): class AutocompleteSystem : def __init__ ( self , words : List [ str ], times : List [ int ]): self . root = TrieNode () self . prefix = \"\" # Insert words with frequencies for word , count in zip ( words , times ): self . _insert ( word , count ) def _insert ( self , word : str , count : int ) -> None : node = self . root for char in word : if char not in node . children : node . children [ char ] = TrieNode () node = node . children [ char ] node . counts [ word ] = count def input ( self , c : str ) -> List [ str ]: if c == '#' : self . _insert ( self . prefix , 1 ) self . prefix = \"\" return [] self . prefix += c node = self . root # Find node for current prefix for char in self . prefix : if char not in node . children : return [] node = node . children [ char ] # Get top 3 suggestions return sorted ( node . counts . items (), key = lambda x : ( - x [ 1 ], x [ 0 ]))[: 3 ]","title":"2. Prefix Matching Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#3-word-square-pattern","text":"def word_square_pattern ( words : List [ str ]) -> List [ List [ str ]]: trie = Trie () n = len ( words [ 0 ]) # Build prefix map prefix_map = defaultdict ( list ) for i , word in enumerate ( words ): for j in range ( len ( word ) + 1 ): prefix_map [ word [: j ]] . append ( i ) def get_words_with_prefix ( prefix ): return [ words [ i ] for i in prefix_map [ prefix ]] def backtrack ( square ): if len ( square ) == n : result . append ( square [:]) return # Get prefix for next word pos = len ( square ) prefix = '' . join ( word [ pos ] for word in square ) # Try all words with this prefix for word in get_words_with_prefix ( prefix ): square . append ( word ) backtrack ( square ) square . pop () result = [] backtrack ([]) return result","title":"3. Word Square Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#timespace-complexity","text":"complexities = { \"Insert\" : { \"Time\" : \"O(m) where m is word length\" , \"Space\" : \"O(m)\" }, \"Search\" : { \"Time\" : \"O(m)\" , \"Space\" : \"O(1)\" }, \"StartsWith\" : { \"Time\" : \"O(m)\" , \"Space\" : \"O(1)\" }, \"Space Usage\" : \"O(ALPHABET_SIZE * m * n) for n words\" }","title":"\ud83c\udfaf Time/Space Complexity"},{"location":"2.Interviews/b.%20technical%20interviews/#key-advantagesdisadvantages","text":"","title":"\ud83d\udd11 Key Advantages/Disadvantages"},{"location":"2.Interviews/b.%20technical%20interviews/#advantages","text":"advantages = [ \"Fast prefix lookups O(m)\" , \"Space-efficient for common prefixes\" , \"No need for hash function\" , \"No collisions to handle\" , \"Natural for autocomplete/spellcheck\" ]","title":"Advantages:"},{"location":"2.Interviews/b.%20technical%20interviews/#disadvantages","text":"disadvantages = [ \"Memory intensive (many null pointers)\" , \"Slower than hash table for exact lookups\" , \"Complex to implement/maintain\" , \"Not cache-friendly due to pointer chasing\" ]","title":"Disadvantages"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-tries","text":"use_cases = { \"Autocomplete\" : \"Search suggestions\" , \"Spell Checker\" : \"Word validation\" , \"IP Routing\" : \"Prefix matching\" , \"Word Games\" : \"Word validation/search\" , \"Contact List\" : \"Type-ahead search\" }","title":"\ud83d\udca1 When to Use Tries"},{"location":"2.Interviews/b.%20technical%20interviews/#common-pitfalls","text":"Memory Management def avoid_memory_issues (): \"\"\" - Consider using array instead of map for fixed alphabet - Clean up unused nodes - Use compressed tries for long strings \"\"\" pass Implementation Choices def implementation_tips (): \"\"\" - Choose appropriate children structure (array vs map based on alphabet size) - Decide on case sensitivity handling - Plan wildcard character handling \"\"\" pass","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"2.Interviews/b.%20technical%20interviews/#practice-problem-types","text":"Basic Operations Implement insert/search/startsWith Handle wildcards Case-sensitive operations Word Problems Word search Word squares Word break Replace words Prefix Problems Autocomplete Longest common prefix Unique prefixes Remember: Consider memory-space tradeoffs Handle edge cases (empty strings, special chars) Think about prefix sharing opportunities Consider case sensitivity requirements","title":"\ud83c\udfaf Practice Problem Types"},{"location":"2.Interviews/b.%20technical%20interviews/#binary-search-guide","text":"","title":"\ud83d\udd0d Binary Search Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#core-template","text":"","title":"\ud83d\udcda Core Template"},{"location":"2.Interviews/b.%20technical%20interviews/#most-generalized-binary-search-template","text":"def binary_search ( array ) -> int : def condition ( value ) -> bool : # Customize condition here pass left , right = min ( search_space ), max ( search_space ) while left < right : mid = left + ( right - left ) // 2 if condition ( mid ): right = mid else : left = mid + 1 return left # Key Points: # 1. Initialize boundaries to include ALL possible answers # 2. Condition function defines search criteria # 3. Returns minimum k where condition(k) is True","title":"Most Generalized Binary Search Template"},{"location":"2.Interviews/b.%20technical%20interviews/#three-key-components","text":"","title":"\ud83c\udfaf Three Key Components"},{"location":"2.Interviews/b.%20technical%20interviews/#1-boundary-initialization","text":"def initialize_boundaries (): \"\"\" Rules for setting left and right: 1. Must include all possible answers 2. Common patterns: - [0, len(array)] # For index search - [min(array), max(array)] # For value search - [1, max_possible] # For minimum/maximum problems \"\"\" # Example bounds for different scenarios bounds = { \"Index Search\" : ( 0 , len ( array )), \"Value Search\" : ( min ( array ), max ( array )), \"Minimum Search\" : ( 1 , max_value ), \"Maximum Search\" : ( min_value , sum ( array )) }","title":"1. Boundary Initialization"},{"location":"2.Interviews/b.%20technical%20interviews/#2-condition-function-design","text":"def design_condition (): \"\"\" Patterns for condition functions: 1. Direct Comparison: array[mid] >= target 2. Feasibility Check: can_achieve(mid) 3. Counting: count_less_equal(mid) >= k 4. Validation: is_valid_solution(mid) \"\"\" # Example condition patterns conditions = { \"Finding Target\" : lambda mid : array [ mid ] >= target , \"Feasibility\" : lambda mid : can_do_task_with_value ( mid ), \"Counting\" : lambda mid : count_elements_less_than ( mid ) >= k , \"Validation\" : lambda mid : validates_constraint ( mid ) }","title":"2. Condition Function Design"},{"location":"2.Interviews/b.%20technical%20interviews/#3-return-value-selection","text":"def choose_return (): \"\"\" Return value patterns: 1. left: Minimum value satisfying condition 2. left - 1: Maximum value not satisfying condition 3. right: Alternative minimum value 4. Special handling for not found cases \"\"\" return_patterns = { \"Minimum Satisfying\" : \"return left\" , \"Maximum Not Satisfying\" : \"return left - 1\" , \"Not Found\" : \"return -1 if not found\" }","title":"3. Return Value Selection"},{"location":"2.Interviews/b.%20technical%20interviews/#common-problem-patterns_1","text":"","title":"\ud83c\udfae Common Problem Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-classical-binary-search","text":"def classical_search ( nums : List [ int ], target : int ) -> int : left , right = 0 , len ( nums ) while left < right : mid = left + ( right - left ) // 2 if nums [ mid ] >= target : right = mid else : left = mid + 1 return left if left < len ( nums ) and nums [ left ] == target else - 1","title":"1. Classical Binary Search"},{"location":"2.Interviews/b.%20technical%20interviews/#2-minimum-value-search","text":"def find_minimum ( nums : List [ int ]) -> int : def feasible ( value ) -> bool : # Define feasibility condition total = 0 for num in nums : if condition ( num , value ): total += 1 return total >= required left , right = min_possible , max_possible while left < right : mid = left + ( right - left ) // 2 if feasible ( mid ): right = mid else : left = mid + 1 return left","title":"2. Minimum Value Search"},{"location":"2.Interviews/b.%20technical%20interviews/#3-maximum-value-search","text":"def find_maximum ( nums : List [ int ]) -> int : def feasible ( value ) -> bool : # Define feasibility condition return can_achieve_with_value ( value ) left , right = min_possible , max_possible while left < right : mid = left + ( right - left + 1 ) // 2 # Note: Different mid calculation if feasible ( mid ): left = mid else : right = mid - 1 return left","title":"3. Maximum Value Search"},{"location":"2.Interviews/b.%20technical%20interviews/#pattern-recognition-guide_1","text":"","title":"\ud83c\udfaf Pattern Recognition Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-binary-search","text":"binary_search_indicators = { \"Sorted Array\" : \"Direct binary search possible\" , \"Monotonic Condition\" : \"Can use binary search on answer space\" , \"Min/Max Optimization\" : \"Likely binary search on result\" , \"Feasibility Check\" : \"Can binary search with validation\" , \"Counting Problems\" : \"Binary search possible if monotonic\" }","title":"When to Use Binary Search:"},{"location":"2.Interviews/b.%20technical%20interviews/#problem-type-recognition","text":"def identify_pattern ( problem ): patterns = { \"Find Exact Value\" : \"Classical binary search\" , \"Find Minimum Satisfying\" : \"Minimum value pattern\" , \"Find Maximum Possible\" : \"Maximum value pattern\" , \"Optimization with Constraint\" : \"Feasibility pattern\" , \"Counting with Condition\" : \"Counting pattern\" }","title":"Problem Type Recognition"},{"location":"2.Interviews/b.%20technical%20interviews/#common-pitfalls_1","text":"Boundary Issues def avoid_boundary_issues (): \"\"\" Common pitfalls: 1. Off-by-one errors in boundaries 2. Not including all possible answers 3. Infinite loops due to improper mid calculation 4. Not handling edge cases \"\"\" pass Condition Design def condition_pitfalls (): \"\"\" Watch out for: 1. Non-monotonic conditions 2. Incorrect comparison operators 3. Missing edge cases in condition 4. Overcomplicated condition logic \"\"\" pass","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"2.Interviews/b.%20technical%20interviews/#implementation-tips","text":"Always use left + (right - left) // 2 to avoid overflow Consider whether to include end points Test with small examples first Verify monotonicity of condition Handle edge cases explicitly Remember: Think in terms of answer space vs index space Verify condition function monotonicity Consider boundary cases carefully Test with small inputs first","title":"\ud83d\udca1 Implementation Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#greedy-algorithms","text":"","title":"\ud83e\ude99 Greedy Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#core-properties_1","text":"","title":"\ud83d\udcda Core Properties"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-a-greedy-algorithm","text":"A greedy algorithm makes the locally optimal choice at each step, hoping to find a global optimum. While simple and intuitive, they don't always yield the optimal solution but often provide efficient solutions for optimization problems.","title":"What is a Greedy Algorithm?"},{"location":"2.Interviews/b.%20technical%20interviews/#key-properties","text":"properties = { \"Local Optimal Choice\" : \"Best choice at current step\" , \"Hope\" : \"Local optimum leads to global optimum\" , \"No Backtracking\" : \"Decisions are final\" , \"Simple Implementation\" : \"Usually straightforward code\" }","title":"Key Properties"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-greedy-algorithms","text":"","title":"\ud83c\udfaf When to Use Greedy Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#criteria-for-greedy-approach","text":"def is_greedy_applicable ( problem ): criteria = { \"Greedy Choice Property\" : \"\"\"Local optimal choices lead to global optimal solution\"\"\" , \"Optimal Substructure\" : \"\"\"Optimal solution contains optimal solutions to subproblems\"\"\" , \"No Future Impact\" : \"Current choice doesn't affect future choices\" , \"Simple Constraints\" : \"Problem has straightforward constraints\" } return all ( criteria . values ())","title":"Criteria for Greedy Approach"},{"location":"2.Interviews/b.%20technical%20interviews/#common-greedy-patterns","text":"","title":"\ud83c\udfae Common Greedy Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-activity-selection-pattern","text":"def activity_selection ( start : List [ int ], finish : List [ int ]) -> List [ int ]: # Sort activities by finish time activities = sorted ( zip ( start , finish ), key = lambda x : x [ 1 ]) selected = [ activities [ 0 ]] last_finish = activities [ 0 ][ 1 ] for start_time , finish_time in activities [ 1 :]: if start_time >= last_finish : selected . append (( start_time , finish_time )) last_finish = finish_time return selected","title":"1. Activity Selection Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#2-fractional-knapsack-problem","text":"def fractional_knapsack ( values : List [ int ], weights : List [ int ], capacity : int ) -> float : # Calculate value/weight ratio items = sorted ( zip ( values , weights ), key = lambda x : x [ 0 ] / x [ 1 ], reverse = True ) total_value = 0 for value , weight in items : if capacity >= weight : # Take whole item capacity -= weight total_value += value else : # Take fraction of item total_value += value * ( capacity / weight ) break return total_value","title":"2. Fractional Knapsack Problem"},{"location":"2.Interviews/b.%20technical%20interviews/#3-meeting-rooms-pattern","text":"def min_meeting_rooms ( intervals : List [ List [ int ]]) -> int : if not intervals : return 0 # Separate start and end times starts = sorted ([ i [ 0 ] for i in intervals ]) ends = sorted ([ i [ 1 ] for i in intervals ]) rooms = 0 max_rooms = 0 s = e = 0 while s < len ( intervals ): if starts [ s ] < ends [ e ]: rooms += 1 s += 1 else : rooms -= 1 e += 1 max_rooms = max ( max_rooms , rooms ) return max_rooms","title":"3. Meeting Rooms Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#4-coin-change-greedy-pattern","text":"def coin_change_greedy ( amount : int , coins : List [ int ]) -> int : coins . sort ( reverse = True ) # Sort coins in descending order count = 0 for coin in coins : while amount >= coin : amount -= coin count += 1 return count if amount == 0 else - 1","title":"4. Coin Change (Greedy Pattern)"},{"location":"2.Interviews/b.%20technical%20interviews/#universal-greedy-patterns","text":"","title":"\ud83d\udd04 Universal Greedy Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-sorting-first-pattern","text":"def sorting_first_pattern ( items , key_function = None ): \"\"\" Universal pattern for problems requiring initial sorting. Common in: Activity selection, Job scheduling, Meeting rooms \"\"\" # 1. Sort based on key metric sorted_items = sorted ( items , key = key_function ) if key_function else sorted ( items ) result = [] current = sorted_items [ 0 ] # Track current selection # 2. Process items in sorted order for item in sorted_items [ 1 :]: if satisfies_constraint ( current , item ): # 3. Make greedy choice result . append ( current ) current = item result . append ( current ) # Don't forget last item return result # Example Usage: Activity Selection def activity_selection ( activities ): return sorting_first_pattern ( activities , key_function = lambda x : x [ 1 ] # Sort by finish time ) # Example Usage: Meeting Rooms def meeting_rooms ( meetings ): return sorting_first_pattern ( meetings , key_function = lambda x : x [ 0 ] # Sort by start time )","title":"1. Sorting-First Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#2-fraction-ratepattern","text":"def fraction_pattern ( items , constraint , get_value , get_weight ): \"\"\" Universal pattern for fractional optimization problems. Common in: Knapsack, Task scheduling with efficiency \"\"\" # 1. Calculate rates and sort rates = [( get_value ( item ) / get_weight ( item ), item ) for item in items ] rates . sort ( reverse = True ) result = [] total_value = 0 remaining = constraint # 2. Process items by rate for rate , item in rates : weight = get_weight ( item ) if remaining >= weight : # Take whole item result . append (( item , 1.0 )) total_value += get_value ( item ) remaining -= weight else : # Take fraction fraction = remaining / weight result . append (( item , fraction )) total_value += get_value ( item ) * fraction break return result , total_value # Example Usage: Fractional Knapsack def fractional_knapsack ( items , capacity ): return fraction_pattern ( items , capacity , get_value = lambda x : x . value , get_weight = lambda x : x . weight )","title":"2. Fraction Rate/Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#3-running-window-pattern","text":"def running_window_pattern ( items , constraint ): \"\"\" Universal pattern for running window problems. Common in: Meeting rooms, Task scheduling, Resource allocation \"\"\" # 1. Separate start and end events events = [] for start , end in items : events . append (( start , 1 )) # 1 for start events . append (( end , - 1 )) # -1 for end # 2. Sort events events . sort () current = 0 max_needed = 0 # 3. Process events in order for time , change in events : current += change max_needed = max ( max_needed , current ) if max_needed > constraint : return False return True # Example Usage: Meeting Rooms def can_schedule_meetings ( meetings , available_rooms ): return running_window_pattern ( meetings , available_rooms )","title":"3. Running Window Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#4-local-exchange-pattern","text":"def local_exchange_pattern ( items ): \"\"\" Universal pattern for local optimization problems. Common in: Job scheduling, Task optimization \"\"\" result = list ( items ) # Create mutable copy made_change = True while made_change : made_change = False for i in range ( len ( result ) - 1 ): # Compare adjacent items if better_exchange ( result [ i ], result [ i + 1 ]): result [ i ], result [ i + 1 ] = result [ i + 1 ], result [ i ] made_change = True return result # Example Usage: Job Sequencing def job_sequencing ( jobs ): def better_exchange ( job1 , job2 ): return ( job1 . profit / job1 . deadline < job2 . profit / job2 . deadline ) return local_exchange_pattern ( jobs )","title":"4. Local Exchange Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#5-priority-queue-pattern","text":"from heapq import heappush , heappop def priority_queue_pattern ( items , k ): \"\"\" Universal pattern for k-selection problems. Common in: K closest points, Top K frequent elements \"\"\" heap = [] for item in items : # Maintain heap of size k if len ( heap ) < k : heappush ( heap , item ) else : if better_than_top ( item , heap [ 0 ]): heappop ( heap ) heappush ( heap , item ) return sorted ( heap ) # Return sorted result # Example Usage: K Closest Points def k_closest_points ( points , k ): return priority_queue_pattern ( points , k = k )","title":"5. Priority Queue Pattern"},{"location":"2.Interviews/b.%20technical%20interviews/#pattern-selection-guide","text":"pattern_guide = { \"Sorting-First\" : { \"Use When\" : [ \"Items need to be processed in specific order\" , \"Selection based on sorted property\" , \"No overlapping allowed\" ], \"Examples\" : [ \"Activity selection\" , \"Meeting rooms\" , \"Task scheduling\" ] }, \"Fraction/Rate\" : { \"Use When\" : [ \"Divisible items\" , \"Optimization based on rates\" , \"Knapsack-like problems\" ], \"Examples\" : [ \"Fractional knapsack\" , \"Resource allocation\" , \"Time management\" ] }, \"Running Window\" : { \"Use When\" : [ \"Time/Space intervals\" , \"Resource constraints\" , \"Overlapping intervals\" ], \"Examples\" : [ \"Meeting rooms\" , \"CPU scheduling\" , \"Resource booking\" ] }, \"Local Exchange\" : { \"Use When\" : [ \"Local optimization possible\" , \"Pairwise comparisons sufficient\" , \"Order matters\" ], \"Examples\" : [ \"Job sequencing\" , \"Task ordering\" , \"Optimization problems\" ] }, \"Priority Queue\" : { \"Use When\" : [ \"K-selection problems\" , \"Running minimum/maximum\" , \"Stream processing\" ], \"Examples\" : [ \"K closest points\" , \"Top K elements\" , \"Running median\" ] } }","title":"Pattern Selection Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#problem-solving-framework","text":"","title":"\ud83c\udfaf Problem-Solving Framework"},{"location":"2.Interviews/b.%20technical%20interviews/#1-verify-greedy-approach","text":"def verify_greedy_approach (): checks = { \"Local Choice\" : \"Can we make locally optimal choice?\" , \"Subproblem\" : \"Does it lead to simpler subproblem?\" , \"Optimality\" : \"Do local choices lead to global optimum?\" , \"Constraints\" : \"Are constraints simple and local?\" }","title":"1. Verify Greedy Approach"},{"location":"2.Interviews/b.%20technical%20interviews/#2-design-steps","text":"Sort if Needed Often first step is sorting by key metric Examples: finish time, value/weight ratio Define Greedy Choice What makes a choice locally optimal? How to select next element? Implement Selection Process Process elements in sorted order Apply greedy choice at each step Track Progress/Result Maintain running solution Update constraints","title":"2. Design Steps"},{"location":"2.Interviews/b.%20technical%20interviews/#common-pitfalls_2","text":"","title":"\u26a0\ufe0f Common Pitfalls"},{"location":"2.Interviews/b.%20technical%20interviews/#1-verification-issues","text":"pitfalls = { \"Optimality\" : \"Not verifying if greedy leads to optimal\" , \"Constraints\" : \"Missing important constraints\" , \"Sorting\" : \"Wrong sorting criteria\" , \"Edge Cases\" : \"Not handling edge cases\" }","title":"1. Verification Issues"},{"location":"2.Interviews/b.%20technical%20interviews/#2-implementation-issues","text":"implementation_issues = { \"Initialization\" : \"Incorrect initial values\" , \"Updates\" : \"Wrong progress tracking\" , \"Termination\" : \"Incorrect stopping condition\" , \"Optimization\" : \"Missing optimization opportunities\" }","title":"2. Implementation Issues"},{"location":"2.Interviews/b.%20technical%20interviews/#common-interview-problems_1","text":"","title":"\ud83d\udcdd Common Interview Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#1-scheduling-problems","text":"Activity Selection Meeting Rooms Task Scheduling","title":"1. Scheduling Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#2-optimization-problems","text":"Fractional Knapsack Minimum Coins Huffman Coding","title":"2. Optimization Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#3-connection-problems","text":"Minimum Spanning Tree Job Sequencing Shortest Path (Dijkstra's)","title":"3. Connection Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips_4","text":"Approach Start with greedy hypothesis Prove/disprove with examples Consider sorting first Track progress clearly Verification Use small examples Find counter-examples Explain why greedy works Implementation Keep code clean and simple Handle edge cases Consider optimization Test with various inputs","title":"\ud83d\udca1 Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#time-complexity-analysis_1","text":"complexities = { \"Sorting Based\" : \"O(n log n) typical\" , \"Linear Scan\" : \"O(n) without sorting\" , \"Priority Queue\" : \"O(n log k) for k elements\" , \"Space\" : \"Usually O(1) or O(n)\" } Remember: Greedy algorithms are simple but not always optimal Verify greedy choice property Consider sorting as first step Handle edge cases carefully","title":"\ud83c\udfaf Time Complexity Analysis"},{"location":"2.Interviews/b.%20technical%20interviews/#dynamic-programming-from-fundamentals-to-mastery","text":"","title":"\ud83c\udfaf Dynamic Programming - From Fundamentals to Mastery"},{"location":"2.Interviews/b.%20technical%20interviews/#introduction-to-dynamic-programming","text":"","title":"\ud83d\udcda Introduction to Dynamic Programming"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-dynamic-programming","text":"Dynamic Programming (DP) is both a mathematical optimization method and a programming method that: Breaks down complex problems into simpler subproblems Stores solutions to these subproblems to avoid recalculating them Uses stored solutions to build up to the final solution Think of it as \"careful brute force\" - instead of recalculating values we've seen before, we save them for later use.","title":"What is Dynamic Programming?"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-dynamic-programming","text":"criteria_for_dp = { \"1. Optimal Substructure\" : \"\"\" Can the problem be broken down into smaller problems? Example: Fibonacci numbers - F(n) depends on F(n-1) and F(n-2) \"\"\" , \"2. Overlapping Subproblems\" : \"\"\" Do we calculate the same things repeatedly? Example: In Fibonacci, F(5) and F(4) both need F(3) \"\"\" , \"3. No Greedy Choice\" : \"\"\" Does making the locally optimal choice not always lead to global optimal? Example: Coin change problem with coins [1, 15, 25] \"\"\" }","title":"When to Use Dynamic Programming"},{"location":"2.Interviews/b.%20technical%20interviews/#core-concepts-explained","text":"","title":"\ud83c\udfaf Core Concepts Explained"},{"location":"2.Interviews/b.%20technical%20interviews/#1-subproblems-and-optimal-substructure","text":"def understand_subproblems (): \"\"\" Example: Finding F(4) in Fibonacci sequence F(4) = F(3) + F(2) # Main problem F(3) = F(2) + F(1) # Subproblem F(2) = F(1) + F(0) # Smaller subproblem Properties: 1. Each subproblem is smaller version of main problem 2. Solution to main problem depends on subproblems 3. Base cases stop the recursion \"\"\" pass","title":"1. Subproblems and Optimal Substructure"},{"location":"2.Interviews/b.%20technical%20interviews/#2-overlapping-subproblems","text":"def show_overlapping_example ( n : int ): \"\"\" Without DP (lots of repeated calculations): F(5) \u251c\u2500\u2500 F(4) \u2502 \u251c\u2500\u2500 F(3) \u2502 \u2502 \u251c\u2500\u2500 F(2) # Calculated multiple times \u2502 \u2502 \u2514\u2500\u2500 F(1) \u2502 \u2514\u2500\u2500 F(2) # Calculated again \u2514\u2500\u2500 F(3) \u251c\u2500\u2500 F(2) # Calculated yet again \u2514\u2500\u2500 F(1) With DP (calculate once, reuse result): memo = { 0: 0, 1: 1, 2: F(2), # Calculate once, reuse many times 3: F(3), ... } \"\"\" pass","title":"2. Overlapping Subproblems"},{"location":"2.Interviews/b.%20technical%20interviews/#two-main-approaches-to-dp","text":"","title":"\ud83c\udfae Two Main Approaches to DP"},{"location":"2.Interviews/b.%20technical%20interviews/#1-top-down-memoization","text":"def explain_memoization (): \"\"\" Top-Down Process: 1. Start with original problem (top) 2. Break into subproblems recursively 3. Store results in memo table 4. Return memoized results if subproblem seen before Advantages: - More intuitive (follows natural thinking) - Only solves needed subproblems - Easier to debug Disadvantages: - Recursion overhead - Stack space usage \"\"\" # Example implementation def fib_memo ( n : int , memo : dict = None ) -> int : if memo is None : memo = {} # Base cases if n <= 1 : return n # Check memo before computing if n in memo : return memo [ n ] # Store result in memo memo [ n ] = fib_memo ( n - 1 , memo ) + fib_memo ( n - 2 , memo ) return memo [ n ]","title":"1. Top-Down (Memoization)"},{"location":"2.Interviews/b.%20technical%20interviews/#2-bottom-up-tabulation","text":"def explain_tabulation (): \"\"\" Bottom-Up Process: 1. Start with base cases (bottom) 2. Build larger solutions from smaller ones 3. Store results in table 4. Use table to build final solution Advantages: - More space efficient - No recursion overhead - Better cache performance Disadvantages: - May solve unnecessary subproblems - Sometimes less intuitive \"\"\" # Example implementation def fib_table ( n : int ) -> int : if n <= 1 : return n # Initialize table with base cases dp = [ 0 ] * ( n + 1 ) dp [ 1 ] = 1 # Build up the solution for i in range ( 2 , n + 1 ): dp [ i ] = dp [ i - 1 ] + dp [ i - 2 ] return dp [ n ]","title":"2. Bottom-Up (Tabulation)"},{"location":"2.Interviews/b.%20technical%20interviews/#problem-solving-framework_1","text":"","title":"\ud83c\udfaf Problem-Solving Framework"},{"location":"2.Interviews/b.%20technical%20interviews/#step-1-identify-dp-characteristics","text":"def identify_dp_potential ( problem ): \"\"\" Ask these questions: 1. Can I break this into smaller similar subproblems? 2. Does solving subproblems help solve the original problem? 3. Am I calculating same things repeatedly? 4. Can I store and reuse these calculations? \"\"\" checklist = { \"Optimal Substructure\" : False , \"Overlapping Subproblems\" : False , \"Need for Optimization\" : False } return all ( checklist . values ())","title":"Step 1: Identify DP Characteristics"},{"location":"2.Interviews/b.%20technical%20interviews/#step-2-define-the-subproblem","text":"def define_subproblem (): \"\"\" 1. State Definition: - What variables define a subproblem? - What information needed to solve it? 2. State Transition: - How do I move from one state to another? - What choices do I have at each state? Example (Knapsack): - State: dp[i][w] = max value using items[0..i] with weight limit w - Transition: Choose whether to include item i or not \"\"\" pass","title":"Step 2: Define the Subproblem"},{"location":"2.Interviews/b.%20technical%20interviews/#step-3-write-the-recurrence-relation","text":"def create_recurrence (): \"\"\" 1. Base Cases: - Smallest possible subproblem - Starting point for computation 2. Recurrence Formula: - How larger problems relate to smaller ones - Mathematical relationship between states Example (Knapsack): dp[i][w] = max( dp[i-1][w], # Don't take item dp[i-1][w-weight[i]] + val[i] # Take item ) \"\"\" pass","title":"Step 3: Write the Recurrence Relation"},{"location":"2.Interviews/b.%20technical%20interviews/#step-4-implement-solution","text":"def implement_solution (): \"\"\" Choose Implementation Style: 1. Top-Down if: - Natural recursive solution - Not all subproblems needed - Need to debug/understand easily 2. Bottom-Up if: - Need to optimize space - All subproblems needed - Want to avoid recursion \"\"\" pass","title":"Step 4: Implement Solution"},{"location":"2.Interviews/b.%20technical%20interviews/#common-dp-patterns","text":"","title":"\ud83c\udfaf Common DP Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-linear-sequence","text":"Used when each state depends on previous states. def linear_dp_example (): # Example: House Robber Problem def rob ( nums : List [ int ]) -> int : if not nums : return 0 if len ( nums ) == 1 : return nums [ 0 ] dp = [ 0 ] * len ( nums ) dp [ 0 ] = nums [ 0 ] dp [ 1 ] = max ( nums [ 0 ], nums [ 1 ]) for i in range ( 2 , len ( nums )): dp [ i ] = max ( dp [ i - 1 ], dp [ i - 2 ] + nums [ i ]) return dp [ - 1 ]","title":"1. Linear Sequence"},{"location":"2.Interviews/b.%20technical%20interviews/#2-matrix-chain","text":"Used for optimization problems involving sequences. def matrix_chain_example (): # Example: Matrix Chain Multiplication def matrix_mult_cost ( dimensions : List [ int ]) -> int : n = len ( dimensions ) - 1 dp = [[ 0 ] * n for _ in range ( n )] for length in range ( 2 , n + 1 ): for i in range ( n - length + 1 ): j = i + length - 1 dp [ i ][ j ] = float ( 'inf' ) for k in range ( i , j ): cost = ( dp [ i ][ k ] + dp [ k + 1 ][ j ] + dimensions [ i ] * dimensions [ k + 1 ] * dimensions [ j + 1 ]) dp [ i ][ j ] = min ( dp [ i ][ j ], cost ) return dp [ 0 ][ n - 1 ]","title":"2. Matrix Chain"},{"location":"2.Interviews/b.%20technical%20interviews/#3-interval-problems","text":"Used when dealing with ranges or intervals. def interval_dp_example (): # Example: Palindrome Partitioning def min_cuts ( s : str ) -> int : n = len ( s ) # is_palindrome[i][j] tells if s[i:j+1] is palindrome is_palindrome = [[ False ] * n for _ in range ( n )] # Single letters are palindromes for i in range ( n ): is_palindrome [ i ][ i ] = True # Check for palindromes of length 2 and more for length in range ( 2 , n + 1 ): for start in range ( n - length + 1 ): end = start + length - 1 if length == 2 : is_palindrome [ start ][ end ] = ( s [ start ] == s [ end ]) else : is_palindrome [ start ][ end ] = ( s [ start ] == s [ end ] and is_palindrome [ start + 1 ][ end - 1 ] ) # dp[i] = minimum cuts needed for s[0:i+1] dp = [ 0 ] * n for i in range ( n ): if is_palindrome [ 0 ][ i ]: dp [ i ] = 0 else : dp [ i ] = i for j in range ( i ): if is_palindrome [ j + 1 ][ i ]: dp [ i ] = min ( dp [ i ], dp [ j ] + 1 ) return dp [ n - 1 ]","title":"3. Interval Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#advanced-optimization-techniques","text":"","title":"\ud83d\udca1 Advanced Optimization Techniques"},{"location":"2.Interviews/b.%20technical%20interviews/#1-space-optimization","text":"def space_optimization_example (): \"\"\" Common Techniques: 1. Rolling Array - Keep only last k states - Use mod operator for indexing 2. State Compression - Use bits to represent states - Reduce dimension of dp table Example: Fibonacci with O(1) space \"\"\" def fib_optimized ( n : int ) -> int : if n <= 1 : return n a , b = 0 , 1 for _ in range ( 2 , n + 1 ): a , b = b , a + b return b","title":"1. Space Optimization"},{"location":"2.Interviews/b.%20technical%20interviews/#2-state-reduction","text":"def state_reduction_example (): \"\"\" Techniques: 1. Eliminate Redundant States - Identify states that can be derived - Combine overlapping states 2. Change State Representation - More efficient encoding - Different perspective on problem Example: Reducing 2D DP to 1D \"\"\" # Original 2D Knapsack def knapsack_2d ( weights : List [ int ], values : List [ int ], capacity : int ) -> int : n = len ( weights ) dp = [[ 0 ] * ( capacity + 1 ) for _ in range ( n + 1 )] for i in range ( 1 , n + 1 ): for w in range ( capacity + 1 ): if weights [ i - 1 ] <= w : dp [ i ][ w ] = max ( values [ i - 1 ] + dp [ i - 1 ][ w - weights [ i - 1 ]], dp [ i - 1 ][ w ]) else : dp [ i ][ w ] = dp [ i - 1 ][ w ] return dp [ n ][ capacity ] # Optimized 1D Knapsack def knapsack_1d ( weights : List [ int ], values : List [ int ], capacity : int ) -> int : dp = [ 0 ] * ( capacity + 1 ) for i in range ( len ( weights )): for w in range ( capacity , weights [ i ] - 1 , - 1 ): dp [ w ] = max ( dp [ w ], dp [ w - weights [ i ]] + values [ i ]) return dp [ capacity ] Remember: Always start with a clear understanding of subproblems Draw out the recurrence relation Consider both top-down and bottom-up approaches Look for optimization opportunities Test with small cases first","title":"2. State Reduction"},{"location":"2.Interviews/b.%20technical%20interviews/#reference","text":"Dynamic Programming","title":"Reference"},{"location":"2.Interviews/b.%20technical%20interviews/#graphs-graph-theory","text":"","title":"\ud83d\udcca Graphs &amp; Graph Theory"},{"location":"2.Interviews/b.%20technical%20interviews/#core-concepts_2","text":"","title":"\ud83d\udcda Core Concepts"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-a-graph","text":"A graph is a data structure consisting of: Vertices (Nodes) : Points in the graph Edges : Connections between vertices Optional Properties : Weights, directions, labels Types of Graphs: graph_types = { \"Undirected\" : \"Edges have no direction (Facebook friendships)\" , \"Directed\" : \"Edges have direction (Twitter follows)\" , \"Weighted\" : \"Edges have weights (Road distances)\" , \"Connected\" : \"Path exists between any two vertices\" , \"Cyclic\" : \"Contains at least one cycle\" , \"Acyclic\" : \"Contains no cycles (trees are acyclic)\" }","title":"What is a Graph?"},{"location":"2.Interviews/b.%20technical%20interviews/#graph-representations","text":"","title":"\ud83c\udfaf Graph Representations"},{"location":"2.Interviews/b.%20technical%20interviews/#1-adjacency-list-most-common-in-interviews","text":"class Graph : def __init__ ( self ): self . graph = {} def add_vertex ( self , vertex ): if vertex not in self . graph : self . graph [ vertex ] = set () def add_edge ( self , v1 , v2 ): if v1 not in self . graph : self . add_vertex ( v1 ) if v2 not in self . graph : self . add_vertex ( v2 ) self . graph [ v1 ] . add ( v2 ) self . graph [ v2 ] . add ( v1 ) # Remove for directed graph","title":"1. Adjacency List (Most Common in Interviews)"},{"location":"2.Interviews/b.%20technical%20interviews/#2-adjacency-matrix","text":"class GraphMatrix : def __init__ ( self , vertices ): self . V = vertices self . graph = [[ 0 ] * vertices for _ in range ( vertices )] def add_edge ( self , v1 , v2 , weight = 1 ): self . graph [ v1 ][ v2 ] = weight self . graph [ v2 ][ v1 ] = weight # Remove for directed graph","title":"2. Adjacency Matrix"},{"location":"2.Interviews/b.%20technical%20interviews/#essential-graph-operations","text":"","title":"\ud83c\udfae Essential Graph Operations"},{"location":"2.Interviews/b.%20technical%20interviews/#1-graph-traversal","text":"","title":"1. Graph Traversal"},{"location":"2.Interviews/b.%20technical%20interviews/#bfs-breadth-first-search","text":"from collections import deque def bfs ( graph , start ): \"\"\" Time: O(V + E) Space: O(V) Use when: - Finding shortest paths - Level-by-level traversal - Finding nodes at distance k \"\"\" visited = set ([ start ]) queue = deque ([ start ]) while queue : vertex = queue . popleft () for neighbor in graph [ vertex ]: if neighbor not in visited : visited . add ( neighbor ) queue . append ( neighbor ) return visited","title":"BFS (Breadth-First Search)"},{"location":"2.Interviews/b.%20technical%20interviews/#dfs-depth-first-search","text":"def dfs ( graph , start , visited = None ): \"\"\" Time: O(V + E) Space: O(V) Use when: - Finding paths/cycles - Exhaustively exploring paths - Topological sorting \"\"\" if visited is None : visited = set () visited . add ( start ) for neighbor in graph [ start ]: if neighbor not in visited : dfs ( graph , neighbor , visited ) return visited # Iterative DFS (often preferred in interviews) def dfs_iterative ( graph , start ): visited = set () stack = [ start ] while stack : node = stack . pop () if node not in visited : visited . add ( node ) stack . extend ( neighbor for neighbor in graph [ node ] if neighbor not in visited ) return visited","title":"DFS (Depth-First Search)"},{"location":"2.Interviews/b.%20technical%20interviews/#2-path-finding","text":"","title":"2. Path Finding"},{"location":"2.Interviews/b.%20technical%20interviews/#find-path-between-two-vertices","text":"def find_path ( graph , start , end , path = None ): if path is None : path = [] path = path + [ start ] if start == end : return path for neighbor in graph [ start ]: if neighbor not in path : new_path = find_path ( graph , neighbor , end , path ) if new_path : return new_path return None","title":"Find Path Between Two Vertices"},{"location":"2.Interviews/b.%20technical%20interviews/#find-all-paths","text":"def find_all_paths ( graph , start , end , path = None ): if path is None : path = [] path = path + [ start ] if start == end : return [ path ] paths = [] for neighbor in graph [ start ]: if neighbor not in path : new_paths = find_all_paths ( graph , neighbor , end , path ) paths . extend ( new_paths ) return paths","title":"Find All Paths"},{"location":"2.Interviews/b.%20technical%20interviews/#common-graph-algorithms-for-interviews","text":"","title":"\ud83c\udfaf Common Graph Algorithms for Interviews"},{"location":"2.Interviews/b.%20technical%20interviews/#1-detect-cycle","text":"def has_cycle ( graph ): visited = set () rec_stack = set () def dfs_cycle ( vertex ): visited . add ( vertex ) rec_stack . add ( vertex ) for neighbor in graph [ vertex ]: if neighbor not in visited : if dfs_cycle ( neighbor ): return True elif neighbor in rec_stack : return True rec_stack . remove ( vertex ) return False for vertex in graph : if vertex not in visited : if dfs_cycle ( vertex ): return True return False","title":"1. Detect Cycle"},{"location":"2.Interviews/b.%20technical%20interviews/#2-topological-sort","text":"def topological_sort ( graph ): \"\"\" For directed acyclic graphs (DAGs) Time: O(V + E) Space: O(V) Use when: - Scheduling with dependencies - Build systems - Course prerequisites \"\"\" def dfs ( node ): if node in visited : return visited . add ( node ) for neighbor in graph [ node ]: dfs ( neighbor ) result . append ( node ) visited = set () result = [] for node in graph : dfs ( node ) return result [:: - 1 ] # Reverse for correct order # Alternative: Kahn's Algorithm (BFS-based) def topological_sort_kahn ( graph ): in_degree = { node : 0 for node in graph } for node in graph : for neighbor in graph [ node ]: in_degree [ neighbor ] += 1 queue = deque ([ node for node , degree in in_degree . items () if degree == 0 ]) result = [] while queue : node = queue . popleft () result . append ( node ) for neighbor in graph [ node ]: in_degree [ neighbor ] -= 1 if in_degree [ neighbor ] == 0 : queue . append ( neighbor ) return result if len ( result ) == len ( graph ) else [] # Check for cycles","title":"2. Topological Sort"},{"location":"2.Interviews/b.%20technical%20interviews/#3-connected-components","text":"def find_connected_components ( graph ): def dfs_component ( vertex , component ): visited . add ( vertex ) component . append ( vertex ) for neighbor in graph [ vertex ]: if neighbor not in visited : dfs_component ( neighbor , component ) visited = set () components = [] for vertex in graph : if vertex not in visited : current_component = [] dfs_component ( vertex , current_component ) components . append ( current_component ) return components","title":"3. Connected Components"},{"location":"2.Interviews/b.%20technical%20interviews/#4-shortest-path-algorithms","text":"","title":"4. Shortest Path Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#dijkstras-algorithm","text":"import heapq def dijkstra ( graph , start ): \"\"\" For weighted graphs with non-negative edges Time: O((V + E) log V) Space: O(V) Use when: - Finding shortest paths - Network routing - GPS navigation \"\"\" distances = { vertex : float ( 'infinity' ) for vertex in graph } distances [ start ] = 0 pq = [( 0 , start )] while pq : current_distance , current = heapq . heappop ( pq ) if current_distance > distances [ current ]: continue for neighbor , weight in graph [ current ] . items (): distance = current_distance + weight if distance < distances [ neighbor ]: distances [ neighbor ] = distance heapq . heappush ( pq , ( distance , neighbor )) return distances","title":"Dijkstra's Algorithm"},{"location":"2.Interviews/b.%20technical%20interviews/#5-union-find-disjoint-set","text":"class UnionFind : \"\"\" Time: O(\u03b1(n)) per operation (practically O(1)) Space: O(n) Use when: - Finding connected components - Cycle detection - Minimum spanning trees \"\"\" def __init__ ( self , size ): self . parent = list ( range ( size )) self . rank = [ 0 ] * size def find ( self , x ): if self . parent [ x ] != x : self . parent [ x ] = self . find ( self . parent [ x ]) # Path compression return self . parent [ x ] def union ( self , x , y ): px , py = self . find ( x ), self . find ( y ) if px == py : return False # Union by rank if self . rank [ px ] < self . rank [ py ]: self . parent [ px ] = py elif self . rank [ px ] > self . rank [ py ]: self . parent [ py ] = px else : self . parent [ py ] = px self . rank [ px ] += 1 return True","title":"5. Union Find (Disjoint Set)"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-problem-patterns","text":"","title":"\ud83d\udcdd Interview Problem Patterns"},{"location":"2.Interviews/b.%20technical%20interviews/#1-graph-traversal-problems","text":"Visiting all nodes/edges Finding connected components Level-order traversal traversal_tips = { \"BFS\" : \"Use when:- Finding shortest path- Level by level traversal- Minimum steps\" , \"DFS\" : \"Use when:- Exploring paths- Finding cycles- Topological sorting\" , \"Edge Cases\" : \"- Empty graph- Single node- Disconnected components\" }","title":"1. Graph Traversal Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#2-path-finding-problems","text":"Shortest path All possible paths Path with constraints def shortest_path ( graph , start , end ): queue = deque ([( start , [ start ])]) visited = { start } while queue : vertex , path = queue . popleft () if vertex == end : return path for neighbor in graph [ vertex ]: if neighbor not in visited : visited . add ( neighbor ) queue . append (( neighbor , path + [ neighbor ])) return None","title":"2. Path Finding Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips_5","text":"Representation Choice choosing_representation = { \"Adjacency List\" : \"- Sparse graphs- Memory efficient- Quick neighbor lookup\" , \"Adjacency Matrix\" : \"- Dense graphs- Quick edge weight lookup- Simple implementation\" } Algorithm Selection algorithm_selection = { \"BFS\" : \"Shortest path in unweighted graph\" , \"DFS\" : \"Path finding, cycle detection\" , \"Dijkstra\" : \"Shortest path in weighted graph\" , \"Union Find\" : \"Connected components, cycle detection in undirected graph\" } selection_guide = { \"Shortest Path (Unweighted)\" : \"Use BFS\" , \"Shortest Path (Weighted, Non-negative)\" : \"Use Dijkstra\" , \"Shortest Path (Weighted, Can be negative)\" : \"Use Bellman-Ford\" , \"Cycle Detection\" : \"Use DFS with recursion stack\" , \"Component Finding\" : \"Use Union Find or DFS\" , \"Dependency Ordering\" : \"Use Topological Sort\" , \"Two-Coloring Problems\" : \"Use Bipartite Check\" } Edge Cases to Consider edge_cases = [ \"Empty graph\" , \"Single node\" , \"Disconnected components\" , \"Cycles\" , \"Self-loops\" , \"Bidirectional edges\" , \"No path exists\" ] Optimization Tips : Use adjacency list for sparse graphs Use adjacency matrix for dense graphs Consider using iterative DFS instead of recursive for large graphs Use Union Find for dynamic connectivity problems Cache results in graph traversal when possible Remember: Always clarify the graph properties (directed/undirected, weighted/unweighted) Consider time/space complexity tradeoffs Draw examples when solving Test with small cases first Consider using helper functions for complex logic","title":"\ud83d\udca1 Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#minimum-spanning-trees-mst","text":"","title":"\ud83c\udf33 Minimum Spanning Trees (MST)"},{"location":"2.Interviews/b.%20technical%20interviews/#core-concepts_3","text":"","title":"\ud83d\udcda Core Concepts"},{"location":"2.Interviews/b.%20technical%20interviews/#what-is-a-minimum-spanning-tree","text":"\"\"\" A Minimum Spanning Tree (MST) is a subset of edges in a connected, undirected, weighted graph that: 1. Connects all vertices 2. Contains no cycles 3. Has minimum total edge weight among all possible spanning trees Properties: - Contains exactly V-1 edges (where V is number of vertices) - May not be unique (graph can have multiple MSTs) - Always unique if all edge weights are different \"\"\"","title":"What is a Minimum Spanning Tree?"},{"location":"2.Interviews/b.%20technical%20interviews/#key-algorithms","text":"","title":"\ud83c\udfaf Key Algorithms"},{"location":"2.Interviews/b.%20technical%20interviews/#1-kruskals-algorithm","text":"class UnionFind : def __init__ ( self , size ): self . parent = list ( range ( size )) self . rank = [ 0 ] * size def find ( self , x ): if self . parent [ x ] != x : self . parent [ x ] = self . find ( self . parent [ x ]) # Path compression return self . parent [ x ] def union ( self , x , y ): px , py = self . find ( x ), self . find ( y ) if px == py : return False # Union by rank if self . rank [ px ] < self . rank [ py ]: self . parent [ px ] = py elif self . rank [ px ] > self . rank [ py ]: self . parent [ py ] = px else : self . parent [ py ] = px self . rank [ px ] += 1 return True def kruskal_mst ( graph , V ): \"\"\" Time: O(E log E) where E is number of edges Space: O(V) where V is number of vertices Use when: - Graph is sparse (E << V\u00b2) - Graph might not be connected - Edge weights are primary consideration \"\"\" edges = [] # (weight, u, v) for u in range ( V ): for v , w in graph [ u ]: edges . append (( w , u , v )) edges . sort () # Sort by weight uf = UnionFind ( V ) mst = [] mst_weight = 0 for weight , u , v in edges : if uf . union ( u , v ): # If no cycle is created mst . append (( u , v )) mst_weight += weight if len ( mst ) == V - 1 : break return mst , mst_weight","title":"1. Kruskal's Algorithm"},{"location":"2.Interviews/b.%20technical%20interviews/#2-prims-algorithm","text":"from heapq import heappush , heappop def prim_mst ( graph , V ): \"\"\" Time: O(E log V) with min-heap Space: O(V) Use when: - Graph is dense (E \u2248 V\u00b2) - Graph is guaranteed to be connected - Starting vertex is known/important \"\"\" visited = [ False ] * V min_heap = [( 0 , 0 , - 1 )] # (weight, vertex, parent) mst = [] mst_weight = 0 while min_heap : weight , vertex , parent = heappop ( min_heap ) if visited [ vertex ]: continue visited [ vertex ] = True if parent != - 1 : mst . append (( parent , vertex )) mst_weight += weight for next_vertex , edge_weight in graph [ vertex ]: if not visited [ next_vertex ]: heappush ( min_heap , ( edge_weight , next_vertex , vertex )) return mst , mst_weight","title":"2. Prim's Algorithm"},{"location":"2.Interviews/b.%20technical%20interviews/#algorithm-selection-guide","text":"","title":"\ud83c\udfae Algorithm Selection Guide"},{"location":"2.Interviews/b.%20technical%20interviews/#when-to-use-each-algorithm","text":"def choose_mst_algorithm ( graph_properties ): selection_guide = { \"Kruskal\" : { \"Best for\" : [ \"Sparse graphs (E << V\u00b2)\" , \"When graph might be disconnected\" , \"When edge weights are the focus\" ], \"Advantages\" : [ \"Works with disconnected graphs\" , \"Tends to be simpler to implement\" , \"Good for sparse graphs\" ] }, \"Prim\" : { \"Best for\" : [ \"Dense graphs (E \u2248 V\u00b2)\" , \"When starting vertex matters\" , \"When graph is connected\" ], \"Advantages\" : [ \"Better for dense graphs\" , \"Can find partial MSTs\" , \"More efficient with priority queue\" ] } }","title":"When to Use Each Algorithm"},{"location":"2.Interviews/b.%20technical%20interviews/#common-interview-problems_2","text":"","title":"\ud83d\udcdd Common Interview Problems"},{"location":"2.Interviews/b.%20technical%20interviews/#1-connecting-cities-with-minimum-cost","text":"def min_cost_connect_cities ( connections , N ): \"\"\" Given a list of connections [city1, city2, cost], find minimum cost to connect all cities \"\"\" def find ( x ): if parent [ x ] != x : parent [ x ] = find ( parent [ x ]) return parent [ x ] def union ( x , y ): px , py = find ( x ), find ( y ) if px == py : return False parent [ px ] = py return True parent = list ( range ( N + 1 )) connections . sort ( key = lambda x : x [ 2 ]) # Sort by cost total_cost = 0 edges_used = 0 for city1 , city2 , cost in connections : if union ( city1 , city2 ): total_cost += cost edges_used += 1 return total_cost if edges_used == N - 1 else - 1","title":"1. Connecting Cities with Minimum Cost"},{"location":"2.Interviews/b.%20technical%20interviews/#2-network-optimization","text":"def optimize_network ( nodes , connections ): \"\"\" Optimize network connections while maintaining minimum latency between all nodes \"\"\" def mst_with_constraints ( edges ): uf = UnionFind ( len ( nodes )) mst = [] total_latency = 0 for u , v , latency in sorted ( edges , key = lambda x : ( x [ 2 ], x [ 0 ])): if uf . union ( u , v ): mst . append (( u , v )) total_latency += latency return mst , total_latency if len ( mst ) == len ( nodes ) - 1 else float ( 'inf' )","title":"2. Network Optimization"},{"location":"2.Interviews/b.%20technical%20interviews/#interview-tips_6","text":"","title":"\ud83d\udca1 Interview Tips"},{"location":"2.Interviews/b.%20technical%20interviews/#1-problem-recognition","text":"mst_indicators = { \"Minimum cost/distance/weight\" : \"Total weight needs to be minimized\" , \"Connect all points\" : \"Need spanning tree property\" , \"No cycles allowed\" : \"Tree structure required\" , \"Optimize network\" : \"Network optimization problems\" , \"Reduce redundancy\" : \"Remove unnecessary edges\" }","title":"1. Problem Recognition"},{"location":"2.Interviews/b.%20technical%20interviews/#2-implementation-strategy","text":"implementation_tips = { \"1. Graph Representation\" : [ \"Adjacency list for sparse graphs\" , \"Adjacency matrix for dense graphs\" , \"Edge list for Kruskal's\" ], \"2. Edge Cases\" : [ \"Empty graph\" , \"Single node\" , \"Disconnected components\" , \"Equal edge weights\" ], \"3. Optimization\" : [ \"Use Union-Find for cycle detection\" , \"Priority queue for Prim's\" , \"Sort edges once for Kruskal's\" ] }","title":"2. Implementation Strategy"},{"location":"2.Interviews/b.%20technical%20interviews/#3-common-mistakes-to-avoid","text":"common_mistakes = { \"Algorithm Selection\" : \"Not considering graph density\" , \"Cycle Detection\" : \"Forgetting to check for cycles\" , \"Edge Processing\" : \"Not handling duplicate edges\" , \"Disconnected Graphs\" : \"Assuming graph is connected\" , \"Edge Weights\" : \"Not handling negative weights\" } Remember: Always verify if graph is connected when using Prim's Consider edge cases (empty graph, single node) Watch for negative edge weights Check if all vertices are included in final MST Consider trade-offs between algorithms based on graph properties","title":"3. Common Mistakes to Avoid"},{"location":"2.Interviews/b.%20technical%20interviews/#technical-interview-patterns","text":"Common Technical Interview Patterns","title":"Technical Interview Patterns"}]}